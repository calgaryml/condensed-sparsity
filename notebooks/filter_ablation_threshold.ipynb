{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "import wandb\n",
    "from datetime import date\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models.model_factory import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1337/3979993277.py:3: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize(config_path=\"../configs\"):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset': {'name': 'cifar10', 'normalize': False, 'num_classes': 10, 'classes': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], 'train_len': 50000}, 'model': {'name': 'wide_resnet22'}, 'experiment': {'comment': 'dense_alloc-${rigl.dense_allocation}_weight_per_neuron-${rigl.min_salient_weights_per_neuron}', 'name': '${model.name}_${dataset.name}_${experiment.comment}', 'resume_from_checkpoint': False, 'run_id': None}, 'paths': {'base': '${oc.env:BASE_PATH}', 'data_folder': '${paths.base}/data', 'artifacts': '${paths.base}/artifacts', 'logs': '${paths.base}/logs', 'checkpoints': '${paths.artifacts}/checkpoints'}, 'rigl': {'dense_allocation': 0.01, 'delta': 2, 'grad_accumulation_n': 1, 'alpha': 0.3, 'static_topo': 0, 'const_fan_in': True, 'sparsity_distribution': 'erk', 'erk_power_scale': 1.0, 'use_t_end': True, 'static_ablation': False, 'dynamic_ablation': True, 'filter_ablation_threshold': 0.01, 'use_sparse_initialization': False, 'min_salient_weights_per_neuron': 1}, 'training': {'dry_run': False, 'batch_size': 128, 'simulated_batch_size': None, 'test_batch_size': 1000, 'epochs': 250, 'seed': 42, 'log_interval': 1000, 'save_model': True, 'max_steps': None, 'optimizer': 'sgd', 'weight_decay': 0.0005, 'momentum': 0.9, 'label_smoothing': 0.0, 'scheduler': 'step_lr', 'lr': 0.1, 'init_lr': 1e-06, 'warm_up_steps': 0, 'gamma': 0.5, 'step_size': 77}, 'compute': {'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 2, 'dist_backend': 'nccl'}, 'wandb': {'project': 'condensed-rigl', 'entity': 'condensed-sparsity', 'start_method': 'thread', 'log_images': False, 'watch_model_grad_and_weights': False, 'log_filter_stats': True}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"cifar10\"\n",
    "model=\"wide_resnet22\"\n",
    "with hydra.initialize(config_path=\"../configs\"):\n",
    "    cfg = hydra.compose(\n",
    "        config_name=\"config.yaml\", \n",
    "        overrides=[\n",
    "            f\"dataset={dataset}\",\n",
    "            f\"model={model}\",\n",
    "            \"compute.distributed=False\",\n",
    "            \"rigl.dense_allocation=0.01\",\n",
    "            \"rigl.const_fan_in=True\",\n",
    "            \"rigl.filter_ablation_threshold=0.01\",\n",
    "            \"rigl.dynamic_ablation=True\", \n",
    "            \"rigl.static_ablation=False\",\n",
    "            \"rigl.min_salient_weights_per_neuron=1\",\n",
    "            \"rigl.delta=2\",\n",
    "            \"rigl.grad_accumulation_n=1\",\n",
    "        ]\n",
    "    )\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model wide_resnet22/cifar10 using <function get_wide_resnet_22 at 0x7f0adc2350d0> with args: () and kwargs: {}\n"
     ]
    }
   ],
   "source": [
    "# net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")\n",
    "# net = ModelFactory.load_model(\"resnet50\", \"imagenet\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name\n",
    "    )\n",
    "model.to(device)\n",
    "optimizer = get_optimizer(cfg, model, state_dict=None)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=None)\n",
    "T_end = get_T_end(cfg, train_loader)\n",
    "if cfg.rigl.const_fan_in:\n",
    "    rigl_scheduler = RigLConstFanScheduler\n",
    "else:\n",
    "    rigl_scheduler = RigLScheduler\n",
    "pruner = rigl_scheduler(\n",
    "    model,\n",
    "    optimizer,\n",
    "    dense_allocation=cfg.rigl.dense_allocation,\n",
    "    alpha=cfg.rigl.alpha,\n",
    "    delta=cfg.rigl.delta,\n",
    "    static_topo=cfg.rigl.static_topo,\n",
    "    T_end=T_end,\n",
    "    ignore_linear_layers=False,\n",
    "    grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "    sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "    erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "    state_dict=None,\n",
    "    filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "    static_ablation=cfg.rigl.static_ablation,\n",
    "    dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "    min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m score_grow_lifted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs(w)\n\u001b[1;32m      3\u001b[0m n_fan_in \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m----> 4\u001b[0m idx_to_grow \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtopk(\n\u001b[1;32m      5\u001b[0m                     score_grow_lifted\u001b[39m.\u001b[39;49mflatten(),\n\u001b[1;32m      6\u001b[0m                     k\u001b[39m=\u001b[39;49mn_fan_in,\n\u001b[1;32m      7\u001b[0m                 )\u001b[39m.\u001b[39mindices\n\u001b[1;32m      8\u001b[0m idx_to_grow\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "w = pruner.W[0]\n",
    "score_grow_lifted = torch.abs(w)\n",
    "n_fan_in = -1\n",
    "idx_to_grow = torch.topk(\n",
    "                    score_grow_lifted.flatten(),\n",
    "                    k=n_fan_in,\n",
    "                ).indices\n",
    "idx_to_grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False],\n",
       "        [ True, False]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.Tensor([[2,3],[2,3]])\n",
    "torch.where(\n",
    "    t==2,\n",
    "    torch.ones_like(t, dtype=torch.bool),\n",
    "    torch.zeros_like(t, dtype=torch.bool)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (data,target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    logits = model(data)\n",
    "    loss = F.cross_entropy(\n",
    "        logits,\n",
    "        target,\n",
    "        label_smoothing=cfg.training.label_smoothing,\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx > 200:\n",
    "        break\n",
    "    pruner()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_fraction = pruner.cosine_annealing()\n",
    "# if distributed these values will be populated\n",
    "is_dist = dist.is_initialized()\n",
    "world_size = dist.get_world_size() if is_dist else None\n",
    "\n",
    "pruner.dynamically_ablated_neuron_idx = []\n",
    "for idx, w in enumerate(pruner.W):\n",
    "    # if sparsity is 0%, skip\n",
    "    if pruner.S[idx] <= 0:\n",
    "        continue\n",
    "\n",
    "    # calculate raw scores\n",
    "    score_drop = torch.abs(w)\n",
    "    _max_score_drop = score_drop.max().item()\n",
    "\n",
    "    # Set ablated filter drop scores to min of score_grow to avoid\n",
    "    # pruning already inactive weights\n",
    "    # TODO: Remove inital ablated filtering.\n",
    "    score_drop[\n",
    "        : pruner.static_ablated_filters[idx]\n",
    "    ] = score_drop.min().item()\n",
    "\n",
    "    score_grow = torch.abs(pruner.backward_hook_objects[idx].dense_grad)\n",
    "\n",
    "    # Set ablated filter scores to min of score_grow to avoid regrowing\n",
    "    score_grow[\n",
    "        : pruner.static_ablated_filters[idx]\n",
    "    ] = score_grow.min().item()\n",
    "\n",
    "    current_mask = pruner.backward_masks[idx]\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(326, device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_values, sorted_idx = torch.abs(w).flatten().sort(descending=True)\n",
    "max_idx = sorted_idx[0]\n",
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3056, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value = sorted_values[0]\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([326, 328, 424,  12, 244, 199, 203, 427, 342, 247, 215,  17,  14, 350,\n",
      "        192,  26, 420, 260, 411, 409, 333, 245, 202, 251, 250, 248, 256, 254,\n",
      "        259, 257, 243, 253,  19, 193, 194, 207, 246,  20,  18, 197, 249, 196,\n",
      "        198, 191, 190,  22,  25, 414, 349,  24, 415, 429, 347, 345, 200,  13,\n",
      "         16], device='cuda:0')\n",
      "ablating neuron 2\n",
      "ablating neuron 3\n",
      "ablating neuron 4\n",
      "ablating neuron 5\n",
      "ablating neuron 6\n",
      "ablating neuron 8\n",
      "ablating neuron 10\n",
      "ablating neuron 13\n",
      "ablating neuron 14\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def _get_neurons_to_ablate(\n",
    "    pruner, \n",
    "    score_drop: torch.Tensor,\n",
    "    score_grow,\n",
    "    n_keep,\n",
    "    n_prune,\n",
    "    n_total,\n",
    "):\n",
    "    if pruner.dynamic_ablation:\n",
    "        neurons_to_ablate = []\n",
    "        saliency_mask = torch.zeros(\n",
    "            size=(score_drop.numel(),),\n",
    "            dtype=torch.bool,\n",
    "            device=score_drop.device,\n",
    "        )\n",
    "        _, keep_idx = score_drop.flatten().sort(descending=True)\n",
    "        print(keep_idx[:n_keep])\n",
    "        saliency_mask[keep_idx[:n_keep]] = True\n",
    "        # print(f\"Keep_idx from drop: {[i for i in saliency_mask if i.any()]}\")\n",
    "\n",
    "        _, grow_idx = score_grow.flatten().sort(descending=True)\n",
    "        saliency_mask[grow_idx[:n_prune]] = True\n",
    "\n",
    "        saliency_mask = saliency_mask.reshape(shape=score_drop.shape)\n",
    "        for neuron_idx, neuron in enumerate(saliency_mask):\n",
    "            if neuron.sum() < pruner.min_salient_weights_per_neuron:\n",
    "                print(f\"ablating neuron {neuron_idx}\")\n",
    "                neurons_to_ablate.append(neuron_idx)\n",
    "        return neurons_to_ablate, saliency_mask\n",
    "        \n",
    "n_total = pruner.N[idx]\n",
    "n_ones = torch.sum(current_mask).item()\n",
    "n_prune = int(n_ones * drop_fraction)\n",
    "n_keep = int(n_ones - n_prune)\n",
    "n_non_zero_weights = torch.count_nonzero(score_drop).item()\n",
    "if n_non_zero_weights < n_keep:\n",
    "    # Then we don't have enough non-zero weights to keep. We keep\n",
    "    # ALL non-zero weights in this scenario and readjust our keep /\n",
    "    # prune amounts to suit\n",
    "    n_keep = n_non_zero_weights\n",
    "    n_prune = n_ones - n_keep\n",
    "\n",
    "# Get neurons to ablate\n",
    "neurons_to_ablate, saliency_mask = _get_neurons_to_ablate(\n",
    "    pruner,\n",
    "    score_drop=score_drop,\n",
    "    score_grow=score_grow,\n",
    "    n_keep=n_keep,\n",
    "    n_prune=n_prune,\n",
    "    n_total=n_total,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 8, 10, 13, 14]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons_to_ablate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(326, device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12, device='cuda:0')\n",
      "tensor(7, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(15, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(0, device='cuda:0')\n",
      "tensor(8, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for f in saliency_mask:\n",
    "    print(f.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 8, 10, 13, 14]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurons_to_ablate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 0, 0, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_conv_idx_from_flat_idx(max_idx.item(), w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner.dynamically_ablated_neuron_idx.append(neurons_to_ablate)\n",
    "# print(f\"neurons to ablate = {neurons_to_ablate}\")\n",
    "# print(f\"len neurons to ablate = {len(neurons_to_ablate)}\")\n",
    "n_fan_in = get_fan_in_after_ablation(\n",
    "    weight_tensor=w,\n",
    "    num_neurons_to_ablate=len(neurons_to_ablate),\n",
    "    sparsity=pruner.S[idx],\n",
    ")\n",
    "\n",
    "# create drop mask\n",
    "drop_mask = pruner._get_drop_mask(\n",
    "    score_drop,\n",
    "    n_keep,\n",
    "    neurons_to_ablate=neurons_to_ablate,\n",
    "    n_fan_in=n_fan_in,\n",
    ")\n",
    "\n",
    "# create growth mask per filter\n",
    "grow_mask = pruner._get_grow_mask(\n",
    "    score_grow,\n",
    "    drop_mask,\n",
    "    n_fan_in,\n",
    "    neurons_to_ablate,\n",
    ")\n",
    "\n",
    "# get new weights\n",
    "new_weights = pruner._get_new_weights(w, current_mask, grow_mask)\n",
    "w.data = new_weights\n",
    "\n",
    "combined_mask = grow_mask + drop_mask\n",
    "current_mask.data = combined_mask\n",
    "\n",
    "pruner.reset_momentum()\n",
    "pruner.apply_mask_to_weights()\n",
    "pruner.apply_mask_to_gradients()\n",
    "pruner._verify_neuron_ablation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3056, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(w).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import get_W\n",
    "\n",
    "W = get_W(model=model)\n",
    "type(W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[13,  9,  8],\n",
       "          [ 3, 12, 10],\n",
       "          [11, 11,  9]],\n",
       "\n",
       "         [[ 0,  1,  0],\n",
       "          [ 1,  1,  1],\n",
       "          [ 0,  0,  0]],\n",
       "\n",
       "         [[ 0,  2,  1],\n",
       "          [ 1,  2,  0],\n",
       "          [ 0,  1, 12]]],\n",
       "\n",
       "\n",
       "        [[[ 0,  1, 13],\n",
       "          [ 0, 15, 13],\n",
       "          [ 0, 14, 11]],\n",
       "\n",
       "         [[ 3,  7,  1],\n",
       "          [ 3,  4,  7],\n",
       "          [ 1,  1, 10]],\n",
       "\n",
       "         [[ 4,  3,  0],\n",
       "          [ 6,  3,  2],\n",
       "          [ 2,  4, 13]]],\n",
       "\n",
       "\n",
       "        [[[ 3,  3,  0],\n",
       "          [ 1,  0,  1],\n",
       "          [ 1,  1,  0]],\n",
       "\n",
       "         [[ 6,  9,  7],\n",
       "          [ 4,  6,  2],\n",
       "          [ 2,  3,  2]],\n",
       "\n",
       "         [[ 7,  5,  2],\n",
       "          [ 7,  1,  3],\n",
       "          [ 5,  6,  2]]]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_fan_in = 3\n",
    "\n",
    "_, idx = w.topk(k=n_fan_in, largest=True, dim=0, sorted=False)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = W[0]\n",
    "w.shape\n",
    "n_keep = int(w.numel()*0.1)\n",
    "n_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = 0.3347453474998474"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3347, 0.3173, 0.3022, 0.2750, 0.2702, 0.2687, 0.2682, 0.2674, 0.1919,\n",
       "        0.1640, 0.1605, 0.1596, 0.1591, 0.1573, 0.1544, 0.1524, 0.1522, 0.1480,\n",
       "        0.1461, 0.1427, 0.1416, 0.1350, 0.1318, 0.1273, 0.1163, 0.1135, 0.1129,\n",
       "        0.1128, 0.1062, 0.1062, 0.1047, 0.1025, 0.0999, 0.0956, 0.0897, 0.0894,\n",
       "        0.0883, 0.0869, 0.0861, 0.0854], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v, i = torch.abs(w).flatten().sort(descending=True)\n",
    "i\n",
    "torch.abs(w).flatten()[i][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_w = (mask.to(device=\"cuda\") * w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3347, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_w[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros(size=(w.numel(),), dtype=torch.bool)\n",
    "mask[i[:40]] = True\n",
    "mask = mask.reshape(w.shape)\n",
    "# mask = mask.reshape(-1)[i] = True\n",
    "# mask.reshape(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "_, keep_mask_idx = torch.abs(w).flatten().topk(k=w.numel(), dim=-1, largest=True, sorted=False)\n",
    "mask = (keep_mask_idx == 0).reshape(w.shape)\n",
    "\n",
    "for idx, f in enumerate(mask):\n",
    "    if f.any():\n",
    "        print(idx)\n",
    "# keep_mask= torch.zeros(size=w.shape, dtype=torch.bool).flatten()\n",
    "# keep_mask[keep_mask_idx] = True\n",
    "# keep_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "selected index k out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m values, idx \u001b[39m=\u001b[39m w\u001b[39m.\u001b[39;49mtopk(k\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      2\u001b[0m                      dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m idx\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mRuntimeError\u001b[0m: selected index k out of range"
     ]
    }
   ],
   "source": [
    "values, idx = w.topk(k=-1,\n",
    "                     dim=0)\n",
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2 = _get_W(model=model)\n",
    "W2 == W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruner.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conv1', Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False))\n",
      "('bn1', BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
      "('relu', ReLU(inplace=True))\n",
      "('maxpool', MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False))\n",
      "('layer1', Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "))\n",
      "('layer2', Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "))\n",
      "('layer3', Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "))\n",
      "('layer4', Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "))\n",
      "('avgpool', AdaptiveAvgPool2d(output_size=(1, 1)))\n",
      "('fc', Linear(in_features=2048, out_features=1000, bias=True))\n"
     ]
    }
   ],
   "source": [
    "for i in model._modules.items():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n",
      "tensor(True, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for better_way, pruner_way in zip(found_types, pruner.W):\n",
    "    print(torch.eq(better_way.weight, pruner_way).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RigLScheduler(\\nlayers=54,\\nnonzero_params=[384/9408, 576/4096, 640/36864, 1536/16384, 1536/16384, 1536/16384, 640/36864, 1536/16384, 1536/16384, 640/36864, 1536/16384, 1792/32768, 1200/147456, 3072/65536, 3584/131072, 3072/65536, 1200/147456, 3072/65536, 3072/65536, 1200/147456, 3072/65536, 3072/65536, 1200/147456, 3072/65536, 3584/131072, 2500/589824, 6000/262144, 7000/524288, 6144/262144, 2500/589824, 6000/262144, 6144/262144, 2500/589824, 6000/262144, 6144/262144, 2500/589824, 6000/262144, 6144/262144, 2500/589824, 6000/262144, 6144/262144, 2500/589824, 6000/262144, 7168/524288, 5000/2359296, 12000/1048576, 14700/2097152, 12288/1048576, 5000/2359296, 12000/1048576, 12288/1048576, 5000/2359296, 12000/1048576, 14000/2048000],\\nnonzero_percentages=[4.08%, 14.06%, 1.74%, 9.38%, 9.38%, 9.38%, 1.74%, 9.38%, 9.38%, 1.74%, 9.38%, 5.47%, 0.81%, 4.69%, 2.73%, 4.69%, 0.81%, 4.69%, 4.69%, 0.81%, 4.69%, 4.69%, 0.81%, 4.69%, 2.73%, 0.42%, 2.29%, 1.34%, 2.34%, 0.42%, 2.29%, 2.34%, 0.42%, 2.29%, 2.34%, 0.42%, 2.29%, 2.34%, 0.42%, 2.29%, 2.34%, 0.42%, 2.29%, 1.37%, 0.21%, 1.14%, 0.70%, 1.17%, 0.21%, 1.14%, 1.17%, 0.21%, 1.14%, 0.68%],\\ntotal_nonzero_params=247524/25502912 (0.97%),\\ntotal_CONV_nonzero_params=233524/23454912 (1.00%),\\nstep=0,\\nnum_rigl_steps=0,\\nignoring_linear_layers=False,\\nsparsity_distribution=erk,\\nITOP rate=0.0097,\\nconstant fan ins=[32, 9, 10, 6, 6, 24, 10, 6, 24, 10, 6, 14, 12, 6, 7, 24, 12, 6, 24, 12, 6, 24, 12, 6, 14, 25, 10, 10, 24, 25, 10, 24, 25, 10, 24, 25, 10, 24, 25, 10, 24, 25, 10, 14, 50, 20, 21, 24, 50, 20, 24, 50, 20, 14]\\nNeurons Ablated per layer = [52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 0, 0, 0, 28, 0, 0, 28, 0, 0, 28, 0, 0, 156, 424, 324, 0, 156, 424, 0, 156, 424, 0, 156, 424, 0, 156, 424, 0, 156, 424, 0, 412, 1448, 1348, 0, 412, 1448, 0, 412, 1448, 0]\\n)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9900, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.get_global_sparsity_from_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RigLScheduler(\\nlayers=54,\\nnonzero_params=[147/9408, 576/4096, 649/36864, 1560/16384, 1560/16384, 1536/16384, 649/36864, 1560/16384, 1536/16384, 649/36864, 1560/16384, 1792/32768, 1270/147456, 3120/65536, 3710/131072, 3072/65536, 1270/147456, 3120/65536, 3072/65536, 1270/147456, 3120/65536, 3072/65536, 1270/147456, 3120/65536, 3640/131072, 2520/589824, 6240/262144, 7490/524288, 6240/262144, 2520/589824, 6240/262144, 6240/262144, 2520/589824, 6240/262144, 6240/262144, 2520/589824, 6240/262144, 6240/262144, 2520/589824, 6240/262144, 6240/262144, 2520/589824, 6240/262144, 7420/524288, 5020/2359296, 12480/1048576, 14980/2097152, 12480/1048576, 5020/2359296, 12480/1048576, 12480/1048576, 5020/2359296, 12480/1048576, 14840/2048000],\\nnonzero_percentages=[1.56%, 14.06%, 1.76%, 9.52%, 9.52%, 9.38%, 1.76%, 9.52%, 9.38%, 1.76%, 9.52%, 5.47%, 0.86%, 4.76%, 2.83%, 4.69%, 0.86%, 4.76%, 4.69%, 0.86%, 4.76%, 4.69%, 0.86%, 4.76%, 2.78%, 0.43%, 2.38%, 1.43%, 2.38%, 0.43%, 2.38%, 2.38%, 0.43%, 2.38%, 2.38%, 0.43%, 2.38%, 2.38%, 0.43%, 2.38%, 2.38%, 0.43%, 2.38%, 1.42%, 0.21%, 1.19%, 0.71%, 1.19%, 0.21%, 1.19%, 1.19%, 0.21%, 1.19%, 0.72%],\\ntotal_nonzero_params=253850/25502912 (1.00%),\\ntotal_CONV_nonzero_params=239010/23454912 (1.02%),\\nstep=0,\\nnum_rigl_steps=0,\\nignoring_linear_layers=False,\\nsparsity_distribution=erk,\\nITOP rate=0.0100,\\nconstant fan ins=[147, 9, 59, 26, 26, 24, 59, 26, 24, 59, 26, 14, 127, 52, 53, 24, 127, 52, 24, 127, 52, 24, 127, 52, 26, 252, 104, 107, 26, 252, 104, 26, 252, 104, 26, 252, 104, 26, 252, 104, 26, 252, 104, 53, 502, 208, 214, 52, 502, 208, 52, 502, 208, 106]\\nNeurons Ablated per layer = [63, 0, 53, 196, 196, 0, 53, 196, 0, 53, 196, 0, 118, 452, 442, 0, 118, 452, 0, 118, 452, 0, 118, 452, 116, 246, 964, 954, 16, 246, 964, 16, 246, 964, 16, 246, 964, 16, 246, 964, 16, 246, 964, 372, 502, 1988, 1978, 272, 502, 1988, 272, 502, 1988, 860]\\n)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63,\n",
       " 0,\n",
       " 53,\n",
       " 196,\n",
       " 196,\n",
       " 0,\n",
       " 53,\n",
       " 196,\n",
       " 0,\n",
       " 53,\n",
       " 196,\n",
       " 0,\n",
       " 118,\n",
       " 452,\n",
       " 442,\n",
       " 0,\n",
       " 118,\n",
       " 452,\n",
       " 0,\n",
       " 118,\n",
       " 452,\n",
       " 0,\n",
       " 118,\n",
       " 452,\n",
       " 116,\n",
       " 246,\n",
       " 964,\n",
       " 954,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 372,\n",
       " 502,\n",
       " 1988,\n",
       " 1978,\n",
       " 272,\n",
       " 502,\n",
       " 1988,\n",
       " 272,\n",
       " 502,\n",
       " 1988,\n",
       " 860]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63,\n",
       " 0,\n",
       " 53,\n",
       " 196,\n",
       " 196,\n",
       " 0,\n",
       " 53,\n",
       " 196,\n",
       " 0,\n",
       " 53,\n",
       " 196,\n",
       " 0,\n",
       " 118,\n",
       " 452,\n",
       " 442,\n",
       " 0,\n",
       " 118,\n",
       " 452,\n",
       " 0,\n",
       " 118,\n",
       " 452,\n",
       " 0,\n",
       " 118,\n",
       " 452,\n",
       " 116,\n",
       " 246,\n",
       " 964,\n",
       " 954,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 16,\n",
       " 246,\n",
       " 964,\n",
       " 372,\n",
       " 502,\n",
       " 1988,\n",
       " 1978,\n",
       " 272,\n",
       " 502,\n",
       " 1988,\n",
       " 272,\n",
       " 502,\n",
       " 1988,\n",
       " 860]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_neurons_per_layer = pruner.inital_ablated_filters\n",
    "old_neurons_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0156, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[0][-1].sum() / pruner.backward_masks[0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0419701390045516"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-pruner.S[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rigl_torch.utils.rigl_utils import get_fan_in_tensor\n",
    "\n",
    "\n",
    "for idx, (m, n) in enumerate(list(zip(pruner.backward_masks, pruner.inital_ablated_filters))):\n",
    "    fan_in_tens = get_fan_in_tensor(m)\n",
    "    # print(fan_in_tens)\n",
    "    if m.shape[0] < n:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2048])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[53].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2048])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9580298609954484,\n",
       " 0.8452836889704899,\n",
       " 0.9822803541214066,\n",
       " 0.9041948997086495,\n",
       " 0.9041948997086495,\n",
       " 0.9041948997086495,\n",
       " 0.9822803541214066,\n",
       " 0.9041948997086495,\n",
       " 0.9041948997086495,\n",
       " 0.9822803541214066,\n",
       " 0.9041948997086495,\n",
       " 0.9425764460986625,\n",
       " 0.9913385313056129,\n",
       " 0.9522462155380069,\n",
       " 0.9713626058911724,\n",
       " 0.9522462155380069,\n",
       " 0.9913385313056129,\n",
       " 0.9522462155380069,\n",
       " 0.9522462155380069,\n",
       " 0.9913385313056129,\n",
       " 0.9522462155380069,\n",
       " 0.9522462155380069,\n",
       " 0.9913385313056129,\n",
       " 0.9522462155380069,\n",
       " 0.9713626058911724,\n",
       " 0.9957188542140338,\n",
       " 0.9761602991899241,\n",
       " 0.9856998986560465,\n",
       " 0.9761602991899241,\n",
       " 0.9957188542140338,\n",
       " 0.9761602991899241,\n",
       " 0.9761602991899241,\n",
       " 0.9957188542140338,\n",
       " 0.9761602991899241,\n",
       " 0.9761602991899241,\n",
       " 0.9957188542140338,\n",
       " 0.9761602991899241,\n",
       " 0.9761602991899241,\n",
       " 0.9957188542140338,\n",
       " 0.9761602991899241,\n",
       " 0.9761602991899241,\n",
       " 0.9957188542140338,\n",
       " 0.9761602991899241,\n",
       " 0.9856998986560465,\n",
       " 0.9978718242473238,\n",
       " 0.9880894474501921,\n",
       " 0.9928545982556383,\n",
       " 0.9880894474501921,\n",
       " 0.9978718242473238,\n",
       " 0.9880894474501921,\n",
       " 0.9880894474501921,\n",
       " 0.9978718242473238,\n",
       " 0.9880894474501921,\n",
       " 0.9927449951381855]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1152, 1152)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import calculate_fan_in_and_fan_out\n",
    "\n",
    "\n",
    "calculate_fan_in_and_fan_out(pruner.W[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = -2\n",
    "get_fan_in_after_ablation(pruner.W[idx], num_neurons_to_ablate=pruner.inital_ablated_filters[idx], sparsity=pruner.S[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 62, 0, 62, 62, 62, 62, 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1664, device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[idx].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[idx][1].any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 * (128-62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005818684895833333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 * (128-62) / pruner.W[idx].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9904, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_global_sparsity_from_masks(pruner) -> float:\n",
    "    total_els = 0\n",
    "    total_non_zero_els = 0\n",
    "    for w, m in list(zip(pruner.W, pruner.backward_masks)):\n",
    "        if m is None:\n",
    "            total_non_zero_els += w.numel()\n",
    "            total_els += w.numel()\n",
    "        else:\n",
    "            total_non_zero_els += m.sum()\n",
    "            total_els += w.numel()\n",
    "    return 1 - (total_non_zero_els / total_els)\n",
    "\n",
    "get_global_sparsity_from_masks(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9904, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_el = 0\n",
    "non_zero_els = 0\n",
    "for w, m,s in list(zip(pruner.W, pruner.backward_masks, pruner.S)):\n",
    "    total_el += m.numel()\n",
    "    non_zero_els += m.sum()\n",
    "1-(non_zero_els / total_el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9904, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.get_global_sparsity_from_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 62, 0, 62, 62, 62, 62, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[39m.\u001b[39;49mconcat([pruner\u001b[39m.\u001b[39;49mbackward_masks])\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "total_el = 0 \n",
    "non_zero_el = 0\n",
    "for m in pruner.backward_masks:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0151, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.get_global_sparsity_from_masks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RigLScheduler(\\nlayers=23,\\nnonzero_params=[85/432, 183/4608, 237/9216, 170/512, 237/9216, 237/9216, 237/9216, 237/9216, 345/18432, 454/36864, 332/2048, 454/36864, 454/36864, 454/36864, 454/36864, 670/73728, 886/147456, 656/8192, 886/147456, 886/147456, 886/147456, 886/147456, 467/1280],\\nnonzero_percentages=[19.68%, 3.97%, 2.57%, 33.20%, 2.57%, 2.57%, 2.57%, 2.57%, 1.87%, 1.23%, 16.21%, 1.23%, 1.23%, 1.23%, 1.23%, 0.91%, 0.60%, 8.01%, 0.60%, 0.60%, 0.60%, 0.60%, 36.48%],\\ntotal_nonzero_params=10793/1076912 (1.00%),\\ntotal_CONV_nonzero_params=10326/1075632 (0.96%),\\nstep=0,\\nnum_rigl_steps=0,\\nignoring_linear_layers=False,\\nsparsity_distribution=erk,\\nITOP rate=0.0100,\\n)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[432, 4608, 9216, 512, 9216, 9216, 9216, 9216, 18432, 36864, 2048, 36864, 36864, 36864, 36864, 73728, 147456, 8192, 147456, 147456, 147456, 147456, 1280]\n",
      "[85, 183, 237, 170, 237, 237, 237, 237, 345, 454, 332, 454, 454, 454, 454, 670, 886, 656, 886, 886, 886, 886, 467]\n",
      "10793\n",
      "1076912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010022174513795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_global_sparsity_from_masks(pruner) -> float:\n",
    "    total_els = [m.numel() for m in pruner.backward_masks]\n",
    "    print(total_els)\n",
    "    non_zero_els = [m.sum().item() for m in pruner.backward_masks]\n",
    "    print(non_zero_els)\n",
    "    print(sum(non_zero_els))\n",
    "    print(sum(total_els))\n",
    "    return sum(non_zero_els) / sum(total_els)\n",
    "\n",
    "get_global_sparsity_from_masks(pruner)\n",
    "\n",
    "#todo what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rigl_torch.utils.rigl_utils import calculate_fan_in_and_fan_out\n",
    "# @torch.no_grad()\n",
    "# def random_sparsify(pruner) -> None:\n",
    "#     \"\"\"Randomly sparsifies model to desired sparsity distribution with\n",
    "#     constant fan in.\n",
    "#     \"\"\"\n",
    "#     is_dist: bool = dist.is_initialized()\n",
    "#     pruner.backward_masks = []\n",
    "#     for idx, (w, num_neurons_to_ablate) in enumerate(\n",
    "#         list(zip(pruner.W, pruner.ablated_filters))\n",
    "#     ):\n",
    "#         # if sparsity is 0%, skip\n",
    "#         if pruner.S[idx] <= 0:\n",
    "#             pruner.backward_masks.append(None)\n",
    "#             continue\n",
    "\n",
    "#         dense_fan_in, _ = calculate_fan_in_and_fan_out(module=w)\n",
    "#         fan_in = get_fan_in_after_ablation(\n",
    "#             weight_tensor=w,\n",
    "#             num_neurons_to_ablate=num_neurons_to_ablate,\n",
    "#             sparsity=pruner.S[idx],\n",
    "#         )\n",
    "#         print(fan_in)\n",
    "#         print(dense_fan_in)\n",
    "#         # Number of connections to drop per filter\n",
    "#         s = dense_fan_in - fan_in\n",
    "#         print(f\"s is {s}\")\n",
    "#         perm = torch.concat(\n",
    "#             [\n",
    "#                 torch.randperm(fan_in).reshape(1, -1)\n",
    "#                 for _ in range(w.shape[0])\n",
    "#             ]\n",
    "#         )\n",
    "#         # Generate random perm of indices to mask per filter / neuron\n",
    "#         perm = perm[\n",
    "#             :, :s\n",
    "#         ]  # Drop s elements from n to achieve desired sparsity\n",
    "#         print(perm)\n",
    "#         print(f\"perm shape: {perm.shape}\")\n",
    "#         mask = torch.concat(\n",
    "#             [torch.ones(dense_fan_in).reshape(1, -1) for _ in range(w.shape[0])]\n",
    "#         )\n",
    "#         print(f\"mask shape: {mask.shape}\")\n",
    "#         for filter_idx in range(mask.shape[0]):  # TODO: vectorize?\n",
    "#             mask[filter_idx][perm[filter_idx]] = 0\n",
    "#         mask = mask.reshape(w.shape).to(device=w.device)\n",
    "#         # Ablate top n neurons according to filter sparsity criterion\n",
    "#         mask[num_neurons_to_ablate:] = False\n",
    "\n",
    "#         if is_dist:\n",
    "#             dist.broadcast(mask, 0)\n",
    "#         mask = mask.bool()\n",
    "#         w *= mask\n",
    "#         pruner.backward_masks.append(mask)\n",
    "#     return pruner\n",
    "\n",
    "# const_fan_pruner = random_sparsify(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 62, 0, 62, 62, 62, 62, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.inital_ablated_filters   # TODO: Make sure this matches below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _update_current_filter_ablation(pruner) -> None:\n",
    "    def get_num_ablated_filters(mask) -> int:\n",
    "        if mask is None:\n",
    "            return 0\n",
    "        else:\n",
    "            return torch.sum(\n",
    "                torch.stack([~filter.any() for filter in mask])\n",
    "            ).item()\n",
    "\n",
    "    ablated_filters = [\n",
    "        get_num_ablated_filters(filter) for filter in pruner.backward_masks\n",
    "    ]\n",
    "    return ablated_filters\n",
    "\n",
    "_update_current_filter_ablation(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9199324398812323"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 1])\n",
      "tensor(False, device='cuda:0')\n",
      "torch.Size([64, 1, 1])\n",
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pruner.backward_masks[-6]\n",
    "\n",
    "for filter in pruner.backward_masks[-6]:\n",
    "    if  ~filter.any():\n",
    "        print(filter.shape)\n",
    "        print(filter.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_filters = 0\n",
    "for f in mask:\n",
    "    if f.any():\n",
    "        non_zero_filters+=1\n",
    "non_zero_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21][0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0060, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21].sum() / pruner.backward_masks[21].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060073598943634066"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-pruner.S[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006944444444444444"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*128 / pruner.backward_masks[21].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147456"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006944444444444444"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*128 / 147456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007568359375"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18*62 / 147456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005997474747474747"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "456/76032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import calculate_fan_in_and_fan_out\n",
    "import math\n",
    "idx=21\n",
    "weight_tensor = pruner.W[idx]\n",
    "num_neurons_to_ablate = pruner.ablated_filters[idx]\n",
    "sparsity = pruner.S[idx]\n",
    "active_neurons = weight_tensor.shape[0] - num_neurons_to_ablate\n",
    "print(active_neurons)\n",
    "remaining_non_zero_elements = math.floor(weight_tensor.numel() * (1 - sparsity))\n",
    "print(remaining_non_zero_elements)\n",
    "remaining_non_zero_elements // active_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.ablated_filters[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970987955729167"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(6.9*62 / weight_tensor.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939926401056366"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002685546875"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*66 / weight_tensor.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060073598943634066"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_sparsity(mask): \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030975449455311315"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dense_fan_in * (pruner.W[21].shape[0]-62) * (1-pruner.S[21])) / pruner.W[21][:].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[21][62:].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456.75158748823856"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dense_fan_in * (pruner.W[21].shape[0]-62) * (1-pruner.S[21])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fan_in_after_ablation(\n",
    "    weight_tensor = pruner.W[21],\n",
    "    num_neurons_to_ablate=62,\n",
    "    sparsity=pruner.S[21]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71424"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_els * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0060, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[21].sum() / pruner.backward_masks[21].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060073598943634066"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-pruner.S[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008680555555555556\n",
      "15\n",
      "0.005208333333333333\n",
      "16\n",
      "0.008680555555555556\n",
      "17\n",
      "0.005208333333333333\n",
      "18\n",
      "0.005208333333333333\n",
      "19\n",
      "0.005208333333333333\n",
      "20\n",
      "0.005208333333333333\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for idx, (w,s) in enumerate(list(zip(pruner.W, pruner.S))):\n",
    "    if s is None: \n",
    "        continue\n",
    "    unadjusted_fan_in = w.shape[1]*math.prod(w.shape[2:])\n",
    "    sparse_fan_in = int( (1-s) * unadjusted_fan_in)\n",
    "    out_channels = w.shape[1]\n",
    "    receptive_field_size=9\n",
    "    unadjusted_filter_sparsity = sparse_fan_in / (out_channels * receptive_field_size)\n",
    "    if unadjusted_filter_sparsity < 0.01:\n",
    "        print(unadjusted_filter_sparsity)\n",
    "        print(idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.ablated_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 27])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import calculate_fan_in_and_fan_out\n",
    "idx=0\n",
    "\n",
    "w = pruner.W[idx]\n",
    "fan_in, fan_out = calculate_fan_in_and_fan_out(w)\n",
    "s = int(fan_in * pruner.S[idx])\n",
    "perm = torch.concat(\n",
    "    [\n",
    "        torch.randperm(fan_in).reshape(1, -1)\n",
    "        for i in range(w.shape[0])\n",
    "    ]\n",
    ")\n",
    "perm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8043404410996132"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2222222222222222"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(27-21)/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 21])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm = perm[\n",
    ":, :s\n",
    "]  # Drop s elements from n to achieve desired sparsity\n",
    "perm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.prod(w.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 3, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8043404410996132,\n",
       " 0.9603789393226717,\n",
       " 0.9743196828943242,\n",
       " 0.6698244943555973,\n",
       " 0.9743196828943242,\n",
       " 0.9743196828943242,\n",
       " 0.9743196828943242,\n",
       " 0.9743196828943242,\n",
       " 0.9812900546801505,\n",
       " 0.9877101339565695,\n",
       " 0.8382140022342427,\n",
       " 0.9877101339565695,\n",
       " 0.9877101339565695,\n",
       " 0.9877101339565695,\n",
       " 0.9877101339565695,\n",
       " 0.9909201735947789,\n",
       " 0.9939926401056366,\n",
       " 0.9199324398812323,\n",
       " 0.9939926401056366,\n",
       " 0.9939926401056366,\n",
       " 0.9939926401056366,\n",
       " 0.9939926401056366,\n",
       " 0.6354862417685794]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = model.get_submodule(\"conv1\")\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 144)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init._calculate_fan_in_and_fan_out(conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "144/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in pruner.backward_masks:\n",
    "    if m is None:\n",
    "        continue\n",
    "    else:\n",
    "        break\n",
    "        print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9603789393226717"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pruner.backward_masks[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939926401056366"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruner.backward_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939926401056366"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9940, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - ( m.sum() / m.numel() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_abalation_mask = torch.ones(size=m.shape, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939926401056366"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0060073598943634066"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-pruner.S[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006008572149767133\n"
     ]
    }
   ],
   "source": [
    "def get_filter_s(filter) -> float:\n",
    "    return (filter.sum() / filter.numel()).item()\n",
    "\n",
    "filter_sparsities = list(map(get_filter_s, m))\n",
    "avg_filter_s = sum(filter_sparsities)/len(filter_sparsities)\n",
    "if avg_filter_s < 0.1:\n",
    "    print(avg_filter_s)\n",
    "m[0].numel()\n",
    "num_filters = m.numel()\n",
    "# m.shape[0] * m[0].numel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: \n",
      "0.196759263984859\n",
      "0.08629842102527618\n",
      "Layer 1: \n",
      "0.039713542646495625\n",
      "0.013802867382764816\n",
      "Layer 2: \n",
      "0.025716146221384406\n",
      "0.008679855614900589\n",
      "Layer 3: \n",
      "0.33203125\n",
      "0.1387929469347\n",
      "Layer 4: \n",
      "0.025716146228660364\n",
      "0.008266767486929893\n",
      "Layer 5: \n",
      "0.025716146221384406\n",
      "0.009327770210802555\n",
      "Layer 6: \n",
      "0.025716146337799728\n",
      "0.00817213486880064\n",
      "Layer 7: \n",
      "0.02571614623593632\n",
      "0.011185742914676666\n",
      "Layer 8: \n",
      "0.018717448412644444\n",
      "0.00805725622922182\n",
      "Layer 9: \n",
      "0.012315538364418899\n",
      "0.004985100124031305\n",
      "Layer 10: \n",
      "0.162109375\n",
      "0.06678630411624908\n",
      "Layer 11: \n",
      "0.012315538457187358\n",
      "0.004511543083935976\n",
      "Layer 12: \n",
      "0.01231553842080757\n",
      "0.0046781389974057674\n",
      "Layer 13: \n",
      "0.012315538442635443\n",
      "0.005127036478370428\n",
      "Layer 14: \n",
      "0.012315538398979697\n",
      "0.0044474611058831215\n",
      "Layer 15: \n",
      "0.009087456804991234\n",
      "0.003371547209098935\n",
      "Layer 16: \n",
      "0.00600857215204087\n",
      "0.002363148145377636\n",
      "Layer 17: \n",
      "0.080078125\n",
      "0.033391211181879044\n",
      "Layer 18: \n",
      "0.0060085721570430906\n",
      "0.002108385320752859\n",
      "Layer 19: \n",
      "0.0060085721570430906\n",
      "0.002471152227371931\n",
      "Layer 20: \n",
      "0.006008572149767133\n",
      "0.0019806979689747095\n",
      "Layer 21: \n",
      "0.006008572162045311\n",
      "0.0021938891150057316\n",
      "Layer 22: \n",
      "0.36484375\n",
      "0.050771232694387436\n"
     ]
    }
   ],
   "source": [
    "def get_filters_to_prune(mask):\n",
    "    m = mask\n",
    "    kernel_size = m.shape[-2] * m.shape[-1]\n",
    "    in_channels = m.shape[0]\n",
    "    out_channels = m.shape[1]\n",
    "    avg_filter_s = []\n",
    "    for filter in m:\n",
    "        avg_filter_s.append((filter.sum() / filter.numel()).item())\n",
    "    print(sum(avg_filter_s) / len(avg_filter_s))\n",
    "    print(torch.std(torch.tensor(avg_filter_s)).item())\n",
    "        \n",
    "for idx, mask in enumerate(pruner.backward_masks):\n",
    "    # if idx != 20:\n",
    "    #     continue\n",
    "    print(f\"Layer {idx}: \")\n",
    "    if mask is None:\n",
    "        print( \"NONE\")\n",
    "    else:\n",
    "        get_filters_to_prune(mask)\n",
    "        \n",
    "\n",
    "# filter_abalation_mask = torch.ones(shape=mask.shape, dtype=torch.bool)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 3, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/user/condensed-sparsity')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Checkpoint.parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user/condensed-sparsity/artifacts/checkpoints'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.paths.checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/20221009_2d4v4ezc/checkpoint.pt.tar...\n"
     ]
    }
   ],
   "source": [
    "# 99% sparse runs\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "const_fan_in_run_id = \"2d4v4ezc\"\n",
    "vanilla_rigl_run_id = \"xhnqnd6c\"\n",
    "\n",
    "const_fan_ckp = Checkpoint.load_last_checkpoint(run_id=const_fan_in_run_id, parent_dir=cfg.paths.checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/20221011_xhnqnd6c/checkpoint.pt.tar...\n"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_ckp = Checkpoint.load_last_checkpoint(run_id=vanilla_rigl_run_id, parent_dir=cfg.paths.checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_fan_masks =const_fan_ckp.pruner[\"backward_masks\"]\n",
    "vanilla_rigl_masks =vanilla_rigl_ckp.pruner[\"backward_masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9957, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - ( vanilla_rigl_masks[35].sum() / vanilla_rigl_masks[35].numel() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2421875\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "zeros = 0\n",
    "for filter in vanilla_rigl_masks[35]:\n",
    "    total+=1\n",
    "    if filter.any():\n",
    "        # print(\"Not zero!\")\n",
    "        continue\n",
    "    else:\n",
    "        # print(\"zero\")\n",
    "        zeros+=1\n",
    "print(zeros/total)\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.8672, device='cuda:0')\n",
      "tensor(10.5944, device='cuda:0')\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "non_zero = []\n",
    "max = 0\n",
    "for filter in vanilla_rigl_masks[35]:\n",
    "    non_zero.append(filter.sum())\n",
    "    if max < filter.sum().item():\n",
    "        max = filter.sum().item()\n",
    "non_zero = torch.stack(non_zero).type(torch.float32)\n",
    "print(torch.mean(non_zero))\n",
    "print(torch.std(non_zero))\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0043, device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / vanilla_rigl_masks[35].numel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.390625"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/256*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00390625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9/(256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9957, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - ( vanilla_rigl_masks[35].sum() / vanilla_rigl_masks[35].numel() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9965277777777777"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "46/(256*3*3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4340277777777778"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10/(256*3*3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fan_in' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m thres \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m n \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m\u001b[39m/\u001b[39mfan_in\u001b[39m*\u001b[39m()\n\u001b[1;32m      3\u001b[0m fan_in\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m      4\u001b[0m fan_in\u001b[39m/\u001b[39m((\u001b[39m256\u001b[39m\u001b[39m-\u001b[39mn)\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fan_in' is not defined"
     ]
    }
   ],
   "source": [
    "thres = 0.5\n",
    "n = 0.5/100/fan_in*()\n",
    "fan_in=10\n",
    "fan_in/((256-n)*3*3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "256-10*100/(0.5*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def get_filters_to_prune(mask):\n",
    "    m = mask\n",
    "    kernel_size = m.shape[-2] * m.shape[-1]\n",
    "    in_channels = m.shape[0]\n",
    "    out_channels = m.shape[1]\n",
    "    mask_sparsity = 1 - (mask.sum() / mask.numel()).item()\n",
    "    fan_in = mask[0].sum()\n",
    "    target_filter_sparsity_percent = 0.5\n",
    "    return out_channels - fan_in * 100 / (target_filter_sparsity_percent * kernel_size)\n",
    "    avg_filter_s = []\n",
    "    for filter in m:\n",
    "        avg_filter_s.append((filter.sum() / filter.numel()).item())\n",
    "    print(sum(avg_filter_s) / len(avg_filter_s))\n",
    "    print(torch.std(torch.tensor(avg_filter_s)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "fan_in=10\n",
    "n=33.78\n",
    "fan_in/((256-n)*3*3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / vanilla_rigl_masks[35].numel()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / ((256-62)*256*3*3) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / ((256-0)*256*3*3) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "62*256*3*3 / (256*256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "non_zero.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "(non_zero>9).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "194/256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "62*256*3*3 / (256*256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / ((256-62)*256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_masks[35].sum() / (256*256*3*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_ckp.pruner[\"S\"][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "1-vanilla_rigl_ckp.pruner[\"S\"][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Compare this with model weights to close loop on investigating 00 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vanilla_rigl_ckp.pruner.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for idx, f in enumerate(vanilla_rigl_masks[35]):\n",
    "    print(1 - (f.sum() / f.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "10/(256*9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "const_fan_masks[35][0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "for idx, mask in enumerate(const_fan_masks):\n",
    "    if idx != 35:\n",
    "        continue\n",
    "    print(f\"Layer {idx}: \")\n",
    "    if mask is None:\n",
    "        print( \"NONE\")\n",
    "    else:\n",
    "        get_filters_to_prune(mask)\n",
    "        \n",
    "for idx, mask in enumerate(vanilla_rigl_masks):\n",
    "    if idx != 35:\n",
    "        continue\n",
    "    print(f\"Layer {idx}: \")\n",
    "    if mask is None:\n",
    "        print( \"NONE\")\n",
    "    else:\n",
    "        get_filters_to_prune(mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 16 2021, 14:20:20) \n[GCC 9.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "832f61c19470ea428b2cef022cd1fe1aa91b00b83b99363aeeaecf593912d607"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

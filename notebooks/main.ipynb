{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Config for Vit-B-16\\n    return _vision_transformer(\\n        patch_size=16,\\n        num_layers=12,\\n        num_heads=12,\\n        hidden_dim=768,  # same as embed dim in MHA module\\n        mlp_dim=3072,\\n        weights=weights,\\n        progress=progress,\\n        **kwargs,\\n    )\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Config for Vit-B-16\n",
    "    return _vision_transformer(\n",
    "        patch_size=16,\n",
    "        num_layers=12,\n",
    "        num_heads=12,\n",
    "        hidden_dim=768,  # same as embed dim in MHA module\n",
    "        mlp_dim=3072,\n",
    "        weights=weights,\n",
    "        progress=progress,\n",
    "        **kwargs,\n",
    "    )\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint, get_checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "from rigl_torch.utils.logging_utils import get_logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_large\n",
      "/home/mike/condensed-sparsity\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "    cfg = compose(\n",
    "        \"config.yaml\",\n",
    "        overrides=[\n",
    "            \"compute.distributed=False\",\n",
    "            \"dataset=imagenet\",\n",
    "            \"model=mobilenet_large\",\n",
    "            \"rigl.dense_allocation=0.1\",\n",
    "            # \"experiment.run_id=nrblbn15\",\n",
    "            f\"training.batch_size={batch_size}\",\n",
    "            # \"compute.no_cuda=True\",\n",
    "            # \"training.test_batch_size=10\"\n",
    "            # # \"model=skinny_resnet18\",\n",
    "            # \"rigl.dense_allocation=0.01\",\n",
    "            # \"rigl.delta=2\",\n",
    "            # \"rigl.grad_accumulation_n=1\"\n",
    "            ])\n",
    "dotenv.load_dotenv(\"../.env\", override=True)\n",
    "os.environ[\"IMAGE_NET_PATH\"]\n",
    "print(cfg.model.name)\n",
    "print(cfg.paths.base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_shape_hook_wrapper(name, mod):\n",
    "    def forward_shape_print_name_and_shape(mod, input, output):\n",
    "        out_str = f\"{name} ({type(mod)}): \"\n",
    "        if isinstance(input, torch.Tensor):\n",
    "            out_str+= f\"input: {input.shape} \"\n",
    "        else:\n",
    "            # out_str += f\"input: tuple of len {len(input)} and types {[type(i) for i in input]} \"\n",
    "            out_str += f\"input: {input[0].shape} \"\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            out_str+= f\"output: {output.shape}\"\n",
    "        else:\n",
    "            # out_str += f\"output: tuple of len {len(output)} and types {[type(o) for o in output] \"\n",
    "            out_str += f\"output: {output[0].shape}\"\n",
    "        print(out_str)\n",
    "    return mod.register_forward_hook(forward_shape_print_name_and_shape)\n",
    "\n",
    "def register_name_shape_hook(model):\n",
    "    handles = []\n",
    "    for name, mod in model.named_modules():\n",
    "        handles.append(name_shape_hook_wrapper(name, mod))\n",
    "    return handles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinit_ablated_neuron_count(pruner: RigLConstFanScheduler) -> RigLConstFanScheduler:\n",
    "    pruner.dynamically_ablated_neuron_idx = [\n",
    "            [x for x in list(range(len(layer))) if x not in layer]\n",
    "            for layer in pruner.active_neurons\n",
    "        ]\n",
    "    return pruner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # checkpoint_dir=pathlib.Path(\"../artifacts/checkpoints/20230511_361mldkb\")  # 80% sparse\n",
    "# # checkpoint_dir=pathlib.Path(\"../artifacts/checkpoints/20230511_2sn0e1sy\")  # 90% sparse\n",
    "# # checkpoint_dir=pathlib.Path(\"../artifacts/checkpoints/20231001_1pvth6zw\")  # 70% sparse w/ dense mha\n",
    "# # checkpoint_dir = pathlib.Path(\"../artifacts/checkpoints/20230601_nrblbn15\")\n",
    "\n",
    "\n",
    "# checkpoint_dir=pathlib.Path(\"../artifacts/checkpoints/20231115_2kqt8l8e\")  # large mobile net 1 epoch\n",
    "# checkpoint = Checkpoint.load_best_checkpoint(checkpoint_dir=checkpoint_dir)\n",
    "# logger = get_logger(cfg.paths.logs, __name__, 0)\n",
    "# # checkpoint = get_checkpoint(cfg, rank=0, logger=logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl', 'use_tf32': False}\n",
      "loading to device rank: 0\n",
      "/home/mike/condensed-sparsity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] 2023-11-15 14:14:07,251 G- /home/mike/condensed-sparsity/src/rigl_torch/models/model_factory.py - load_model (28) : Loading model mobilenet_large/imagenet using <function get_mobilenet_large at 0x7f08663af250> with args: () and kwargs: {'diet': None}\n",
      "[INFO] 2023-11-15 14:14:07,355 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 1 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,364 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 2 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,367 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 4 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,370 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 7 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,374 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 31 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,377 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 34 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,380 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 28 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,383 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 25 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,390 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 37 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,398 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 42 set to 0.0\n",
      "[INFO] 2023-11-15 14:14:07,404 G- /home/mike/condensed-sparsity/src/rigl_torch/rigl_scheduler.py - _erk_sparsity_dist (496) : Sparsity of layer at index 3 set to 0.0\n"
     ]
    }
   ],
   "source": [
    "rank=0\n",
    "checkpoint=None\n",
    "if checkpoint is not None:\n",
    "    run_id = checkpoint.run_id\n",
    "    optimizer_state = checkpoint.optimizer\n",
    "    scheduler_state = checkpoint.scheduler\n",
    "    pruner_state = checkpoint.pruner\n",
    "    model_state = checkpoint.model\n",
    "    cfg = checkpoint.cfg\n",
    "else:\n",
    "    run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "if \"diet\" not in cfg.rigl:\n",
    "    with omegaconf.open_dict(cfg):\n",
    "        cfg.rigl.diet = None\n",
    "if \"keep_first_layer_dense\" not in cfg.rigl:\n",
    "    with omegaconf.open_dict(cfg):\n",
    "        cfg.rigl.keep_first_layer_dense = False\n",
    "if \"no_ablation_module_names\" not in cfg.model:\n",
    "    with omegaconf.open_dict(cfg):\n",
    "        cfg.model.no_ablation_module_names=None\n",
    "print(cfg.compute)\n",
    "cfg.compute.distributed=False\n",
    "# cfg.compute.no_cuda=True\n",
    "    \n",
    "pl.seed_everything(cfg.training.seed)\n",
    "use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "# if not use_cuda:\n",
    "#     raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "#     logger.warning(\n",
    "#         \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "#         \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "#     )\n",
    "\n",
    "if cfg.compute.distributed and use_cuda:\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "else:\n",
    "    print(f\"loading to device rank: {rank}\")\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "if not use_cuda:\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(cfg.paths.base)\n",
    "cfg.training.batch_size=batch_size\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "model = ModelFactory.load_model(\n",
    "    model=cfg.model.name, dataset=cfg.dataset.name, diet=cfg.rigl.diet\n",
    ")\n",
    "model.to(device)\n",
    "if cfg.compute.distributed:\n",
    "    model = DistributedDataParallel(model, device_ids=[rank])\n",
    "if model_state is not None:\n",
    "    try:\n",
    "        model.load_state_dict(model_state)\n",
    "    except RuntimeError:\n",
    "        model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "        model.load_state_dict(model_state)\n",
    "        \n",
    "optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "pruner = None\n",
    "if cfg.rigl.dense_allocation is not None:\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        if cfg.model.name == \"skinny_resnet18\":\n",
    "            dense_allocation = (\n",
    "                cfg.rigl.dense_allocation * cfg.model.sparsity_scale_factor\n",
    "            )\n",
    "            print(\n",
    "                f\"Scaling {cfg.rigl.dense_allocation} by \"\n",
    "                f\"{cfg.model.sparsity_scale_factor:.2f} for SkinnyResNet18 \"\n",
    "                f\"New Dense Alloc == {dense_allocation:.6f}\"\n",
    "            )\n",
    "        else:\n",
    "            dense_allocation = cfg.rigl.dense_allocation\n",
    "        T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "        if cfg.rigl.const_fan_in:\n",
    "            rigl_scheduler = RigLConstFanScheduler\n",
    "        else:\n",
    "            rigl_scheduler = RigLScheduler\n",
    "        pruner = rigl_scheduler(\n",
    "            model,\n",
    "            optimizer,\n",
    "            dense_allocation=dense_allocation,\n",
    "            alpha=cfg.rigl.alpha,\n",
    "            delta=cfg.rigl.delta,\n",
    "            static_topo=cfg.rigl.static_topo,\n",
    "            T_end=T_end,\n",
    "            ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "            ignore_mha_layers=cfg.rigl.ignore_mha_layers,\n",
    "            grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "            sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "            erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "            state_dict=pruner_state,\n",
    "            filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "            static_ablation=cfg.rigl.static_ablation,\n",
    "            dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "            min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "            use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "            init_method_str=cfg.rigl.init_method_str,\n",
    "            use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "            keep_first_layer_dense=cfg.rigl.keep_first_layer_dense,\n",
    "            initialize_grown_weights=cfg.rigl.initialize_grown_weights,\n",
    "            no_ablation_module_names=cfg.model.no_ablation_module_names,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigLScheduler(\n",
      "layers=64,\n",
      "nonzero_params=[416/432, 144/144, 256/256, 1024/1024, 576/576, 1512/1536, 1656/1728, 648/648, 1656/1728, 1656/1728, 1368/1800, 1656/1728, 1656/1728, 1920/2880, 2640/4800, 2160/3000, 2592/3840, 2520/3840, 2720/4800, 2640/4800, 2160/3000, 2592/3840, 2520/3840, 2720/4800, 4560/9600, 2160/2160, 5440/19200, 4600/16000, 1800/1800, 4720/16000, 4416/14720, 1656/1656, 4480/14720, 4416/14720, 1656/1656, 4480/14720, 9120/38400, 4320/4320, 10080/57600, 10080/57600, 9968/53760, 12768/75264, 6048/6048, 14112/112896, 14112/112896, 13216/75264, 12768/75264, 11424/16800, 14112/112896, 14112/112896, 14080/107520, 18240/153600, 16320/24000, 20160/230400, 20160/230400, 18880/153600, 18240/153600, 16320/24000, 20160/230400, 20160/230400, 18880/153600, 18240/153600, 37120/1228800, 38000/1280000],\n",
      "nonzero_percentages=[96.30%, 100.00%, 100.00%, 100.00%, 100.00%, 98.44%, 95.83%, 100.00%, 95.83%, 95.83%, 76.00%, 95.83%, 95.83%, 66.67%, 55.00%, 72.00%, 67.50%, 65.62%, 56.67%, 55.00%, 72.00%, 67.50%, 65.62%, 56.67%, 47.50%, 100.00%, 28.33%, 28.75%, 100.00%, 29.50%, 30.00%, 100.00%, 30.43%, 30.00%, 100.00%, 30.43%, 23.75%, 100.00%, 17.50%, 17.50%, 18.54%, 16.96%, 100.00%, 12.50%, 12.50%, 17.56%, 16.96%, 68.00%, 12.50%, 12.50%, 13.10%, 11.88%, 68.00%, 8.75%, 8.75%, 12.29%, 11.88%, 68.00%, 8.75%, 8.75%, 12.29%, 11.88%, 3.02%, 2.97%],\n",
      "total_nonzero_params=536992/5451272 (9.85%),\n",
      "total_CONV_nonzero_params=461872/2942472 (15.70%),\n",
      "step=0,\n",
      "num_rigl_steps=0,\n",
      "ignoring_linear_layers=False,\n",
      "sparsity_distribution=erk,\n",
      "ITOP rate=0.0985,\n",
      "Active Neuron Count=[(16, 16), (16, 16), (16, 16), (64, 64), (64, 64), (24, 24), (72, 72), (72, 72), (24, 24), (72, 72), (72, 72), (24, 24), (72, 72), (40, 40), (120, 120), (120, 120), (32, 32), (120, 120), (40, 40), (120, 120), (120, 120), (32, 32), (120, 120), (40, 40), (240, 240), (240, 240), (80, 80), (200, 200), (200, 200), (80, 80), (184, 184), (184, 184), (80, 80), (184, 184), (184, 184), (80, 80), (480, 480), (480, 480), (120, 120), (480, 480), (112, 112), (672, 672), (672, 672), (168, 168), (672, 672), (112, 112), (672, 672), (672, 672), (168, 168), (672, 672), (160, 160), (960, 960), (960, 960), (240, 240), (960, 960), (160, 160), (960, 960), (960, 960), (240, 240), (960, 960), (160, 160), (960, 960), (1280, 1280), (1000, 1000)],\n",
      "constant fan ins=[26, 9, 16, 16, 9, 63, 23, 9, 69, 23, 19, 69, 23, 48, 22, 18, 81, 21, 68, 22, 18, 81, 21, 68, 19, 9, 68, 23, 9, 59, 24, 9, 56, 24, 9, 56, 19, 9, 84, 21, 89, 19, 9, 84, 21, 118, 19, 17, 84, 21, 88, 19, 17, 84, 21, 118, 19, 17, 84, 21, 118, 19, 29, 38]\n",
      "Neurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Neurons Dynamically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pruner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from condensed_sparsity.condensed_linear import CondensedLinearFineGrained, CondensedLinearFineGrainedSparseOp, CondensedLinearStructured, structured_condensed_conv2d_factory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x,y in train_loader:\n",
    "    break\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.fx as fx\n",
    "g = fx.symbolic_trace(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape_prop = fx.passes.shape_prop.ShapeProp(g)\n",
    "# shape_prop.propagate(x.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g.graph.print_tabular()\n",
    "# # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(size=(1,2,3))\n",
    "t.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape[:-1]+(3,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from condensed_sparsity.condensed_linear import _get_active_neuron_idx, _default_weight_getter\n",
    "from typing import Callable, Union\n",
    "\n",
    "class ZeroChannelPadder(nn.Module):\n",
    "    def __init__(self, dense_mod: nn.Module, condensed_mod_converter: Union[nn.Module, Callable], weight_getter: Callable):\n",
    "        super().__init__()\n",
    "        with torch.no_grad():\n",
    "            dense_weight = weight_getter(dense_mod)\n",
    "            self.out_channels = dense_weight.shape[0]\n",
    "            active_neuron_idx = _get_active_neuron_idx(dense_weight)\n",
    "            self.active_neurons = torch.argwhere(active_neuron_idx).flatten()\n",
    "            self.condensed_mod = condensed_mod_converter(dense_mod)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        out_condensed = self.condensed_mod(input)  # will be of shape batch_size x condensed out channels\n",
    "        with torch.no_grad():\n",
    "            # target = torch.zeros(size=(input.shape[0], self.out_channels), dtype=out_condensed.dtype)  # Needs to be of shape bath size x out_channels\n",
    "            target = torch.zeros(size=(input.shape[:-1]+(self.out_channels,)), dtype=out_condensed.dtype)  # Needs to be of shape ... x out_channels\n",
    "            return target.index_add(dim=out_condensed.dim()-1, index=self.active_neurons, source=out_condensed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,    0,    0,  ..., 3071, 3071, 3071])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.weight.nonzero()[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3072, -1]' is invalid for input of size 235930",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/mike/condensed-sparsity/notebooks/main.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhector/home/mike/condensed-sparsity/notebooks/main.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhector/home/mike/condensed-sparsity/notebooks/main.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     mod\u001b[39m.\u001b[39mbias[inactive_neurons]\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhector/home/mike/condensed-sparsity/notebooks/main.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m zero_pad \u001b[39m=\u001b[39m ZeroChannelPadder(mod, CondensedLinearFineGrained, _default_weight_getter)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhector/home/mike/condensed-sparsity/notebooks/main.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m con_mod \u001b[39m=\u001b[39m CondensedLinearFineGrained(mod)\n",
      "\u001b[1;32m/home/mike/condensed-sparsity/notebooks/main.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhector/home/mike/condensed-sparsity/notebooks/main.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m active_neuron_idx \u001b[39m=\u001b[39m _get_active_neuron_idx(dense_weight)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhector/home/mike/condensed-sparsity/notebooks/main.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_neurons \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margwhere(active_neuron_idx)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhector/home/mike/condensed-sparsity/notebooks/main.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcondensed_mod \u001b[39m=\u001b[39m condensed_mod_converter(dense_mod)\n",
      "File \u001b[0;32m~/condensed-sparsity/src/condensed_sparsity/condensed_linear.py:180\u001b[0m, in \u001b[0;36mCondensedLinearFineGrained.__init__\u001b[0;34m(self, module, dtype)\u001b[0m\n\u001b[1;32m    176\u001b[0m fine_grained_idx \u001b[39m=\u001b[39m (module\u001b[39m.\u001b[39mweight[active_neuron_idx] \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mto(\n\u001b[1;32m    177\u001b[0m     torch\u001b[39m.\u001b[39mbool\n\u001b[1;32m    178\u001b[0m )\n\u001b[1;32m    179\u001b[0m _, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_mask \u001b[39m=\u001b[39m fine_grained_idx\u001b[39m.\u001b[39mnonzero(as_tuple\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_mask\u001b[39m.\u001b[39;49mreshape(\n\u001b[1;32m    181\u001b[0m     shape\u001b[39m=\u001b[39;49m(module\u001b[39m.\u001b[39;49mweight[active_neuron_idx]\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    182\u001b[0m )\n\u001b[1;32m    183\u001b[0m weight \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mweight[active_neuron_idx]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mtype(dtype)\n\u001b[1;32m    184\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcondensed_weight \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mParameter(\n\u001b[1;32m    185\u001b[0m     torch\u001b[39m.\u001b[39mclone(\n\u001b[1;32m    186\u001b[0m         weight[fine_grained_idx]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    192\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3072, -1]' is invalid for input of size 235930"
     ]
    }
   ],
   "source": [
    "mod = model.get_submodule(\"encoder.layers.encoder_layer_11.mlp.0\").to(\"cpu\") # with full dim\n",
    "inactive_neurons = torch.argwhere(_get_active_neuron_idx(mod.weight)==False).flatten()\n",
    "with torch.no_grad():\n",
    "    mod.bias[inactive_neurons]=0\n",
    "zero_pad = ZeroChannelPadder(mod, CondensedLinearFineGrained, _default_weight_getter)\n",
    "con_mod = CondensedLinearFineGrained(mod)\n",
    "\n",
    "# zeroed_bias = torch.clone(mod.bias)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.80013020833333"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "235930/3072\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(size=(512,768))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2399,  0.0769,  0.1053,  ...,  0.0761,  0.0580, -0.1101],\n",
       "        [-0.3469,  0.1174, -0.2479,  ...,  0.0083, -0.1598,  0.1447],\n",
       "        [-0.6197,  0.1537, -0.3976,  ..., -0.0141, -0.0801,  0.2131],\n",
       "        ...,\n",
       "        [-0.3389, -0.0772, -0.2537,  ..., -0.2824,  0.0641,  0.3217],\n",
       "        [-0.6175, -0.1593, -0.1333,  ...,  0.1820, -0.0386,  0.2598],\n",
       "        [-0.6039,  0.1758, -0.0850,  ...,  0.2269,  0.0991,  0.2677]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(input)[:, zero_pad.active_neurons]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2399,  0.0769,  0.1053,  ...,  0.0761,  0.0580, -0.1101],\n",
       "        [-0.3469,  0.1174, -0.2479,  ...,  0.0083, -0.1598,  0.1447],\n",
       "        [-0.6197,  0.1537, -0.3976,  ..., -0.0141, -0.0801,  0.2131],\n",
       "        ...,\n",
       "        [-0.3389, -0.0772, -0.2537,  ..., -0.2824,  0.0641,  0.3217],\n",
       "        [-0.6175, -0.1593, -0.1333,  ...,  0.1820, -0.0386,  0.2598],\n",
       "        [-0.6039,  0.1758, -0.0850,  ...,  0.2269,  0.0991,  0.2677]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mod(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_pad(input).allclose(mod(input), atol=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3072])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_pad(input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3072])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.linear import NonDynamicallyQuantizableLinear\n",
    "__TARGET_TYPES = [nn.Linear]\n",
    "__EXCLUDED_NAMES = [\"in_proj_weight\"]\n",
    "\n",
    "def convert_condensed_linear(module, condensed_mod_converter):\n",
    "    # Based on convert_sync_batchnorm\n",
    "    module_output = module\n",
    "    if type(module) in __TARGET_TYPES:\n",
    "        # Introspection to determine subclass\n",
    "        module_output = condensed_mod_converter(module)\n",
    "        # TODO: Move cls method to each condensed class\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(name, convert_condensed_linear(child, condensed_mod_converter))  # noqa\n",
    "    del module\n",
    "    return module_output\n",
    "\n",
    "from functools import partial\n",
    "converter = partial(ZeroChannelPadder, condensed_mod_converter=CondensedLinearFineGrained, weight_getter=_default_weight_getter)\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "condensed_model = convert_condensed_linear(copy.deepcopy(model.to(\"cpu\")), converter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.to(\"cpu\")(x.to(\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = condensed_model.to(\"cpu\")(x.to(\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_mod = condensed_model.encoder.layers.encoder_layer_0.mlp.get_submodule('0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.9 ms ± 5.08 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.19 s ± 45.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "condensed_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-18 21:16:55,273] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n",
      "[2023-10-18 21:16:56,157] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)\n",
      "[2023-10-18 21:16:56,171] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-10-18 21:17:02,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0\n",
      "[2023-10-18 21:17:17,215] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0\n",
      "[2023-10-18 21:17:17,218] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n"
     ]
    }
   ],
   "source": [
    "dense_jit = torch.compile(model)\n",
    "_ = dense_jit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 ms ± 5.3 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "dense_jit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-18 21:17:36,984] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n",
      "[2023-10-18 21:17:37,840] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)\n",
      "[2023-10-18 21:17:37,866] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-10-18 21:17:40,298] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1\n",
      "[2023-10-18 21:17:47,706] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1\n",
      "[2023-10-18 21:17:47,710] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n"
     ]
    }
   ],
   "source": [
    "sparse_jit = torch.compile(condensed_model)\n",
    "_ = sparse_jit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920 ms ± 41.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sparse_jit(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handles = register_name_shape_hook(model)\n",
    "con_model_handles = register_name_shape_hook(condensed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224/16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_proj (<class 'torch.nn.modules.conv.Conv2d'>): input: torch.Size([2, 3, 224, 224]) output: torch.Size([2, 768, 14, 14])\n",
      "encoder.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_0.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_0.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_0.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_1.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_1.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_1.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_2.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_2.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_2.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_3.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_3.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_3.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_4.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_4.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_4.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_5.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_5.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_5.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_6.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_6.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_6.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_7.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_7.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_7.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_8.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_8.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_8.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_9.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_9.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_9.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_10.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_10.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_10.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_11.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_11.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_11.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers (<class 'torch.nn.modules.container.Sequential'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.ln (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder (<class 'torchvision.models.vision_transformer.Encoder'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "heads.head (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 768]) output: torch.Size([2, 1000])\n",
      "heads (<class 'torch.nn.modules.container.Sequential'>): input: torch.Size([2, 768]) output: torch.Size([2, 1000])\n",
      " (<class 'torchvision.models.vision_transformer.VisionTransformer'>): input: torch.Size([2, 3, 224, 224]) output: torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "_ = model.to(\"cpu\")(x.to(\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 197, 768])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mod_input = torch.rand(size=[2, 197, 768])\n",
    "con_mod_input.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mod_input.dim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([993, 169])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mod.condensed_mod.input_mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layers.encoder_layer_0.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1062,  0.0775,  0.2559,  ..., -0.2307, -0.0242, -0.1812],\n",
       "         [ 0.2253, -0.3532,  0.1342,  ..., -0.2322, -0.0932, -0.1949],\n",
       "         [ 0.0852, -0.3378,  0.1683,  ..., -0.0664,  0.1384, -0.2432],\n",
       "         ...,\n",
       "         [ 0.1869, -0.2886,  0.1001,  ...,  0.1053, -0.1926, -0.2403],\n",
       "         [ 0.3135, -0.0729,  0.3140,  ..., -0.2693, -0.1118, -0.1949],\n",
       "         [ 0.3514,  0.1535,  0.3118,  ..., -0.3770,  0.0761, -0.2348]],\n",
       "\n",
       "        [[ 0.2977, -0.3494,  0.2928,  ..., -0.0483,  0.1729, -0.1782],\n",
       "         [-0.1052, -0.6197,  0.1351,  ..., -0.0043, -0.0115, -0.3618],\n",
       "         [ 0.3307, -0.4847,  0.1688,  ..., -0.1475, -0.2343, -0.1749],\n",
       "         ...,\n",
       "         [ 0.0611, -0.5173,  0.3920,  ..., -0.2028, -0.1901, -0.0789],\n",
       "         [ 0.1215,  0.0600,  0.3542,  ..., -0.1085, -0.0811, -0.3844],\n",
       "         [ 0.2566, -0.0828,  0.1344,  ...,  0.1149, -0.0204, -0.0543]]],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.layers.encoder_layer_0.mlp.get_submodule('0')(con_mod_input)[:,:,con_mod.active_neurons]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layers.encoder_layer_0.mlp.0.condensed_mod (<class 'condensed_sparsity.condensed_linear.CondensedLinearFineGrained'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 993])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1062,  0.0775,  0.2559,  ..., -0.2307, -0.0242, -0.1812],\n",
       "         [ 0.2253, -0.3532,  0.1342,  ..., -0.2322, -0.0932, -0.1949],\n",
       "         [ 0.0852, -0.3378,  0.1683,  ..., -0.0664,  0.1384, -0.2432],\n",
       "         ...,\n",
       "         [ 0.1869, -0.2886,  0.1001,  ...,  0.1053, -0.1926, -0.2403],\n",
       "         [ 0.3135, -0.0729,  0.3140,  ..., -0.2693, -0.1118, -0.1949],\n",
       "         [ 0.3514,  0.1535,  0.3118,  ..., -0.3770,  0.0761, -0.2348]],\n",
       "\n",
       "        [[ 0.2977, -0.3494,  0.2928,  ..., -0.0483,  0.1729, -0.1782],\n",
       "         [-0.1052, -0.6197,  0.1351,  ..., -0.0043, -0.0115, -0.3618],\n",
       "         [ 0.3307, -0.4847,  0.1688,  ..., -0.1475, -0.2343, -0.1749],\n",
       "         ...,\n",
       "         [ 0.0611, -0.5173,  0.3920,  ..., -0.2028, -0.1901, -0.0789],\n",
       "         [ 0.1215,  0.0600,  0.3542,  ..., -0.1085, -0.0811, -0.3844],\n",
       "         [ 0.2566, -0.0828,  0.1344,  ...,  0.1149, -0.0204, -0.0543]]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mod.condensed_mod(con_mod_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.layers.encoder_layer_0.mlp.0.condensed_mod (<class 'condensed_sparsity.condensed_linear.CondensedLinearFineGrained'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 993])\n",
      "encoder.layers.encoder_layer_0.mlp.0 (<class '__main__.ZeroChannelPadder'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.1062,  0.0775,  ...,  0.0000,  0.0000, -0.1812],\n",
       "         [ 0.0000,  0.2253, -0.3532,  ...,  0.0000,  0.0000, -0.1949],\n",
       "         [ 0.0000,  0.0852, -0.3378,  ...,  0.0000,  0.0000, -0.2432],\n",
       "         ...,\n",
       "         [ 0.0000,  0.1869, -0.2886,  ...,  0.0000,  0.0000, -0.2403],\n",
       "         [ 0.0000,  0.3135, -0.0729,  ...,  0.0000,  0.0000, -0.1949],\n",
       "         [ 0.0000,  0.3514,  0.1535,  ...,  0.0000,  0.0000, -0.2348]],\n",
       "\n",
       "        [[ 0.0000,  0.2977, -0.3494,  ...,  0.0000,  0.0000, -0.1782],\n",
       "         [ 0.0000, -0.1052, -0.6197,  ...,  0.0000,  0.0000, -0.3618],\n",
       "         [ 0.0000,  0.3307, -0.4847,  ...,  0.0000,  0.0000, -0.1749],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0611, -0.5173,  ...,  0.0000,  0.0000, -0.0789],\n",
       "         [ 0.0000,  0.1215,  0.0600,  ...,  0.0000,  0.0000, -0.3844],\n",
       "         [ 0.0000,  0.2566, -0.0828,  ...,  0.0000,  0.0000, -0.0543]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mod(con_mod_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_proj (<class 'torch.nn.modules.conv.Conv2d'>): input: torch.Size([2, 3, 224, 224]) output: torch.Size([2, 768, 14, 14])\n",
      "encoder.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_0.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_0.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_0.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_0 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_1.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_1.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_1.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_1 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_2.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_2.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_2.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_2 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_3.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_3.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_3.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_3 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_4.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_4.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_4.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_4 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_5.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_5.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_5.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_5 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_6.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_6.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_6.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_6 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_7.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_7.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_7.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_7 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_8.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_8.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_8.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_8 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_9.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_9.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_9.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_9 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_10.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_10.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_10.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_10 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.mlp.0 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_11.mlp.1 (<class 'torch.nn.modules.activation.GELU'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_11.mlp.2 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 3072])\n",
      "encoder.layers.encoder_layer_11.mlp.3 (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 197, 3072]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.mlp.4 (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11.mlp (<class 'torchvision.models.vision_transformer.MLPBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers.encoder_layer_11 (<class 'torchvision.models.vision_transformer.EncoderBlock'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.layers (<class 'torch.nn.modules.container.Sequential'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder.ln (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "encoder (<class 'torchvision.models.vision_transformer.Encoder'>): input: torch.Size([2, 197, 768]) output: torch.Size([2, 197, 768])\n",
      "heads.head (<class 'torch.nn.modules.linear.Linear'>): input: torch.Size([2, 768]) output: torch.Size([2, 1000])\n",
      "heads (<class 'torch.nn.modules.container.Sequential'>): input: torch.Size([2, 768]) output: torch.Size([2, 1000])\n",
      " (<class 'torchvision.models.vision_transformer.VisionTransformer'>): input: torch.Size([2, 3, 224, 224]) output: torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "_ = model.to(\"cuda\")(x.to(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([993, 169])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_model.get_submodule(\"encoder.layers.encoder_layer_0.mlp.0\").condensed_mod.condensed_weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_model.get_submodule(\"encoder.layers.encoder_layer_0.mlp.0\").out_channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/mike/condensed-sparsity/notebooks/main.ipynb Cell 42\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhector-tailscale/home/mike/condensed-sparsity/notebooks/main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m input_inter \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(size\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m197\u001b[39m,\u001b[39m768\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhector-tailscale/home/mike/condensed-sparsity/notebooks/main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m con_mod \u001b[39m=\u001b[39m condensed_model\u001b[39m.\u001b[39mget_submodule(\u001b[39m\"\u001b[39m\u001b[39mencoder.layers.encoder_layer_0.mlp.0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhector-tailscale/home/mike/condensed-sparsity/notebooks/main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m con_mod(input_inter\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "\u001b[1;32m/home/mike/condensed-sparsity/notebooks/main.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhector-tailscale/home/mike/condensed-sparsity/notebooks/main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bhector-tailscale/home/mike/condensed-sparsity/notebooks/main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     out_condensed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcondensed_mod(\u001b[39minput\u001b[39;49m)  \u001b[39m# will be of shape batch_size x condensed out channels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhector-tailscale/home/mike/condensed-sparsity/notebooks/main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhector-tailscale/home/mike/condensed-sparsity/notebooks/main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m         \u001b[39m# target = torch.zeros(size=(input.shape[0], self.out_channels), dtype=out_condensed.dtype)  # Needs to be of shape bath size x out_channels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bhector-tailscale/home/mike/condensed-sparsity/notebooks/main.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(size\u001b[39m=\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m+\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_channels,)), dtype\u001b[39m=\u001b[39mout_condensed\u001b[39m.\u001b[39mdtype)  \u001b[39m# Needs to be of shape ... x out_channels\u001b[39;00m\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/condensed-sparsity/src/condensed_sparsity/condensed_linear.py:211\u001b[0m, in \u001b[0;36mCondensedLinearFineGrained.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    204\u001b[0m     \u001b[39m# return (\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[39m#     torch.sum(self.condensed_weight * input[:, self.input_mask], dim=2)\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[39m#     + self.bias\u001b[39;00m\n\u001b[1;32m    207\u001b[0m     \u001b[39m# )\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[39m# TODO: Test for 2-dim, benchmark 3 dim\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    210\u001b[0m         torch\u001b[39m.\u001b[39msum(\n\u001b[0;32m--> 211\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcondensed_weight \u001b[39m*\u001b[39;49m \u001b[39minput\u001b[39;49m[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_mask],\n\u001b[1;32m    212\u001b[0m             dim\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(),\n\u001b[1;32m    213\u001b[0m         )\n\u001b[1;32m    214\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n\u001b[1;32m    215\u001b[0m     )\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    217\u001b[0m         torch\u001b[39m.\u001b[39msum(\n\u001b[1;32m    218\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcondensed_weight \u001b[39m*\u001b[39m \u001b[39minput\u001b[39m[:, :, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_mask], dim\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m\n\u001b[1;32m    219\u001b[0m         )\n\u001b[1;32m    220\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "input_inter = torch.rand(size=(1,197,768))\n",
    "con_mod = condensed_model.get_submodule(\"encoder.layers.encoder_layer_0.mlp.0\")\n",
    "\n",
    "con_mod(input_inter.to(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_proj (<class 'torch.nn.modules.conv.Conv2d'>): input: torch.Size([1, 3, 224, 224]) output: torch.Size([1, 768, 14, 14])\n",
      "encoder.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([1, 197, 768]) output: torch.Size([1, 197, 768])\n",
      "encoder.layers.encoder_layer_0.ln_1 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([1, 197, 768]) output: torch.Size([1, 197, 768])\n",
      "encoder.layers.encoder_layer_0.self_attention (<class 'torch.nn.modules.activation.MultiheadAttention'>): input: torch.Size([1, 197, 768]) output: torch.Size([1, 197, 768])\n",
      "encoder.layers.encoder_layer_0.dropout (<class 'torch.nn.modules.dropout.Dropout'>): input: torch.Size([1, 197, 768]) output: torch.Size([1, 197, 768])\n",
      "encoder.layers.encoder_layer_0.ln_2 (<class 'torch.nn.modules.normalization.LayerNorm'>): input: torch.Size([1, 197, 768]) output: torch.Size([1, 197, 768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (169) must match the size of tensor b (768) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/mike/condensed-sparsity/notebooks/main.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/mike/condensed-sparsity/notebooks/main.ipynb#Y623sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m condensed_model(x\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py:298\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    295\u001b[0m batch_class_token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_token\u001b[39m.\u001b[39mexpand(n, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    296\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([batch_class_token, x], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 298\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m    300\u001b[0m \u001b[39m# Classifier \"token\" as used by standard language architectures\u001b[39;00m\n\u001b[1;32m    301\u001b[0m x \u001b[39m=\u001b[39m x[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py:157\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    155\u001b[0m torch\u001b[39m.\u001b[39m_assert(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected (batch_size, seq_length, hidden_dim) got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_embedding\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m)))\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py:118\u001b[0m, in \u001b[0;36mEncoderBlock.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m    117\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(x)\n\u001b[0;32m--> 118\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(y)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m y\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "\u001b[1;32m/home/mike/condensed-sparsity/notebooks/main.ipynb Cell 37\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mike/condensed-sparsity/notebooks/main.ipynb#Y623sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mike/condensed-sparsity/notebooks/main.ipynb#Y623sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     out_condensed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcondensed_mod(\u001b[39minput\u001b[39;49m)  \u001b[39m# will be of shape batch_size x condensed out channels\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mike/condensed-sparsity/notebooks/main.ipynb#Y623sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mike/condensed-sparsity/notebooks/main.ipynb#Y623sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(size\u001b[39m=\u001b[39m(out_condensed\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_channels), dtype\u001b[39m=\u001b[39mout_condensed\u001b[39m.\u001b[39mdtype)  \u001b[39m# Needs to be of shape bath size x out_channels\u001b[39;00m\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/condensed-sparsity/src/condensed_sparsity/condensed_linear.py:205\u001b[0m, in \u001b[0;36mCondensedLinearFineGrained.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 205\u001b[0m         torch\u001b[39m.\u001b[39msum(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcondensed_weight \u001b[39m*\u001b[39;49m \u001b[39minput\u001b[39;49m[:, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_mask], dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    206\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n\u001b[1;32m    207\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (169) must match the size of tensor b (768) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "condensed_model(x.to(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1004])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_condensed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3072])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   1,    6,    9,  ..., 3049, 3058, 3059])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_pad.active_neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(10,10))\n",
    "src = torch.ones(size=(3,10))\n",
    "active_neurons = torch.tensor([0,5,9])\n",
    "zeros.index_add(dim=0, index=active_neurons, source=src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out_condensed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.7566e-01,  2.2813e-01, -2.7752e-01,  ..., -3.8584e-01,\n",
       "          5.9473e-02,  3.5377e-01],\n",
       "        [-4.7152e-01,  2.2312e-01, -3.1001e-01,  ...,  5.7035e-02,\n",
       "          1.2624e-01,  1.6490e-01],\n",
       "        [-3.9183e-01,  3.1754e-05, -4.4271e-01,  ..., -3.1127e-01,\n",
       "          8.1305e-02, -8.6896e-02],\n",
       "        ...,\n",
       "        [-6.3535e-01, -9.3485e-02, -2.3353e-01,  ...,  2.7315e-02,\n",
       "          1.1955e-01,  8.7144e-02],\n",
       "        [-3.9497e-01,  3.4416e-01,  9.1024e-02,  ...,  4.3176e-01,\n",
       "          1.8066e-01,  1.9384e-01],\n",
       "        [-6.8717e-01,  9.0617e-03, -2.0833e-01,  ...,  3.4003e-02,\n",
       "         -1.4089e-01,  3.7132e-01]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_proj\n",
      "x\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "encoder_dropout\n",
      "add\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_0_ln_1\n",
      "encoder_dropout\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_0_self_attention\n",
      "encoder_layers_encoder_layer_0_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_0_dropout\n",
      "getitem_5\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_0_ln_2\n",
      "add_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_0_mlp_0\n",
      "encoder_layers_encoder_layer_0_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_0_mlp_1\n",
      "encoder_layers_encoder_layer_0_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_0_mlp_2\n",
      "encoder_layers_encoder_layer_0_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_0_mlp_3\n",
      "encoder_layers_encoder_layer_0_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_0_mlp_4\n",
      "encoder_layers_encoder_layer_0_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_1_ln_1\n",
      "add_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_1_self_attention\n",
      "encoder_layers_encoder_layer_1_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_1_dropout\n",
      "getitem_7\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_1_ln_2\n",
      "add_3\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_1_mlp_0\n",
      "encoder_layers_encoder_layer_1_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_1_mlp_1\n",
      "encoder_layers_encoder_layer_1_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_1_mlp_2\n",
      "encoder_layers_encoder_layer_1_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_1_mlp_3\n",
      "encoder_layers_encoder_layer_1_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_1_mlp_4\n",
      "encoder_layers_encoder_layer_1_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_2_ln_1\n",
      "add_4\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_2_self_attention\n",
      "encoder_layers_encoder_layer_2_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_2_dropout\n",
      "getitem_9\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_2_ln_2\n",
      "add_5\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_2_mlp_0\n",
      "encoder_layers_encoder_layer_2_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_2_mlp_1\n",
      "encoder_layers_encoder_layer_2_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_2_mlp_2\n",
      "encoder_layers_encoder_layer_2_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_2_mlp_3\n",
      "encoder_layers_encoder_layer_2_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_2_mlp_4\n",
      "encoder_layers_encoder_layer_2_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_3_ln_1\n",
      "add_6\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_3_self_attention\n",
      "encoder_layers_encoder_layer_3_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_3_dropout\n",
      "getitem_11\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_3_ln_2\n",
      "add_7\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_3_mlp_0\n",
      "encoder_layers_encoder_layer_3_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_3_mlp_1\n",
      "encoder_layers_encoder_layer_3_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_3_mlp_2\n",
      "encoder_layers_encoder_layer_3_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_3_mlp_3\n",
      "encoder_layers_encoder_layer_3_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_3_mlp_4\n",
      "encoder_layers_encoder_layer_3_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_4_ln_1\n",
      "add_8\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_4_self_attention\n",
      "encoder_layers_encoder_layer_4_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_4_dropout\n",
      "getitem_13\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_4_ln_2\n",
      "add_9\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_4_mlp_0\n",
      "encoder_layers_encoder_layer_4_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_4_mlp_1\n",
      "encoder_layers_encoder_layer_4_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_4_mlp_2\n",
      "encoder_layers_encoder_layer_4_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_4_mlp_3\n",
      "encoder_layers_encoder_layer_4_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_4_mlp_4\n",
      "encoder_layers_encoder_layer_4_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_5_ln_1\n",
      "add_10\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_5_self_attention\n",
      "encoder_layers_encoder_layer_5_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_5_dropout\n",
      "getitem_15\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_5_ln_2\n",
      "add_11\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_5_mlp_0\n",
      "encoder_layers_encoder_layer_5_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_5_mlp_1\n",
      "encoder_layers_encoder_layer_5_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_5_mlp_2\n",
      "encoder_layers_encoder_layer_5_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_5_mlp_3\n",
      "encoder_layers_encoder_layer_5_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_5_mlp_4\n",
      "encoder_layers_encoder_layer_5_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_6_ln_1\n",
      "add_12\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_6_self_attention\n",
      "encoder_layers_encoder_layer_6_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_6_dropout\n",
      "getitem_17\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_6_ln_2\n",
      "add_13\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_6_mlp_0\n",
      "encoder_layers_encoder_layer_6_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_6_mlp_1\n",
      "encoder_layers_encoder_layer_6_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_6_mlp_2\n",
      "encoder_layers_encoder_layer_6_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_6_mlp_3\n",
      "encoder_layers_encoder_layer_6_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_6_mlp_4\n",
      "encoder_layers_encoder_layer_6_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_7_ln_1\n",
      "add_14\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_7_self_attention\n",
      "encoder_layers_encoder_layer_7_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_7_dropout\n",
      "getitem_19\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_7_ln_2\n",
      "add_15\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_7_mlp_0\n",
      "encoder_layers_encoder_layer_7_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_7_mlp_1\n",
      "encoder_layers_encoder_layer_7_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_7_mlp_2\n",
      "encoder_layers_encoder_layer_7_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_7_mlp_3\n",
      "encoder_layers_encoder_layer_7_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_7_mlp_4\n",
      "encoder_layers_encoder_layer_7_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_8_ln_1\n",
      "add_16\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_8_self_attention\n",
      "encoder_layers_encoder_layer_8_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_8_dropout\n",
      "getitem_21\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_8_ln_2\n",
      "add_17\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_8_mlp_0\n",
      "encoder_layers_encoder_layer_8_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_8_mlp_1\n",
      "encoder_layers_encoder_layer_8_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_8_mlp_2\n",
      "encoder_layers_encoder_layer_8_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_8_mlp_3\n",
      "encoder_layers_encoder_layer_8_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_8_mlp_4\n",
      "encoder_layers_encoder_layer_8_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_9_ln_1\n",
      "add_18\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_9_self_attention\n",
      "encoder_layers_encoder_layer_9_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_9_dropout\n",
      "getitem_23\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_9_ln_2\n",
      "add_19\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_9_mlp_0\n",
      "encoder_layers_encoder_layer_9_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_9_mlp_1\n",
      "encoder_layers_encoder_layer_9_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_9_mlp_2\n",
      "encoder_layers_encoder_layer_9_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_9_mlp_3\n",
      "encoder_layers_encoder_layer_9_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_9_mlp_4\n",
      "encoder_layers_encoder_layer_9_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_10_ln_1\n",
      "add_20\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_10_self_attention\n",
      "encoder_layers_encoder_layer_10_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_10_dropout\n",
      "getitem_25\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_10_ln_2\n",
      "add_21\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_10_mlp_0\n",
      "encoder_layers_encoder_layer_10_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_10_mlp_1\n",
      "encoder_layers_encoder_layer_10_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_10_mlp_2\n",
      "encoder_layers_encoder_layer_10_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_10_mlp_3\n",
      "encoder_layers_encoder_layer_10_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_10_mlp_4\n",
      "encoder_layers_encoder_layer_10_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_11_ln_1\n",
      "add_22\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_11_self_attention\n",
      "encoder_layers_encoder_layer_11_ln_1\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder_layers_encoder_layer_11_dropout\n",
      "getitem_27\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_11_ln_2\n",
      "add_23\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder_layers_encoder_layer_11_mlp_0\n",
      "encoder_layers_encoder_layer_11_ln_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_11_mlp_1\n",
      "encoder_layers_encoder_layer_11_mlp_0\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder_layers_encoder_layer_11_mlp_2\n",
      "encoder_layers_encoder_layer_11_mlp_1\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_layers_encoder_layer_11_mlp_3\n",
      "encoder_layers_encoder_layer_11_mlp_2\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder_layers_encoder_layer_11_mlp_4\n",
      "encoder_layers_encoder_layer_11_mlp_3\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder_ln\n",
      "add_24\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "heads_head\n",
      "getitem_29\n",
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for node in g.graph.nodes:\n",
    "    if node.op==\"call_module\":\n",
    "        print(node.name)\n",
    "        print(node.args[0])\n",
    "        print(type(g.get_submodule(node.target)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from condensed_sparsity.v2.condensed_linear import _get_active_neuron_idx, _get_fine_grained_idx\n",
    "\n",
    "class CondensedMetaData():\n",
    "\n",
    "    def __init__(self, gm: fx.graph_module.GraphModule, node: fx.Node):\n",
    "        self.mod = gm.get_submodule(node.target)\n",
    "        self.active_neuron_idx = _get_active_neuron_idx(self.mod.weight)\n",
    "        self.fine_grained_idx = _get_fine_grained_idx(self.mod.weight, self.active_neuron_idx)\n",
    "        self.original_weight_shape = self.mod.weight.shape\n",
    "\n",
    "def condense_in_proj_tensor(in_proj_tensor, active_idx) -> torch.Tensor:\n",
    "    return torch.clone(in_proj_tensor[torch.concat((active_idx, active_idx, active_idx))].detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (3464658390.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[63], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    mha_mod.in_proj_weight = torch.clone(mha_mod.in_proj_weight[].detach().type(dtype))\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "def trim_mha(gm: fx.graph_module.GraphModule, node: fx.Node, condensed_node: fx.Node, dtype: torch.Type):\n",
    "    mha_mod = gm.get_submodule(node.target)\n",
    "    condensed_mod = gm.get_submodule(condensed_node.target)\n",
    "    active_neuron_idx = condensed_node.meta[\"condensed_meta_data\"].active_neuron_idx\n",
    "    mha_mod.in_proj_weight = condense_in_proj_tensor(mha_mod.in_proj_weight, active_neuron_idx)\n",
    "    mha_mod.in_proj_bias = condense_in_proj_tensor(mha_mod.in_proj_bias, active_neuron_idx)\n",
    "    mha_mod.embed_dim = sum(active_neuron_idx)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2304])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = g.get_submodule(\"encoder.layers.encoder_layer_0.self_attention\")\n",
    "mha.in_proj_bias.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(601)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_idx_active = _get_active_neuron_idx(model.conv_proj.weight)\n",
    "conv_idx_active.sum()\n",
    "# original_neurons = 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha.out_proj.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2304])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat((conv_idx_active, conv_idx_active, conv_idx_active)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiheadAttention' object has no attribute 'in_proj_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/user/condensed-sparsity/notebooks/main.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(mod) \u001b[39m==\u001b[39m nn\u001b[39m.\u001b[39mMultiheadAttention:\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mif\u001b[39;00m last_condensed_node \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         trim_mha(g, node, last_condensed_node)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(mod) \u001b[39m==\u001b[39m nn\u001b[39m.\u001b[39mLayerNorm:\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# TODO: Shrink to last major dim\u001b[39;00m\n",
      "\u001b[1;32m/home/user/condensed-sparsity/notebooks/main.ipynb Cell 18\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m condensed_mod \u001b[39m=\u001b[39m gm\u001b[39m.\u001b[39mget_submodule(condensed_node\u001b[39m.\u001b[39mtarget)\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m active_neuron_idx \u001b[39m=\u001b[39m condensed_node\u001b[39m.\u001b[39mmeta[\u001b[39m\"\u001b[39m\u001b[39mcondensed_meta_data\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mactive_neuron_idx\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f6d696b652f436f64652f5f7068642f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m mha_mod\u001b[39m.\u001b[39;49min_proj_\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiheadAttention' object has no attribute 'in_proj_'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "target=\"encoder_layers_encoder_layer_0_self_attention\"\n",
    "next_mod_user = None\n",
    "tensor_shape = None\n",
    "last_mod = None\n",
    "last_condensed_node = None\n",
    "modules_to_condense = [nn.Linear, nn.Conv2d]\n",
    "for node in g.graph.nodes:\n",
    "    if node.op==\"call_module\":\n",
    "        mod = g.get_submodule(node.target)\n",
    "        # If we hit a linear or conv layer, we extra metadata and condense\n",
    "        if type(mod) in modules_to_condense:\n",
    "            last_condensed_node = node\n",
    "            node.meta[\"condensed_meta_data\"] = CondensedMetaData(g, node)\n",
    "            # TODO: Convert mod / and node?\n",
    "            continue\n",
    "        # If we hit an MHA, we shrink self attention and out projection weights\n",
    "        if type(mod) == nn.MultiheadAttention:\n",
    "            if last_condensed_node is not None:\n",
    "                trim_mha(g, node, last_condensed_node)\n",
    "                continue\n",
    "        # Else we shrink other layer types to suit. Layernorm, maybe something else?\n",
    "        elif type(mod) == nn.LayerNorm:\n",
    "            # TODO: Shrink to last major dim\n",
    "            pass\n",
    "            \n",
    "        \n",
    "        # print(node.name)\n",
    "        # print(node.target)\n",
    "        # print(node._input_nodes)\n",
    "        # print(node.users)\n",
    "        # print(node.meta)\n",
    "        # print(node.args)\n",
    "        # print(\"\\n\")\n",
    "        # print(node.__dir__())\n",
    "        # print(node.name, node.meta[\"tensor_meta\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call_module'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encoder_layers_encoder_layer_0_self_attention'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graph',\n",
       " 'name',\n",
       " 'op',\n",
       " 'target',\n",
       " '_input_nodes',\n",
       " '_args',\n",
       " '_kwargs',\n",
       " 'users',\n",
       " 'type',\n",
       " '_prev',\n",
       " '_next',\n",
       " '_erased',\n",
       " '_repr_fn',\n",
       " 'meta',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " 'next',\n",
       " 'prev',\n",
       " 'prepend',\n",
       " 'append',\n",
       " '_remove_from_list',\n",
       " 'args',\n",
       " 'kwargs',\n",
       " 'all_input_nodes',\n",
       " 'update_arg',\n",
       " 'update_kwarg',\n",
       " 'stack_trace',\n",
       " '_Node__update_args_kwargs',\n",
       " '__repr__',\n",
       " '_pretty_print_target',\n",
       " 'format_node',\n",
       " 'replace_all_uses_with',\n",
       " 'is_impure',\n",
       " 'normalized_arguments',\n",
       " 'replace_input_with',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__new__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.__dir__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{getitem_5: None, getitem_6: None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[encoder_layers_encoder_layer_0_ln_1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.all_input_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{reshape: None}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call_module'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graph',\n",
       " 'name',\n",
       " 'op',\n",
       " 'target',\n",
       " '_input_nodes',\n",
       " '_args',\n",
       " '_kwargs',\n",
       " 'users',\n",
       " 'type',\n",
       " '_prev',\n",
       " '_next',\n",
       " '_erased',\n",
       " '_repr_fn',\n",
       " 'meta',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " 'next',\n",
       " 'prev',\n",
       " 'prepend',\n",
       " 'append',\n",
       " '_remove_from_list',\n",
       " 'args',\n",
       " 'kwargs',\n",
       " 'all_input_nodes',\n",
       " 'update_arg',\n",
       " 'update_kwarg',\n",
       " 'stack_trace',\n",
       " '_Node__update_args_kwargs',\n",
       " '__repr__',\n",
       " '_pretty_print_target',\n",
       " 'format_node',\n",
       " 'replace_all_uses_with',\n",
       " 'is_impure',\n",
       " 'normalized_arguments',\n",
       " 'replace_input_with',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__new__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.__dir__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graph',\n",
       " 'name',\n",
       " 'op',\n",
       " 'target',\n",
       " '_input_nodes',\n",
       " '_args',\n",
       " '_kwargs',\n",
       " 'users',\n",
       " 'type',\n",
       " '_prev',\n",
       " '_next',\n",
       " '_erased',\n",
       " '_repr_fn',\n",
       " 'meta',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " 'next',\n",
       " 'prev',\n",
       " 'prepend',\n",
       " 'append',\n",
       " '_remove_from_list',\n",
       " 'args',\n",
       " 'kwargs',\n",
       " 'all_input_nodes',\n",
       " 'update_arg',\n",
       " 'update_kwarg',\n",
       " 'stack_trace',\n",
       " '_Node__update_args_kwargs',\n",
       " '__repr__',\n",
       " '_pretty_print_target',\n",
       " 'format_node',\n",
       " 'replace_all_uses_with',\n",
       " 'is_impure',\n",
       " 'normalized_arguments',\n",
       " 'replace_input_with',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__new__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node.__dir__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mha_1 = model.get_submodule(\"encoder.layers.encoder_layer_0.self_attention\")\n",
    "\n",
    "\n",
    "import re\n",
    "matches = [re.match(r\".*weight.*\", text).group() for text in mha_1.__dir__() if re.match(r\".*weight.*\", text) is not None]\n",
    "weighted_mha_layers =  {k: getattr(mha_1, k) for k in matches}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in_proj_weight': Parameter containing:\n",
       " tensor([[-0.0080, -0.0090,  0.0210,  ...,  0.0408, -0.0053,  0.0022],\n",
       "         [-0.0040,  0.0230, -0.0004,  ..., -0.0697,  0.0072,  0.0044],\n",
       "         [-0.0222, -0.0087,  0.0143,  ...,  0.0675, -0.0029,  0.0044],\n",
       "         ...,\n",
       "         [-0.0094, -0.0243, -0.0096,  ...,  0.0031,  0.0489,  0.0199],\n",
       "         [ 0.0078,  0.0056, -0.0120,  ...,  0.0011, -0.0109,  0.0050],\n",
       "         [-0.0009,  0.0133,  0.0184,  ...,  0.0027,  0.0024, -0.0056]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'k_proj_weight': None,\n",
       " 'q_proj_weight': None,\n",
       " 'v_proj_weight': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_mha_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2304, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha_weights = mha_1.in_proj_weight\n",
    "mha_weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from condensed_sparsity.v2.condensed_linear import _get_active_neuron_idx, _get_fine_grained_idx\n",
    "\n",
    "idx = _get_active_neuron_idx(model.conv_proj.weight)\n",
    "idx.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_proj.out_channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(601, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([601, 3, 16, 16])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_skinny = structured_condensed_conv2d_factory(model.conv_proj)\n",
    "conv1_skinny.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([601])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_skinny.bias.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.conv_proj(x.to(device)) == conv1_skinny(x.to(device))).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    last_mlp = model.get_submodule(\"encoder.layers.encoder_layer_11.mlp.0\") # with full dim\n",
    "    last_mlp_skinny = CondensedLinearFineGrained(last_mlp)\n",
    "    input = torch.rand(size=(512, 768))\n",
    "    idx = _get_active_neuron_idx(last_mlp.weight)\n",
    "    print(torch.allclose(last_mlp(input.to(device))[:, idx], last_mlp_skinny(input.to(device)), atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "getattr_1\n",
      "getitem\n",
      "getitem_1\n",
      "getitem_2\n",
      "getitem_3\n",
      "eq\n",
      "_assert\n",
      "eq_1\n",
      "_assert_1\n",
      "floordiv\n",
      "floordiv_1\n",
      "conv_proj\n",
      "mul\n",
      "reshape\n",
      "permute\n",
      "getattr_2\n",
      "getitem_4\n",
      "class_token\n",
      "expand\n",
      "cat\n",
      "dim\n",
      "eq_2\n",
      "getattr_3\n",
      "_assert_2\n",
      "encoder_pos_embedding\n",
      "add\n",
      "encoder_dropout\n",
      "dim_1\n",
      "eq_3\n",
      "getattr_4\n",
      "_assert_3\n",
      "encoder_layers_encoder_layer_0_ln_1\n",
      "encoder_layers_encoder_layer_0_self_attention\n",
      "getitem_5\n",
      "getitem_6\n",
      "encoder_layers_encoder_layer_0_dropout\n",
      "add_1\n",
      "encoder_layers_encoder_layer_0_ln_2\n",
      "encoder_layers_encoder_layer_0_mlp_0\n",
      "encoder_layers_encoder_layer_0_mlp_1\n",
      "encoder_layers_encoder_layer_0_mlp_2\n",
      "encoder_layers_encoder_layer_0_mlp_3\n",
      "encoder_layers_encoder_layer_0_mlp_4\n",
      "add_2\n",
      "dim_2\n",
      "eq_4\n",
      "getattr_5\n",
      "_assert_4\n",
      "encoder_layers_encoder_layer_1_ln_1\n",
      "encoder_layers_encoder_layer_1_self_attention\n",
      "getitem_7\n",
      "getitem_8\n",
      "encoder_layers_encoder_layer_1_dropout\n",
      "add_3\n",
      "encoder_layers_encoder_layer_1_ln_2\n",
      "encoder_layers_encoder_layer_1_mlp_0\n",
      "encoder_layers_encoder_layer_1_mlp_1\n",
      "encoder_layers_encoder_layer_1_mlp_2\n",
      "encoder_layers_encoder_layer_1_mlp_3\n",
      "encoder_layers_encoder_layer_1_mlp_4\n",
      "add_4\n",
      "dim_3\n",
      "eq_5\n",
      "getattr_6\n",
      "_assert_5\n",
      "encoder_layers_encoder_layer_2_ln_1\n",
      "encoder_layers_encoder_layer_2_self_attention\n",
      "getitem_9\n",
      "getitem_10\n",
      "encoder_layers_encoder_layer_2_dropout\n",
      "add_5\n",
      "encoder_layers_encoder_layer_2_ln_2\n",
      "encoder_layers_encoder_layer_2_mlp_0\n",
      "encoder_layers_encoder_layer_2_mlp_1\n",
      "encoder_layers_encoder_layer_2_mlp_2\n",
      "encoder_layers_encoder_layer_2_mlp_3\n",
      "encoder_layers_encoder_layer_2_mlp_4\n",
      "add_6\n",
      "dim_4\n",
      "eq_6\n",
      "getattr_7\n",
      "_assert_6\n",
      "encoder_layers_encoder_layer_3_ln_1\n",
      "encoder_layers_encoder_layer_3_self_attention\n",
      "getitem_11\n",
      "getitem_12\n",
      "encoder_layers_encoder_layer_3_dropout\n",
      "add_7\n",
      "encoder_layers_encoder_layer_3_ln_2\n",
      "encoder_layers_encoder_layer_3_mlp_0\n",
      "encoder_layers_encoder_layer_3_mlp_1\n",
      "encoder_layers_encoder_layer_3_mlp_2\n",
      "encoder_layers_encoder_layer_3_mlp_3\n",
      "encoder_layers_encoder_layer_3_mlp_4\n",
      "add_8\n",
      "dim_5\n",
      "eq_7\n",
      "getattr_8\n",
      "_assert_7\n",
      "encoder_layers_encoder_layer_4_ln_1\n",
      "encoder_layers_encoder_layer_4_self_attention\n",
      "getitem_13\n",
      "getitem_14\n",
      "encoder_layers_encoder_layer_4_dropout\n",
      "add_9\n",
      "encoder_layers_encoder_layer_4_ln_2\n",
      "encoder_layers_encoder_layer_4_mlp_0\n",
      "encoder_layers_encoder_layer_4_mlp_1\n",
      "encoder_layers_encoder_layer_4_mlp_2\n",
      "encoder_layers_encoder_layer_4_mlp_3\n",
      "encoder_layers_encoder_layer_4_mlp_4\n",
      "add_10\n",
      "dim_6\n",
      "eq_8\n",
      "getattr_9\n",
      "_assert_8\n",
      "encoder_layers_encoder_layer_5_ln_1\n",
      "encoder_layers_encoder_layer_5_self_attention\n",
      "getitem_15\n",
      "getitem_16\n",
      "encoder_layers_encoder_layer_5_dropout\n",
      "add_11\n",
      "encoder_layers_encoder_layer_5_ln_2\n",
      "encoder_layers_encoder_layer_5_mlp_0\n",
      "encoder_layers_encoder_layer_5_mlp_1\n",
      "encoder_layers_encoder_layer_5_mlp_2\n",
      "encoder_layers_encoder_layer_5_mlp_3\n",
      "encoder_layers_encoder_layer_5_mlp_4\n",
      "add_12\n",
      "dim_7\n",
      "eq_9\n",
      "getattr_10\n",
      "_assert_9\n",
      "encoder_layers_encoder_layer_6_ln_1\n",
      "encoder_layers_encoder_layer_6_self_attention\n",
      "getitem_17\n",
      "getitem_18\n",
      "encoder_layers_encoder_layer_6_dropout\n",
      "add_13\n",
      "encoder_layers_encoder_layer_6_ln_2\n",
      "encoder_layers_encoder_layer_6_mlp_0\n",
      "encoder_layers_encoder_layer_6_mlp_1\n",
      "encoder_layers_encoder_layer_6_mlp_2\n",
      "encoder_layers_encoder_layer_6_mlp_3\n",
      "encoder_layers_encoder_layer_6_mlp_4\n",
      "add_14\n",
      "dim_8\n",
      "eq_10\n",
      "getattr_11\n",
      "_assert_10\n",
      "encoder_layers_encoder_layer_7_ln_1\n",
      "encoder_layers_encoder_layer_7_self_attention\n",
      "getitem_19\n",
      "getitem_20\n",
      "encoder_layers_encoder_layer_7_dropout\n",
      "add_15\n",
      "encoder_layers_encoder_layer_7_ln_2\n",
      "encoder_layers_encoder_layer_7_mlp_0\n",
      "encoder_layers_encoder_layer_7_mlp_1\n",
      "encoder_layers_encoder_layer_7_mlp_2\n",
      "encoder_layers_encoder_layer_7_mlp_3\n",
      "encoder_layers_encoder_layer_7_mlp_4\n",
      "add_16\n",
      "dim_9\n",
      "eq_11\n",
      "getattr_12\n",
      "_assert_11\n",
      "encoder_layers_encoder_layer_8_ln_1\n",
      "encoder_layers_encoder_layer_8_self_attention\n",
      "getitem_21\n",
      "getitem_22\n",
      "encoder_layers_encoder_layer_8_dropout\n",
      "add_17\n",
      "encoder_layers_encoder_layer_8_ln_2\n",
      "encoder_layers_encoder_layer_8_mlp_0\n",
      "encoder_layers_encoder_layer_8_mlp_1\n",
      "encoder_layers_encoder_layer_8_mlp_2\n",
      "encoder_layers_encoder_layer_8_mlp_3\n",
      "encoder_layers_encoder_layer_8_mlp_4\n",
      "add_18\n",
      "dim_10\n",
      "eq_12\n",
      "getattr_13\n",
      "_assert_12\n",
      "encoder_layers_encoder_layer_9_ln_1\n",
      "encoder_layers_encoder_layer_9_self_attention\n",
      "getitem_23\n",
      "getitem_24\n",
      "encoder_layers_encoder_layer_9_dropout\n",
      "add_19\n",
      "encoder_layers_encoder_layer_9_ln_2\n",
      "encoder_layers_encoder_layer_9_mlp_0\n",
      "encoder_layers_encoder_layer_9_mlp_1\n",
      "encoder_layers_encoder_layer_9_mlp_2\n",
      "encoder_layers_encoder_layer_9_mlp_3\n",
      "encoder_layers_encoder_layer_9_mlp_4\n",
      "add_20\n",
      "dim_11\n",
      "eq_13\n",
      "getattr_14\n",
      "_assert_13\n",
      "encoder_layers_encoder_layer_10_ln_1\n",
      "encoder_layers_encoder_layer_10_self_attention\n",
      "getitem_25\n",
      "getitem_26\n",
      "encoder_layers_encoder_layer_10_dropout\n",
      "add_21\n",
      "encoder_layers_encoder_layer_10_ln_2\n",
      "encoder_layers_encoder_layer_10_mlp_0\n",
      "encoder_layers_encoder_layer_10_mlp_1\n",
      "encoder_layers_encoder_layer_10_mlp_2\n",
      "encoder_layers_encoder_layer_10_mlp_3\n",
      "encoder_layers_encoder_layer_10_mlp_4\n",
      "add_22\n",
      "dim_12\n",
      "eq_14\n",
      "getattr_15\n",
      "_assert_14\n",
      "encoder_layers_encoder_layer_11_ln_1\n",
      "encoder_layers_encoder_layer_11_self_attention\n",
      "getitem_27\n",
      "getitem_28\n",
      "encoder_layers_encoder_layer_11_dropout\n",
      "add_23\n",
      "encoder_layers_encoder_layer_11_ln_2\n",
      "encoder_layers_encoder_layer_11_mlp_0\n",
      "encoder_layers_encoder_layer_11_mlp_1\n",
      "encoder_layers_encoder_layer_11_mlp_2\n",
      "encoder_layers_encoder_layer_11_mlp_3\n",
      "encoder_layers_encoder_layer_11_mlp_4\n",
      "add_24\n",
      "encoder_ln\n",
      "getitem_29\n",
      "heads_head\n",
      "output\n"
     ]
    }
   ],
   "source": [
    "for node in g.graph.nodes:\n",
    "    print(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.vision_transformer import VisionTransformer, Encoder\n",
    "from copy import deepcopy\n",
    "from condensed_sparsity.v2.condensed_linear import CondensedLinearFineGrained CondensedLinearFineGrainedSparseOp, CondensedLinearStructured\n",
    "from typing import Union, Callable, Optional\n",
    "\n",
    "class CondensedViTFactory(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self, model: nn.Module,\n",
    "        condensed_linear_factory: Union[nn.Module, Callable] = CondensedLinearFineGrained,\n",
    "        condensed_conv_factory: Union[nn.Module, Callable] = structured_condensed_conv2d_factory,\n",
    "        new_dtype: Optional[torch.type] = None\n",
    "    ):\n",
    "        self.model=deepcopy(model)\n",
    "        last_hidden_dim = None\n",
    "        with torch.no_grad():\n",
    "            for n,m in self.model.named_modules():\n",
    "                setattr(self.model, )\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _convert_dtype(self):\n",
    "        # TODO: convert before allocating new?\n",
    "        pass\n",
    "\n",
    "    def _parse_mha(self, mha: nn.MultiheadAttention, prior_mod: nn.Module) -> nn.MultiheadAttention:\n",
    "        pass\n",
    "    \n",
    "    def _parse_encoder(self, encoder: Encoder, prior_mod: nn.Module) -> Encoder:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/condensed-sparsity/src/condensed_sparsity/v2/condensed_linear.py:263: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:54.)\n",
      "  torch.clone(weight.detach().type(dtype).to_sparse_csr()),\n"
     ]
    }
   ],
   "source": [
    "mod = model.get_submodule(\"encoder.layers.encoder_layer_11.mlp.0\") # with full dim\n",
    "con_mod = CondensedLinearFineGrainedSparseOp(mod)\n",
    "input = torch.rand(size=(128, 768)).to(\"cuda\")\n",
    "con_mod.eval()\n",
    "con_mod = con_mod.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mod.sparse_weight.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CondensedLinearFineGrainedSparseOp' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/user/condensed-sparsity/notebooks/main.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f2d7461696c7363616c65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m weight \u001b[39m=\u001b[39m con_mod\u001b[39m.\u001b[39;49mweight\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f2d7461696c7363616c65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m bias \u001b[39m=\u001b[39m con_mod\u001b[39m.\u001b[39mbias\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CondensedLinearFineGrainedSparseOp' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "weight = con_mod.weight\n",
    "bias = con_mod.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1145, 768])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "def timeit(input, sparse_weight, bias):\n",
    "    avg_times = 0\n",
    "    for _ in range(10):\n",
    "        start_time = time.time()\n",
    "        F.linear(input, sparse_weight, bias)\n",
    "        end_time= time.time()-start_time\n",
    "        avg_times += end_time\n",
    "        return avg_times / 10\n",
    "\n",
    "weights = {\n",
    "    \"CSR\": deepcopy(weight).to_sparse_csr(),\n",
    "    # \"COO\": deepcopy(weight).to_sparse(),\n",
    "    \"CSC\": deepcopy(weight).to_sparse_csc(),\n",
    "    # \"BSR\": deepcopy(weight).to_sparse_bsr(blocksize=weight.shape[1]),\n",
    "    # \"BSC\": deepcopy(weight).to_sparse_bsc(blocksize=weight.shape[0]),\n",
    "}\n",
    "\n",
    "times = {k: None for k in weights.keys()}\n",
    "for sparse_type, sparse_weight in weights.items():\n",
    "    times[sparse_type] = timeit(input, sparse_weight, bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CSR': 2.8347969055175783e-05, 'CSC': 0.0002107858657836914}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiheadAttention(\n",
       "  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha = model.get_submodule(\"encoder.layers.encoder_layer_0.self_attention\")\n",
    "mha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2304, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha.in_proj_weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2304])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha.in_proj_bias.shape # TODO: Check for other weight tensors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=3072, bias=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_mlp = model.get_submodule(\"encoder.layers.encoder_layer_11.mlp.0\") # with full dim\n",
    "last_mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_proj = pruner.model.get_submodule(\"conv_proj\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_shape_hook_wrapper(name, mod):\n",
    "    def forward_shape_print_name_and_shape(mod, input, output):\n",
    "        out_str = f\"{name} ({type(mod)}): \"\n",
    "        if isinstance(input, torch.Tensor):\n",
    "            out_str+= f\"input: {input.shape} \"\n",
    "        else:\n",
    "            # out_str += f\"input: tuple of len {len(input)} and types {[type(i) for i in input]} \"\n",
    "            out_str += f\"input: {input[0].shape} \"\n",
    "        if isinstance(output, torch.Tensor):\n",
    "            out_str+= f\"output: {output.shape}\"\n",
    "        else:\n",
    "            # out_str += f\"output: tuple of len {len(output)} and types {[type(o) for o in output] \"\n",
    "            out_str += f\"output: {output[0].shape}\"\n",
    "        print(out_str)\n",
    "    return mod.register_forward_hook(forward_shape_print_name_and_shape)\n",
    "\n",
    "def register_name_shape_hook(model):\n",
    "    handles = []\n",
    "    for name, mod in model.named_modules():\n",
    "        handles.append(name_shape_hook_wrapper(name, mod))\n",
    "    return handles\n",
    "    \n",
    "hook_handles = register_name_shape_hook(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for handle in hook_handles:\n",
    "    handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_shape_print_hook(mod, input, output):\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        print(output.shape)\n",
    "    else:\n",
    "        print(type(output))\n",
    "        print(type(output[0]))\n",
    "        print(len(output))\n",
    "    return\n",
    "\n",
    "# torch.nn.modules.module.register_module_forward_hook(hook=forward_shape_print_hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4669, -1.9827, -0.8106,  ...,  0.3903, -0.3514, -0.2533],\n",
       "        [-0.2506, -0.8067, -0.7103,  ...,  0.9283,  0.7639, -0.6380],\n",
       "        [-0.2412,  0.6987, -0.0702,  ..., -0.0955,  0.2996, -0.4532],\n",
       "        ...,\n",
       "        [-0.5247,  0.3879, -0.1624,  ..., -0.1820,  0.4795, -0.7372],\n",
       "        [-0.4513, -0.1538,  0.5415,  ...,  0.6702,  1.7572, -0.5415],\n",
       "        [ 0.2813, -0.4152, -0.1504,  ...,  0.2948, -1.0811, -0.6731]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conv_proj\n",
      "encoder\n",
      "encoder.dropout\n",
      "encoder.layers\n",
      "encoder.layers.encoder_layer_0\n",
      "encoder.layers.encoder_layer_0.ln_1\n",
      "encoder.layers.encoder_layer_0.self_attention\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_0.dropout\n",
      "encoder.layers.encoder_layer_0.ln_2\n",
      "encoder.layers.encoder_layer_0.mlp\n",
      "encoder.layers.encoder_layer_0.mlp.0\n",
      "encoder.layers.encoder_layer_0.mlp.1\n",
      "encoder.layers.encoder_layer_0.mlp.2\n",
      "encoder.layers.encoder_layer_0.mlp.3\n",
      "encoder.layers.encoder_layer_0.mlp.4\n",
      "encoder.layers.encoder_layer_1\n",
      "encoder.layers.encoder_layer_1.ln_1\n",
      "encoder.layers.encoder_layer_1.self_attention\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_1.dropout\n",
      "encoder.layers.encoder_layer_1.ln_2\n",
      "encoder.layers.encoder_layer_1.mlp\n",
      "encoder.layers.encoder_layer_1.mlp.0\n",
      "encoder.layers.encoder_layer_1.mlp.1\n",
      "encoder.layers.encoder_layer_1.mlp.2\n",
      "encoder.layers.encoder_layer_1.mlp.3\n",
      "encoder.layers.encoder_layer_1.mlp.4\n",
      "encoder.layers.encoder_layer_2\n",
      "encoder.layers.encoder_layer_2.ln_1\n",
      "encoder.layers.encoder_layer_2.self_attention\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_2.dropout\n",
      "encoder.layers.encoder_layer_2.ln_2\n",
      "encoder.layers.encoder_layer_2.mlp\n",
      "encoder.layers.encoder_layer_2.mlp.0\n",
      "encoder.layers.encoder_layer_2.mlp.1\n",
      "encoder.layers.encoder_layer_2.mlp.2\n",
      "encoder.layers.encoder_layer_2.mlp.3\n",
      "encoder.layers.encoder_layer_2.mlp.4\n",
      "encoder.layers.encoder_layer_3\n",
      "encoder.layers.encoder_layer_3.ln_1\n",
      "encoder.layers.encoder_layer_3.self_attention\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_3.dropout\n",
      "encoder.layers.encoder_layer_3.ln_2\n",
      "encoder.layers.encoder_layer_3.mlp\n",
      "encoder.layers.encoder_layer_3.mlp.0\n",
      "encoder.layers.encoder_layer_3.mlp.1\n",
      "encoder.layers.encoder_layer_3.mlp.2\n",
      "encoder.layers.encoder_layer_3.mlp.3\n",
      "encoder.layers.encoder_layer_3.mlp.4\n",
      "encoder.layers.encoder_layer_4\n",
      "encoder.layers.encoder_layer_4.ln_1\n",
      "encoder.layers.encoder_layer_4.self_attention\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_4.dropout\n",
      "encoder.layers.encoder_layer_4.ln_2\n",
      "encoder.layers.encoder_layer_4.mlp\n",
      "encoder.layers.encoder_layer_4.mlp.0\n",
      "encoder.layers.encoder_layer_4.mlp.1\n",
      "encoder.layers.encoder_layer_4.mlp.2\n",
      "encoder.layers.encoder_layer_4.mlp.3\n",
      "encoder.layers.encoder_layer_4.mlp.4\n",
      "encoder.layers.encoder_layer_5\n",
      "encoder.layers.encoder_layer_5.ln_1\n",
      "encoder.layers.encoder_layer_5.self_attention\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_5.dropout\n",
      "encoder.layers.encoder_layer_5.ln_2\n",
      "encoder.layers.encoder_layer_5.mlp\n",
      "encoder.layers.encoder_layer_5.mlp.0\n",
      "encoder.layers.encoder_layer_5.mlp.1\n",
      "encoder.layers.encoder_layer_5.mlp.2\n",
      "encoder.layers.encoder_layer_5.mlp.3\n",
      "encoder.layers.encoder_layer_5.mlp.4\n",
      "encoder.layers.encoder_layer_6\n",
      "encoder.layers.encoder_layer_6.ln_1\n",
      "encoder.layers.encoder_layer_6.self_attention\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_6.dropout\n",
      "encoder.layers.encoder_layer_6.ln_2\n",
      "encoder.layers.encoder_layer_6.mlp\n",
      "encoder.layers.encoder_layer_6.mlp.0\n",
      "encoder.layers.encoder_layer_6.mlp.1\n",
      "encoder.layers.encoder_layer_6.mlp.2\n",
      "encoder.layers.encoder_layer_6.mlp.3\n",
      "encoder.layers.encoder_layer_6.mlp.4\n",
      "encoder.layers.encoder_layer_7\n",
      "encoder.layers.encoder_layer_7.ln_1\n",
      "encoder.layers.encoder_layer_7.self_attention\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_7.dropout\n",
      "encoder.layers.encoder_layer_7.ln_2\n",
      "encoder.layers.encoder_layer_7.mlp\n",
      "encoder.layers.encoder_layer_7.mlp.0\n",
      "encoder.layers.encoder_layer_7.mlp.1\n",
      "encoder.layers.encoder_layer_7.mlp.2\n",
      "encoder.layers.encoder_layer_7.mlp.3\n",
      "encoder.layers.encoder_layer_7.mlp.4\n",
      "encoder.layers.encoder_layer_8\n",
      "encoder.layers.encoder_layer_8.ln_1\n",
      "encoder.layers.encoder_layer_8.self_attention\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_8.dropout\n",
      "encoder.layers.encoder_layer_8.ln_2\n",
      "encoder.layers.encoder_layer_8.mlp\n",
      "encoder.layers.encoder_layer_8.mlp.0\n",
      "encoder.layers.encoder_layer_8.mlp.1\n",
      "encoder.layers.encoder_layer_8.mlp.2\n",
      "encoder.layers.encoder_layer_8.mlp.3\n",
      "encoder.layers.encoder_layer_8.mlp.4\n",
      "encoder.layers.encoder_layer_9\n",
      "encoder.layers.encoder_layer_9.ln_1\n",
      "encoder.layers.encoder_layer_9.self_attention\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_9.dropout\n",
      "encoder.layers.encoder_layer_9.ln_2\n",
      "encoder.layers.encoder_layer_9.mlp\n",
      "encoder.layers.encoder_layer_9.mlp.0\n",
      "encoder.layers.encoder_layer_9.mlp.1\n",
      "encoder.layers.encoder_layer_9.mlp.2\n",
      "encoder.layers.encoder_layer_9.mlp.3\n",
      "encoder.layers.encoder_layer_9.mlp.4\n",
      "encoder.layers.encoder_layer_10\n",
      "encoder.layers.encoder_layer_10.ln_1\n",
      "encoder.layers.encoder_layer_10.self_attention\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_10.dropout\n",
      "encoder.layers.encoder_layer_10.ln_2\n",
      "encoder.layers.encoder_layer_10.mlp\n",
      "encoder.layers.encoder_layer_10.mlp.0\n",
      "encoder.layers.encoder_layer_10.mlp.1\n",
      "encoder.layers.encoder_layer_10.mlp.2\n",
      "encoder.layers.encoder_layer_10.mlp.3\n",
      "encoder.layers.encoder_layer_10.mlp.4\n",
      "encoder.layers.encoder_layer_11\n",
      "encoder.layers.encoder_layer_11.ln_1\n",
      "encoder.layers.encoder_layer_11.self_attention\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj\n",
      "encoder.layers.encoder_layer_11.dropout\n",
      "encoder.layers.encoder_layer_11.ln_2\n",
      "encoder.layers.encoder_layer_11.mlp\n",
      "encoder.layers.encoder_layer_11.mlp.0\n",
      "encoder.layers.encoder_layer_11.mlp.1\n",
      "encoder.layers.encoder_layer_11.mlp.2\n",
      "encoder.layers.encoder_layer_11.mlp.3\n",
      "encoder.layers.encoder_layer_11.mlp.4\n",
      "encoder.ln\n",
      "heads\n",
      "heads.head\n"
     ]
    }
   ],
   "source": [
    "for name, mod in pruner.model.named_modules():\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigLScheduler(\n",
      "layers=38,\n",
      "nonzero_params=[58898/589824, 58558/589824, 235644/2359296, 235904/2359296, 58560/589824, 235818/2359296, 235770/2359296, 58800/589824, 235037/2359296, 235635/2359296, 58764/589824, 235428/2359296, 235620/2359296, 58801/589824, 235366/2359296, 235641/2359296, 58855/589824, 235521/2359296, 235620/2359296, 58982/589824, 235858/2359296, 235704/2359296, 58671/589824, 235445/2359296, 235809/2359296, 58800/589824, 235807/2359296, 235704/2359296, 58820/589824, 235440/2359296, 235840/2359296, 58643/589824, 235054/2359296, 235776/2359296, 58680/589824, 235870/2359296, 235638/2359296, 76000/768000],\n",
      "nonzero_percentages=[9.99%, 9.93%, 9.99%, 10.00%, 9.93%, 10.00%, 9.99%, 9.97%, 9.96%, 9.99%, 9.96%, 9.98%, 9.99%, 9.97%, 9.98%, 9.99%, 9.98%, 9.98%, 9.99%, 10.00%, 10.00%, 9.99%, 9.95%, 9.98%, 9.99%, 9.97%, 9.99%, 9.99%, 9.97%, 9.98%, 10.00%, 9.94%, 9.96%, 9.99%, 9.95%, 10.00%, 9.99%, 9.90%],\n",
      "total_nonzero_params=6494781/65058816 (9.98%),\n",
      "total_CONV_nonzero_params=763832/7667712 (9.96%),\n",
      "step=46919,\n",
      "num_rigl_steps=351,\n",
      "ignoring_linear_layers=False,\n",
      "sparsity_distribution=uniform,\n",
      "ITOP rate=0.3650,\n",
      "Active Neuron Count=[(601, 768), (437, 768), (1076, 3072), (608, 768), (488, 768), (794, 3072), (542, 768), (490, 768), (929, 3072), (345, 768), (498, 768), (853, 3072), (340, 768), (463, 768), (859, 3072), (343, 768), (395, 768), (793, 3072), (330, 768), (383, 768), (991, 3072), (366, 768), (369, 768), (1085, 3072), (399, 768), (350, 768), (1067, 3072), (366, 768), (346, 768), (1080, 3072), (335, 768), (347, 768), (1114, 3072), (307, 768), (360, 768), (1145, 3072), (318, 768), (1000, 1000)],\n",
      "constant fan ins=[98, 134, 219, 388, 120, 297, 435, 120, 253, 683, 118, 276, 693, 127, 274, 687, 149, 297, 714, 154, 238, 644, 159, 217, 591, 168, 221, 644, 170, 218, 704, 169, 211, 768, 163, 206, 741, 76]\n",
      "Neurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Neurons Dynamically Ablated per layer = [167, 331, 1996, 160, 280, 2278, 226, 278, 2143, 423, 270, 2219, 428, 305, 2213, 425, 373, 2279, 438, 385, 2081, 402, 399, 1987, 369, 418, 2005, 402, 422, 1992, 433, 421, 1958, 461, 408, 1927, 450, 0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pruner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conv_proj tensor(167, device='cuda:0')\n",
      "1 out_proj tensor(331, device='cuda:0')\n",
      "2 0 tensor(1996, device='cuda:0')\n",
      "3 3 tensor(160, device='cuda:0')\n",
      "4 out_proj tensor(280, device='cuda:0')\n",
      "5 0 tensor(2278, device='cuda:0')\n",
      "6 3 tensor(226, device='cuda:0')\n",
      "7 out_proj tensor(278, device='cuda:0')\n",
      "8 0 tensor(2143, device='cuda:0')\n",
      "9 3 tensor(423, device='cuda:0')\n",
      "10 out_proj tensor(270, device='cuda:0')\n",
      "11 0 tensor(2219, device='cuda:0')\n",
      "12 3 tensor(428, device='cuda:0')\n",
      "13 out_proj tensor(305, device='cuda:0')\n",
      "14 0 tensor(2213, device='cuda:0')\n",
      "15 3 tensor(425, device='cuda:0')\n",
      "16 out_proj tensor(373, device='cuda:0')\n",
      "17 0 tensor(2279, device='cuda:0')\n",
      "18 3 tensor(438, device='cuda:0')\n",
      "19 out_proj tensor(385, device='cuda:0')\n",
      "20 0 tensor(2081, device='cuda:0')\n",
      "21 3 tensor(402, device='cuda:0')\n",
      "22 out_proj tensor(399, device='cuda:0')\n",
      "23 0 tensor(1987, device='cuda:0')\n",
      "24 3 tensor(369, device='cuda:0')\n",
      "25 out_proj tensor(418, device='cuda:0')\n",
      "26 0 tensor(2005, device='cuda:0')\n",
      "27 3 tensor(402, device='cuda:0')\n",
      "28 out_proj tensor(422, device='cuda:0')\n",
      "29 0 tensor(1992, device='cuda:0')\n",
      "30 3 tensor(433, device='cuda:0')\n",
      "31 out_proj tensor(421, device='cuda:0')\n",
      "32 0 tensor(1958, device='cuda:0')\n",
      "33 3 tensor(461, device='cuda:0')\n",
      "34 out_proj tensor(408, device='cuda:0')\n",
      "35 0 tensor(1927, device='cuda:0')\n",
      "36 3 tensor(450, device='cuda:0')\n",
      "37 head tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for idx, (layer_name, ablated_filters) in enumerate(zip(pruner.module_names, pruner.ablated_filters[1])):\n",
    "    print(idx, layer_name, ablated_filters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = model.get_submodule(\"encoder.layers.encoder_layer_11.mlp.0\")\n",
    "(mod.weight.sum(dim=1) !=0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 768])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1076, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mask = pruner.backward_masks[2]\n",
    "non_zero_idx = target_mask[target_mask.sum(dim=1) != 0]\n",
    "non_zero_idx.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 197, 3072])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(size=(8, 197, 3072)).to(device)\n",
    "input.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_input = input[:, :, target_mask.sum(dim=1) != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 197, 1076])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_input.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 197, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(condensed_input @ non_zero_idx.to(torch.float)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 197, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(condensed_input @ non_zero_idx.to(torch.float)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-433973.0625, device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(condensed_input @ non_zero_idx.to(torch.float)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 197, 768])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input @ target_mask.to(torch.float)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-433973., device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(input @ target_mask.to(torch.float)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 3, 16, 16])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 3, 16, 16])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv_proj.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'torchvision.models.vision_transformer.VisionTransformer'>\n",
      "conv_proj\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "encoder\n",
      "<class 'torchvision.models.vision_transformer.Encoder'>\n",
      "encoder.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "encoder.layers.encoder_layer_0\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_0.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_0.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_0.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_0.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_0.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_0.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_0.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_0.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_0.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_0.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_1\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_1.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_1.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_1.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_1.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_1.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_1.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_1.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_1.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_1.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_1.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_2\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_2.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_2.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_2.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_2.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_2.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_2.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_2.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_2.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_2.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_2.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_3\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_3.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_3.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_3.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_3.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_3.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_3.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_3.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_3.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_3.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_3.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_4\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_4.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_4.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_4.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_4.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_4.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_4.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_4.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_4.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_4.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_4.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_5\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_5.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_5.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_5.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_5.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_5.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_5.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_5.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_5.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_5.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_5.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_6\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_6.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_6.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_6.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_6.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_6.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_6.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_6.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_6.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_6.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_6.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_7\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_7.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_7.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_7.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_7.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_7.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_7.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_7.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_7.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_7.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_7.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_8\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_8.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_8.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_8.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_8.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_8.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_8.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_8.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_8.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_8.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_8.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_9\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_9.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_9.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_9.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_9.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_9.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_9.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_9.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_9.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_9.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_9.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_10\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_10.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_10.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_10.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_10.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_10.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_10.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_10.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_10.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_10.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_10.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_11\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_11.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_11.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_11.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_11.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_11.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_11.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_11.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_11.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_11.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_11.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.ln\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "heads\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "heads.head\n",
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for ii, (n,m) in enumerate(model.named_modules()):\n",
    "    print(n)\n",
    "    print(type(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from torch.nn.modules.linear import NonDynamicallyQuantizableLinear\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class CondensedLinear(nn.Module):\n",
    "    # __TARGET_TYPES = [nn.Linear, NonDynamicallyQuantizableLinear]\n",
    "    __TARGET_TYPES = [nn.Linear]\n",
    "    # __constants__ = ['in_features', 'out_features', \"active_neuron_idx\", \"fine_grained_idx\"]\n",
    "    # __constants__ = [\"active_neuron_idx\", \"fine_grained_idx\"]\n",
    "    # in_features: int\n",
    "    # out_features: int\n",
    "    active_neuron_idx: torch.Tensor\n",
    "    fine_grained_idx: torch.Tensor\n",
    "    weight: torch.Tensor\n",
    "    \n",
    "    def __init__(self, module: nn.Module):\n",
    "        super().__init__()\n",
    "        self._register_idx(module)\n",
    "        with torch.no_grad():\n",
    "            self.weight = module.weight[self.active_neuron_idx]\n",
    "            self.condensed_weight = self.weight[self.fine_grained_idx].reshape(shape=(self.weight.shape[0], -1))\n",
    "            if hasattr(module, \"bias\"):\n",
    "                self.bias = module.bias[self.active_neuron_idx]\n",
    "            else:\n",
    "                self.register_parameter(\"bias\", None)\n",
    "        # self.in_features = module.in_features\n",
    "        # self.out_features=module.out_features\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _register_idx(self, module):\n",
    "        self.active_neuron_idx = module.weight.sum(dim=1) != 0\n",
    "        self.fine_grained_idx = (module.weight[self.active_neuron_idx] != 0).to(torch.bool)\n",
    "        _, self.input_mask = self.fine_grained_idx.nonzero(as_tuple=True)\n",
    "        self.input_mask = self.input_mask.reshape(shape=(module.weight[self.active_neuron_idx].shape[0], -1))\n",
    "\n",
    "    # @torch.jit\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # print(f\"Shape of condensed linear weight: {self.weight.shape}\")\n",
    "        # print(f\"shape of input: {input.shape}\")\n",
    "        # print(f\"active_neuron_idx shape: {self.active_neuron_idx.shape}\")\n",
    "        # print(f\"Shape of input after condensing: {input[:,:,self.active_neuron_idx].shape}\") \n",
    "        # return F.linear(input[:,:,self.active_neuron_idx], self.weight, self.bias) \n",
    "        return F.linear(input, self.weight, self.bias) \n",
    "    \n",
    "    def fine_grained_forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.sum(self.condensed_weight * input[:, self.input_mask], axis=2) + self.bias\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        out_features, in_features = self.weight.shape\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            in_features, out_features, self.bias is not None\n",
    "        )\n",
    "        \n",
    "\n",
    "    @classmethod\n",
    "    def convert_condensed_linear(cls, module):\n",
    "        # Based on convert_sync_batchnorm\n",
    "        module_output = module\n",
    "        if type(module) in cls.__TARGET_TYPES:\n",
    "            module_output = CondensedLinear(module)\n",
    "            if hasattr(module, \"qconfig\"):\n",
    "                module_output.qconfig = module.qconfig\n",
    "        for name, child in module.named_children():\n",
    "            module_output.add_module(\n",
    "                name, cls.convert_condensed_linear(child)\n",
    "            )\n",
    "        del module\n",
    "        return module_output\n",
    "        \n",
    "    \n",
    "# condensed_linear = CondensedLinear.convert_condensed_linear(deepcopy(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_mlp_dense = deepcopy(last_mlp)\n",
    "condensed_mlp = CondensedLinear.convert_condensed_linear(deepcopy(last_mlp))\n",
    "input = torch.rand(size=(128,768)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007038116455078125\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "with torch.no_grad():\n",
    "    start_time=time.time()\n",
    "    _ = last_mlp_dense(input)\n",
    "    end_time = time.time() - start_time\n",
    "print(end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012509822845458984\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start_time=time.time()\n",
    "    _ = condensed_mlp(input)\n",
    "    end_time = time.time() - start_time\n",
    "print(end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021371841430664062\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start_time=time.time()\n",
    "    _ = condensed_mlp.fine_grained_forward(input)\n",
    "    end_time = time.time() - start_time\n",
    "print(end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([235870])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_mlp.input_mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 235870])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[:, condensed_mlp.input_mask].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_mlp_jit = torch.jit.script(condensed_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020494461059570312\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start_time=time.time()\n",
    "    _ = condensed_mlp_jit(input)\n",
    "    end_time = time.time() - start_time\n",
    "print(end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020651817321777344\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start_time=time.time()\n",
    "    _ = condensed_mlp.fine_grained_forward(input)\n",
    "    end_time = time.time() - start_time\n",
    "print(end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1145, 206])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_mlp.condensed_weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 76])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=3072, bias=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_mlp_dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 768, 14, 14])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 3072])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 1000])\n",
      "torch.Size([8, 1000])\n",
      "torch.Size([8, 1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4669, -1.9827, -0.8106,  ...,  0.3903, -0.3514, -0.2533],\n",
       "        [-0.2506, -0.8067, -0.7103,  ...,  0.9283,  0.7639, -0.6380],\n",
       "        [-0.2412,  0.6987, -0.0702,  ..., -0.0955,  0.2996, -0.4532],\n",
       "        ...,\n",
       "        [-0.5247,  0.3879, -0.1624,  ..., -0.1820,  0.4795, -0.7372],\n",
       "        [-0.4513, -0.1538,  0.5415,  ...,  0.6702,  1.7572, -0.5415],\n",
       "        [ 0.2813, -0.4152, -0.1504,  ...,  0.2948, -1.0811, -0.6731]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 768, 14, 14])\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "<class 'tuple'>\n",
      "<class 'torch.Tensor'>\n",
      "2\n",
      "torch.Size([8, 197, 768])\n",
      "torch.Size([8, 197, 768])\n",
      "Shape of condensed linear weight: torch.Size([1076, 768])\n",
      "shape of input: torch.Size([8, 197, 768])\n",
      "active_neuron_idx shape: torch.Size([3072])\n",
      "torch.Size([8, 197, 1076])\n",
      "torch.Size([8, 197, 1076])\n",
      "torch.Size([8, 197, 1076])\n",
      "Shape of condensed linear weight: torch.Size([608, 3072])\n",
      "shape of input: torch.Size([8, 197, 1076])\n",
      "active_neuron_idx shape: torch.Size([768])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1576x1076 and 3072x608)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/user/condensed-sparsity/notebooks/main.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f2d7461696c7363616c65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#Y324sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m condensed_linear(x\u001b[39m.\u001b[39;49mto(device))\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py:298\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    295\u001b[0m batch_class_token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_token\u001b[39m.\u001b[39mexpand(n, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    296\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([batch_class_token, x], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 298\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m    300\u001b[0m \u001b[39m# Classifier \"token\" as used by standard language architectures\u001b[39;00m\n\u001b[1;32m    301\u001b[0m x \u001b[39m=\u001b[39m x[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py:157\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    155\u001b[0m torch\u001b[39m.\u001b[39m_assert(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected (batch_size, seq_length, hidden_dim) got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_embedding\n\u001b[0;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m)))\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py:118\u001b[0m, in \u001b[0;36mEncoderBlock.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[1;32m    117\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(x)\n\u001b[0;32m--> 118\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(y)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m x \u001b[39m+\u001b[39m y\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[1;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[1;32m   1543\u001b[0m     ):\n",
      "\u001b[1;32m/home/user/condensed-sparsity/notebooks/main.ipynb Cell 28\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f2d7461696c7363616c65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#Y324sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactive_neuron_idx shape: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_neuron_idx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f2d7461696c7363616c65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#Y324sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# print(f\"Shape of input after condensing: {input[:,:,self.active_neuron_idx].shape}\") \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f2d7461696c7363616c65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#Y324sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# return F.linear(input[:,:,self.active_neuron_idx], self.weight, self.bias) \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f2d7461696c7363616c65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#Y324sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1576x1076 and 3072x608)"
     ]
    }
   ],
   "source": [
    "condensed_linear(x.to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condensed_mod = condensed_linear.get_submodule(\"encoder.layers.encoder_layer_11.mlp.0\")\n",
    "mod = model.get_submodule(\"encoder.layers.encoder_layer_11.mlp.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1145, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condensed_mod.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3072, 3072])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(size=(8,768,3072)).to(device)\n",
    "\n",
    "(mod.weight @ input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1145, 3072])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.rand(size=(8,768,3072)).to(device)\n",
    "\n",
    "(condensed_mod.weight @ input).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = model.get_submodule(\"encoder.layers.encoder_layer_0.self_attention.out_proj\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.weight.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_loader:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 478, 640])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe1fa63cdc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.axis(False)\n",
    "plt.imshow(x[0].permute(1,2,0))\n",
    "\n",
    "# plt.imshow(x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['segmentation', 'area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'id', 'boxes', 'masks', 'labels'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0][1].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Image([[[0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],\n",
       "         [0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],\n",
       "         [0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],\n",
       "         ...,\n",
       "         [0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],\n",
       "         [0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824],\n",
       "         [0.4824, 0.4824, 0.4824,  ..., 0.4824, 0.4824, 0.4824]],\n",
       " \n",
       "        [[0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4588],\n",
       "         [0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4588],\n",
       "         [0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4588],\n",
       "         ...,\n",
       "         [0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4588],\n",
       "         [0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4588],\n",
       "         [0.4588, 0.4588, 0.4588,  ..., 0.4588, 0.4588, 0.4588]],\n",
       " \n",
       "        [[0.4078, 0.4078, 0.4078,  ..., 0.4078, 0.4078, 0.4078],\n",
       "         [0.4078, 0.4078, 0.4078,  ..., 0.4078, 0.4078, 0.4078],\n",
       "         [0.4078, 0.4078, 0.4078,  ..., 0.4078, 0.4078, 0.4078],\n",
       "         ...,\n",
       "         [0.4078, 0.4078, 0.4078,  ..., 0.4078, 0.4078, 0.4078],\n",
       "         [0.4078, 0.4078, 0.4078,  ..., 0.4078, 0.4078, 0.4078],\n",
       "         [0.4078, 0.4078, 0.4078,  ..., 0.4078, 0.4078, 0.4078]]], ),\n",
       " {'segmentation': [[[125.83,\n",
       "     215.19,\n",
       "     113.98,\n",
       "     219.75,\n",
       "     106.68,\n",
       "     221.57,\n",
       "     93.92,\n",
       "     217.93,\n",
       "     56.53,\n",
       "     215.19,\n",
       "     55.62,\n",
       "     204.25,\n",
       "     66.56,\n",
       "     194.22,\n",
       "     72.95,\n",
       "     186.01,\n",
       "     113.07,\n",
       "     186.92,\n",
       "     131.3,\n",
       "     195.13,\n",
       "     141.33,\n",
       "     197.87]],\n",
       "   [[527.69,\n",
       "     188.59,\n",
       "     516.02,\n",
       "     189.45,\n",
       "     515.17,\n",
       "     189.45,\n",
       "     514.32,\n",
       "     192.01,\n",
       "     514.6,\n",
       "     194.85,\n",
       "     515.17,\n",
       "     195.99,\n",
       "     517.45,\n",
       "     197.98,\n",
       "     522.85,\n",
       "     196.56,\n",
       "     527.69,\n",
       "     196.56,\n",
       "     534.52,\n",
       "     196.56,\n",
       "     538.22,\n",
       "     196.56,\n",
       "     539.64,\n",
       "     196.56,\n",
       "     540.5,\n",
       "     195.42,\n",
       "     540.78,\n",
       "     194.29,\n",
       "     541.92,\n",
       "     194.29,\n",
       "     543.91,\n",
       "     194.29,\n",
       "     546.47,\n",
       "     194.29,\n",
       "     547.33,\n",
       "     191.72,\n",
       "     549.03,\n",
       "     189.16,\n",
       "     549.32,\n",
       "     188.31,\n",
       "     548.18,\n",
       "     186.6,\n",
       "     546.76,\n",
       "     183.76,\n",
       "     543.63,\n",
       "     180.34,\n",
       "     541.63,\n",
       "     179.77,\n",
       "     537.93,\n",
       "     179.77,\n",
       "     531.39,\n",
       "     180.06,\n",
       "     528.83,\n",
       "     180.06,\n",
       "     526.84,\n",
       "     180.34,\n",
       "     526.84,\n",
       "     180.34,\n",
       "     525.98,\n",
       "     180.91,\n",
       "     526.55,\n",
       "     181.76,\n",
       "     531.1,\n",
       "     182.05,\n",
       "     539.93,\n",
       "     181.48,\n",
       "     539.36,\n",
       "     183.19,\n",
       "     537.08,\n",
       "     186.6,\n",
       "     528.54,\n",
       "     190.02]],\n",
       "   [[487.27, 176.35, 502.59, 175.8, 507.79, 181.55, 484.53, 181.28],\n",
       "    [509.16,\n",
       "     189.76,\n",
       "     509.16,\n",
       "     194.68,\n",
       "     506.97,\n",
       "     196.05,\n",
       "     504.78,\n",
       "     194.41,\n",
       "     501.49,\n",
       "     196.6,\n",
       "     497.39,\n",
       "     197.15,\n",
       "     494.11,\n",
       "     195.78,\n",
       "     491.37,\n",
       "     195.5,\n",
       "     486.44,\n",
       "     195.5,\n",
       "     485.08,\n",
       "     196.6,\n",
       "     482.07,\n",
       "     198.51,\n",
       "     479.06,\n",
       "     197.42,\n",
       "     478.51,\n",
       "     194.14,\n",
       "     479.33,\n",
       "     187.29,\n",
       "     502.31,\n",
       "     186.47,\n",
       "     509.43,\n",
       "     187.29]],\n",
       "   [[124.14,\n",
       "     236.35,\n",
       "     130.83,\n",
       "     215.34,\n",
       "     142.29,\n",
       "     200.06,\n",
       "     151.84,\n",
       "     189.56,\n",
       "     160.43,\n",
       "     180.96,\n",
       "     170.94,\n",
       "     175.23,\n",
       "     176.67,\n",
       "     173.32,\n",
       "     182.4,\n",
       "     171.41,\n",
       "     184.31,\n",
       "     5.25,\n",
       "     209.14,\n",
       "     0.48,\n",
       "     222.5,\n",
       "     94.06,\n",
       "     222.5,\n",
       "     116.03,\n",
       "     220.59,\n",
       "     156.14,\n",
       "     229.19,\n",
       "     159.0,\n",
       "     241.6,\n",
       "     152.32,\n",
       "     252.11,\n",
       "     142.77,\n",
       "     260.7,\n",
       "     125.58,\n",
       "     270.25,\n",
       "     102.66,\n",
       "     307.5,\n",
       "     98.84,\n",
       "     371.48,\n",
       "     96.93,\n",
       "     395.35,\n",
       "     95.97,\n",
       "     401.08,\n",
       "     103.61,\n",
       "     406.81,\n",
       "     114.12,\n",
       "     413.5,\n",
       "     144.68,\n",
       "     415.41,\n",
       "     175.23,\n",
       "     414.45,\n",
       "     202.93,\n",
       "     419.23,\n",
       "     233.49,\n",
       "     426.86,\n",
       "     247.81,\n",
       "     640.0,\n",
       "     228.71,\n",
       "     637.91,\n",
       "     275.5,\n",
       "     504.22,\n",
       "     296.51,\n",
       "     502.31,\n",
       "     333.76,\n",
       "     505.17,\n",
       "     338.53,\n",
       "     522.36,\n",
       "     334.71,\n",
       "     527.14,\n",
       "     334.71,\n",
       "     528.09,\n",
       "     347.13,\n",
       "     528.09,\n",
       "     357.63,\n",
       "     526.18,\n",
       "     371.0,\n",
       "     526.18,\n",
       "     389.14,\n",
       "     526.18,\n",
       "     400.6,\n",
       "     526.18,\n",
       "     404.42,\n",
       "     518.54,\n",
       "     405.38,\n",
       "     504.22,\n",
       "     404.42,\n",
       "     488.94,\n",
       "     384.37,\n",
       "     485.12,\n",
       "     361.45,\n",
       "     487.98,\n",
       "     353.81,\n",
       "     487.98,\n",
       "     292.69,\n",
       "     373.39,\n",
       "     306.06,\n",
       "     369.57,\n",
       "     307.02,\n",
       "     452.65,\n",
       "     371.0,\n",
       "     450.74,\n",
       "     377.68,\n",
       "     339.01,\n",
       "     336.62,\n",
       "     322.77,\n",
       "     340.44,\n",
       "     295.08,\n",
       "     348.08,\n",
       "     295.08,\n",
       "     371.95,\n",
       "     289.35,\n",
       "     389.14,\n",
       "     289.35,\n",
       "     399.65,\n",
       "     296.04,\n",
       "     405.38,\n",
       "     303.68,\n",
       "     418.75,\n",
       "     261.66,\n",
       "     416.84,\n",
       "     263.57,\n",
       "     407.29,\n",
       "     268.34,\n",
       "     398.69,\n",
       "     273.12,\n",
       "     360.5,\n",
       "     233.01,\n",
       "     347.13,\n",
       "     208.18,\n",
       "     335.67,\n",
       "     212.95,\n",
       "     353.81,\n",
       "     211.05,\n",
       "     360.5,\n",
       "     201.5,\n",
       "     360.5,\n",
       "     200.54,\n",
       "     361.45,\n",
       "     200.54,\n",
       "     375.77,\n",
       "     193.86,\n",
       "     381.5,\n",
       "     184.31,\n",
       "     384.37,\n",
       "     173.8,\n",
       "     381.5,\n",
       "     173.8,\n",
       "     380.55,\n",
       "     167.12,\n",
       "     371.95,\n",
       "     167.12,\n",
       "     362.41,\n",
       "     168.07,\n",
       "     351.9,\n",
       "     169.98,\n",
       "     339.49,\n",
       "     177.62,\n",
       "     329.94,\n",
       "     181.44,\n",
       "     325.16,\n",
       "     181.44,\n",
       "     318.48,\n",
       "     160.43,\n",
       "     295.56,\n",
       "     155.66,\n",
       "     288.87,\n",
       "     55.39,\n",
       "     348.08,\n",
       "     19.1,\n",
       "     364.32,\n",
       "     10.5,\n",
       "     363.36,\n",
       "     10.5,\n",
       "     352.86,\n",
       "     65.89,\n",
       "     304.15,\n",
       "     79.26,\n",
       "     290.78,\n",
       "     90.72,\n",
       "     280.28,\n",
       "     111.73,\n",
       "     274.55,\n",
       "     120.32,\n",
       "     265.95,\n",
       "     4.77,\n",
       "     246.86,\n",
       "     2.86,\n",
       "     210.57,\n",
       "     42.97,\n",
       "     212.48,\n",
       "     98.36,\n",
       "     226.8,\n",
       "     111.73,\n",
       "     226.8]],\n",
       "   [[544.07,\n",
       "     176.06,\n",
       "     545.88,\n",
       "     172.8,\n",
       "     550.66,\n",
       "     172.31,\n",
       "     552.19,\n",
       "     175.16,\n",
       "     551.91,\n",
       "     177.38,\n",
       "     551.49,\n",
       "     178.21,\n",
       "     546.22,\n",
       "     178.48,\n",
       "     545.46,\n",
       "     177.58,\n",
       "     544.35,\n",
       "     177.86,\n",
       "     544.07,\n",
       "     176.27,\n",
       "     544.07,\n",
       "     176.27]],\n",
       "   [[533.66,\n",
       "     176.08,\n",
       "     533.69,\n",
       "     178.0,\n",
       "     534.77,\n",
       "     177.91,\n",
       "     535.58,\n",
       "     176.54,\n",
       "     538.69,\n",
       "     176.25,\n",
       "     539.62,\n",
       "     176.57,\n",
       "     539.77,\n",
       "     178.11,\n",
       "     540.73,\n",
       "     177.74,\n",
       "     541.05,\n",
       "     175.5,\n",
       "     541.11,\n",
       "     173.23,\n",
       "     539.89,\n",
       "     171.92,\n",
       "     536.72,\n",
       "     171.63,\n",
       "     534.53,\n",
       "     171.51,\n",
       "     533.95,\n",
       "     172.73]],\n",
       "   [[448.72,\n",
       "     141.6,\n",
       "     594.17,\n",
       "     118.79,\n",
       "     606.53,\n",
       "     135.9,\n",
       "     613.18,\n",
       "     119.74,\n",
       "     640.0,\n",
       "     114.03,\n",
       "     640.0,\n",
       "     91.22,\n",
       "     614.13,\n",
       "     85.51,\n",
       "     477.24,\n",
       "     125.44,\n",
       "     436.36,\n",
       "     132.1,\n",
       "     429.7,\n",
       "     99.77,\n",
       "     425.9,\n",
       "     91.22,\n",
       "     420.2,\n",
       "     95.02,\n",
       "     424.95,\n",
       "     118.79,\n",
       "     428.75,\n",
       "     139.7]],\n",
       "   [[503.75,\n",
       "     174.68,\n",
       "     504.11,\n",
       "     171.06,\n",
       "     504.93,\n",
       "     169.88,\n",
       "     510.36,\n",
       "     170.06,\n",
       "     514.44,\n",
       "     170.24,\n",
       "     516.89,\n",
       "     171.87,\n",
       "     517.61,\n",
       "     172.6,\n",
       "     519.33,\n",
       "     173.32,\n",
       "     519.33,\n",
       "     174.77,\n",
       "     518.52,\n",
       "     175.13,\n",
       "     515.89,\n",
       "     175.23,\n",
       "     514.17,\n",
       "     176.77,\n",
       "     512.54,\n",
       "     177.04,\n",
       "     511.27,\n",
       "     176.77,\n",
       "     509.28,\n",
       "     177.58,\n",
       "     508.37,\n",
       "     177.49,\n",
       "     507.1,\n",
       "     177.22,\n",
       "     506.83,\n",
       "     176.22,\n",
       "     505.11,\n",
       "     175.95]]],\n",
       "  'area': [2152.363800000001,\n",
       "   342.4283999999999,\n",
       "   387.5062500000005,\n",
       "   91138.37400000005,\n",
       "   39.712099999999865,\n",
       "   36.88029999999997,\n",
       "   4649.030900000001,\n",
       "   86.8095],\n",
       "  'iscrowd': [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'image_id': 247,\n",
       "  'bbox': [[55.62, 186.01, 85.71, 35.56],\n",
       "   [514.32, 179.77, 35.0, 18.21],\n",
       "   [478.51, 175.8, 30.92, 22.71],\n",
       "   [2.86, 0.48, 637.14, 418.27],\n",
       "   [544.07, 172.31, 8.12, 6.17],\n",
       "   [533.66, 171.51, 7.45, 6.6],\n",
       "   [420.2, 85.51, 219.8, 56.09],\n",
       "   [503.75, 169.88, 15.58, 7.7]],\n",
       "  'category_id': [3, 3, 3, 5, 3, 3, 5, 3],\n",
       "  'id': [137645, 138411, 139458, 160170, 1342772, 1343931, 1363895, 2043341],\n",
       "  'boxes': BoundingBox([[1350.6200,  585.0100, 1436.3300,  620.5700],\n",
       "               [1809.3201,  578.7700, 1844.3201,  596.9800],\n",
       "               [1773.5100,  574.8000, 1804.4301,  597.5100],\n",
       "               [1297.8600,  399.4800, 1935.0000,  817.7500],\n",
       "               [1839.0701,  571.3100, 1847.1899,  577.4800],\n",
       "               [1828.6599,  570.5100, 1836.1100,  577.1100],\n",
       "               [1715.2000,  484.5100, 1935.0000,  540.6000],\n",
       "               [1798.7500,  568.8800, 1814.3301,  576.5800]], format=BoundingBoxFormat.XYXY, spatial_size=(1409, 2126)),\n",
       "  'masks': Mask([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        ...,\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "  \n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n",
       "  'labels': tensor([3, 3, 3, 5, 3, 3, 5, 3])})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not infer where the labels are in the sample. Try passing a callable as the labels_getter parameter?If there are no samples and it is by design, pass labels_getter=None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i, (x,y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader\u001b[39m.\u001b[39mdataset):\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(i)\n\u001b[1;32m      3\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mboxes\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m y:\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torchvision/datapoints/_dataset_wrapper.py:154\u001b[0m, in \u001b[0;36mVisionDatasetDatapointWrapper.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m# Regardless of whether the user has supplied the transforms individually (`transform` and `target_transform`)\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# or joint (`transforms`), we can access the full functionality through `transforms`\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransforms(\u001b[39m*\u001b[39;49msample)\n\u001b[1;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m sample\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torchvision/transforms/v2/_container.py:51\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     49\u001b[0m sample \u001b[39m=\u001b[39m inputs \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m inputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 51\u001b[0m     sample \u001b[39m=\u001b[39m transform(sample)\n\u001b[1;32m     52\u001b[0m \u001b[39mreturn\u001b[39;00m sample\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torchvision/transforms/v2/_misc.py:356\u001b[0m, in \u001b[0;36mSanitizeBoundingBox.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_labels_getter(inputs)\n\u001b[1;32m    357\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    358\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe labels in the input to forward() must be a tensor, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(labels)\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/condensed-sparsity/.venv/lib/python3.10/site-packages/torchvision/transforms/v2/_misc.py:344\u001b[0m, in \u001b[0;36mSanitizeBoundingBox._find_labels_default_heuristic\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         candidate_key \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(key \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mkeys() \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m key\u001b[39m.\u001b[39mlower())\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m candidate_key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    345\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not infer where the labels are in the sample. Try passing a callable as the labels_getter parameter?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf there are no samples and it is by design, pass labels_getter=None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    348\u001b[0m \u001b[39mreturn\u001b[39;00m inputs[candidate_key]\n",
      "\u001b[0;31mValueError\u001b[0m: Could not infer where the labels are in the sample. Try passing a callable as the labels_getter parameter?If there are no samples and it is by design, pass labels_getter=None."
     ]
    }
   ],
   "source": [
    "for i, (x,y) in enumerate(train_loader.dataset):\n",
    "    print(i)\n",
    "    if 'boxes' not in y:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 3799}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset[265][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(sample):\n",
    "    import PIL\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from torchvision.transforms.v2 import functional as F\n",
    "    from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "    image, target = sample\n",
    "    if isinstance(image, PIL.Image.Image):\n",
    "        image = F.to_image_tensor(image)\n",
    "    image = F.convert_dtype(image, torch.uint8)\n",
    "    annotated_image = draw_bounding_boxes(image, target[\"boxes\"], colors=\"yellow\", width=3)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(annotated_image.permute(1, 2, 0).numpy())\n",
    "    ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f338e6ee560>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import get_fan_in_tensor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean=[]\n",
    "std=[]\n",
    "max=[]\n",
    "min=[]\n",
    "for i, m in enumerate(pruner.backward_masks):\n",
    "    # print(f\"Layer {i}\")\n",
    "    fan_in_t = get_fan_in_tensor(m.to(\"cpu\"))\n",
    "    fan_in_t = fan_in_t.type(torch.float32)\n",
    "    max.append(fan_in_t.max().item())\n",
    "    min.append(fan_in_t.min().item())\n",
    "    mean.append(fan_in_t.mean(dtype=torch.float32).item())\n",
    "    std.append(fan_in_t.std().item())\n",
    "    \n",
    "df = pd.DataFrame(dict(\n",
    "    mean=mean,\n",
    "    std=std,\n",
    "    max=max,\n",
    "    min=min\n",
    "))\n",
    "plt.plot(df.index, df[\"max\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f338f12c370>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df.index, df[\"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(153.6003, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fan_in_t.mean(dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rigl_torch.utils.rigl_utils import get_names_and_W, get_W\n",
    "\n",
    "W , _, _ = get_W(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mlen\u001b[39m(W)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "len(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names, W_2 = get_names_and_W(model)\n",
    "len(W_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv_proj',\n",
       " 'encoder.layers.encoder_layer_0.mlp.0',\n",
       " 'encoder.layers.encoder_layer_0.mlp.3',\n",
       " 'encoder.layers.encoder_layer_1.mlp.0',\n",
       " 'encoder.layers.encoder_layer_1.mlp.3',\n",
       " 'encoder.layers.encoder_layer_2.mlp.0',\n",
       " 'encoder.layers.encoder_layer_2.mlp.3',\n",
       " 'encoder.layers.encoder_layer_3.mlp.0',\n",
       " 'encoder.layers.encoder_layer_3.mlp.3',\n",
       " 'encoder.layers.encoder_layer_4.mlp.0',\n",
       " 'encoder.layers.encoder_layer_4.mlp.3',\n",
       " 'encoder.layers.encoder_layer_5.mlp.0',\n",
       " 'encoder.layers.encoder_layer_5.mlp.3',\n",
       " 'encoder.layers.encoder_layer_6.mlp.0',\n",
       " 'encoder.layers.encoder_layer_6.mlp.3',\n",
       " 'encoder.layers.encoder_layer_7.mlp.0',\n",
       " 'encoder.layers.encoder_layer_7.mlp.3',\n",
       " 'encoder.layers.encoder_layer_8.mlp.0',\n",
       " 'encoder.layers.encoder_layer_8.mlp.3',\n",
       " 'encoder.layers.encoder_layer_9.mlp.0',\n",
       " 'encoder.layers.encoder_layer_9.mlp.3',\n",
       " 'encoder.layers.encoder_layer_10.mlp.0',\n",
       " 'encoder.layers.encoder_layer_10.mlp.3',\n",
       " 'encoder.layers.encoder_layer_11.mlp.0',\n",
       " 'encoder.layers.encoder_layer_11.mlp.3',\n",
       " 'heads.head']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv_proj',\n",
       " 'encoder.layers.encoder_layer_0.mlp.0',\n",
       " 'encoder.layers.encoder_layer_0.mlp.3',\n",
       " 'encoder.layers.encoder_layer_1.mlp.0',\n",
       " 'encoder.layers.encoder_layer_1.mlp.3',\n",
       " 'encoder.layers.encoder_layer_2.mlp.0',\n",
       " 'encoder.layers.encoder_layer_2.mlp.3',\n",
       " 'encoder.layers.encoder_layer_3.mlp.0',\n",
       " 'encoder.layers.encoder_layer_3.mlp.3',\n",
       " 'encoder.layers.encoder_layer_4.mlp.0',\n",
       " 'encoder.layers.encoder_layer_4.mlp.3',\n",
       " 'encoder.layers.encoder_layer_5.mlp.0',\n",
       " 'encoder.layers.encoder_layer_5.mlp.3',\n",
       " 'encoder.layers.encoder_layer_6.mlp.0',\n",
       " 'encoder.layers.encoder_layer_6.mlp.3',\n",
       " 'encoder.layers.encoder_layer_7.mlp.0',\n",
       " 'encoder.layers.encoder_layer_7.mlp.3',\n",
       " 'encoder.layers.encoder_layer_8.mlp.0',\n",
       " 'encoder.layers.encoder_layer_8.mlp.3',\n",
       " 'encoder.layers.encoder_layer_9.mlp.0',\n",
       " 'encoder.layers.encoder_layer_9.mlp.3',\n",
       " 'encoder.layers.encoder_layer_10.mlp.0',\n",
       " 'encoder.layers.encoder_layer_10.mlp.3',\n",
       " 'encoder.layers.encoder_layer_11.mlp.0',\n",
       " 'encoder.layers.encoder_layer_11.mlp.3',\n",
       " 'heads.head']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, w = get_names_and_W(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'torchvision.models.vision_transformer.VisionTransformer'>\n",
      "conv_proj\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "encoder\n",
      "<class 'torchvision.models.vision_transformer.Encoder'>\n",
      "encoder.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "encoder.layers.encoder_layer_0\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_0.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_0.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_0.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_0.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_0.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_0.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_0.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_0.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_0.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_0.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_0.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_1\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_1.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_1.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_1.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_1.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_1.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_1.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_1.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_1.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_1.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_1.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_1.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_2\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_2.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_2.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_2.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_2.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_2.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_2.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_2.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_2.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_2.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_2.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_2.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_3\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_3.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_3.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_3.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_3.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_3.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_3.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_3.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_3.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_3.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_3.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_3.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_4\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_4.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_4.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_4.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_4.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_4.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_4.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_4.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_4.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_4.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_4.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_4.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_5\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_5.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_5.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_5.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_5.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_5.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_5.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_5.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_5.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_5.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_5.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_5.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_6\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_6.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_6.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_6.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_6.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_6.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_6.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_6.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_6.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_6.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_6.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_6.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_7\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_7.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_7.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_7.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_7.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_7.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_7.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_7.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_7.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_7.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_7.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_7.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_8\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_8.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_8.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_8.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_8.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_8.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_8.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_8.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_8.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_8.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_8.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_8.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_9\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_9.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_9.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_9.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_9.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_9.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_9.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_9.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_9.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_9.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_9.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_9.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_10\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_10.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_10.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_10.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_10.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_10.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_10.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_10.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_10.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_10.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_10.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_10.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_11\n",
      "<class 'torchvision.models.vision_transformer.EncoderBlock'>\n",
      "encoder.layers.encoder_layer_11.ln_1\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_11.self_attention\n",
      "<class 'torch.nn.modules.activation.MultiheadAttention'>\n",
      "encoder.layers.encoder_layer_11.self_attention.out_proj\n",
      "<class 'torch.nn.modules.linear.NonDynamicallyQuantizableLinear'>\n",
      "encoder.layers.encoder_layer_11.dropout\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_11.ln_2\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "encoder.layers.encoder_layer_11.mlp\n",
      "<class 'torchvision.models.vision_transformer.MLPBlock'>\n",
      "encoder.layers.encoder_layer_11.mlp.0\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_11.mlp.1\n",
      "<class 'torch.nn.modules.activation.GELU'>\n",
      "encoder.layers.encoder_layer_11.mlp.2\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.layers.encoder_layer_11.mlp.3\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "encoder.layers.encoder_layer_11.mlp.4\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "encoder.ln\n",
      "<class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "heads\n",
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "heads.head\n",
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for n, m in model.named_modules():\n",
    "    print(n)\n",
    "    print(type(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f5351f9fa30> with args: () and kwargs: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Bottleneck(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Bottleneck(\n",
       "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (2): Bottleneck(\n",
       "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50 = ModelFactory.load_model(\"resnet50\", \"imagenet\")\n",
    "\n",
    "resnet50.layer1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.nam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, m in resnet50.layer1.named_modules():\n",
    "    break\n",
    "    print(n)\n",
    "    print(type(m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck(\n",
       "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (downsample): Sequential(\n",
       "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.layer1.get_submodule(\"0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('',\n",
       " Bottleneck(\n",
       "   (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "   (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (downsample): Sequential(\n",
       "     (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(resnet50.layer1.get_submodule(\"0\").named_modules()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86567656"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vit 16\n",
    "param = 0\n",
    "for p in model.parameters():\n",
    "    param+=p.numel()\n",
    "\n",
    "param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88224232"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vit 32\n",
    "param = 0\n",
    "for p in model.parameters():\n",
    "    param+=p.numel()\n",
    "\n",
    "param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fd6e01279a0> with args: () and kwargs: {}\n"
     ]
    }
   ],
   "source": [
    "resnet50 = ModelFactory.load_model(\"resnet50\", \"imagenet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25557032"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param = 0\n",
    "for p in resnet50.parameters():\n",
    "    param+=p.numel()\n",
    "\n",
    "param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/user/condensed-sparsity/notebooks/main.ipynb Cell 6\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m train_loader:\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f706579746f227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/main.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39;49mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    break\n",
    "print(x.`shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_shape_wrapper(name, module):\n",
    "    \n",
    "    _unwrapped_call = module.forward\n",
    "    \n",
    "    def wrapped_forward(x):\n",
    "        print(f\"{name}: {x.shape}\")\n",
    "        return _unwrapped_call(x)\n",
    "    \n",
    "    module.forward = wrapped_forward\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "for idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    logits = model(data)\n",
    "    loss = F.cross_entropy(\n",
    "        logits,\n",
    "        target,\n",
    "        label_smoothing=cfg.training.label_smoothing,\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pruner()\n",
    "    if idx > 300:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keeping the module conv1 dense...\n",
      "module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.04581880569458008 fwd and 0.11778903007507324 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1624, s=1, p=1, voo=False) took 0.040848731994628906 fwd and 0.1337604522705078 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1624, s=1, p=1, voo=True) took 0.02041006088256836 fwd and 0.04894590377807617 bwd\n",
      "going with SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1624, s=1, p=1, voo=True) with full time of 0.06935596466064453\n",
      "module layer1.0.conv1 replaced with SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1624, s=1, p=1, voo=True)\n",
      "module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.03919196128845215 fwd and 0.08711695671081543 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1612, s=1, p=1, voo=False) took 0.030234813690185547 fwd and 0.11939430236816406 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1612, s=1, p=1, voo=True) took 0.019991397857666016 fwd and 0.04925894737243652 bwd\n",
      "going with SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1612, s=1, p=1, voo=True) with full time of 0.06925034523010254\n",
      "module layer1.0.conv2 replaced with SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1612, s=1, p=1, voo=True)\n",
      "module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.03809404373168945 fwd and 0.08749651908874512 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1593, s=1, p=1, voo=False) took 0.031239986419677734 fwd and 0.13937902450561523 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1593, s=1, p=1, voo=True) took 0.023902177810668945 fwd and 0.06067299842834473 bwd\n",
      "going with SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1593, s=1, p=1, voo=True) with full time of 0.08457517623901367\n",
      "module layer1.1.conv1 replaced with SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1593, s=1, p=1, voo=True)\n",
      "module Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.03722572326660156 fwd and 0.08730435371398926 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1586, s=1, p=1, voo=False) took 0.02937793731689453 fwd and 0.1299886703491211 bwd\n",
      "module SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1586, s=1, p=1, voo=True) took 0.019896507263183594 fwd and 0.04884672164916992 bwd\n",
      "going with SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1586, s=1, p=1, voo=True) with full time of 0.06874322891235352\n",
      "module layer1.1.conv2 replaced with SparseConv2d([64, 64, 3, 3], sp=0.96, nnz=1586, s=1, p=1, voo=True)\n",
      "module Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) took 0.025561094284057617 fwd and 0.045861005783081055 bwd\n",
      "module SparseConv2d([128, 64, 3, 3], sp=0.97, nnz=2380, s=2, p=1, voo=False) took 0.017370223999023438 fwd and 0.06161093711853027 bwd\n",
      "module SparseConv2d([128, 64, 3, 3], sp=0.97, nnz=2380, s=2, p=1, voo=True) took 0.018700361251831055 fwd and 0.0323643684387207 bwd\n",
      "going with SparseConv2d([128, 64, 3, 3], sp=0.97, nnz=2380, s=2, p=1, voo=True) with full time of 0.05106472969055176\n",
      "module layer2.0.conv1 replaced with SparseConv2d([128, 64, 3, 3], sp=0.97, nnz=2380, s=2, p=1, voo=True)\n",
      "module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.018258094787597656 fwd and 0.03769946098327637 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3094, s=1, p=1, voo=False) took 0.009967803955078125 fwd and 0.04150676727294922 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3094, s=1, p=1, voo=True) took 0.014108657836914062 fwd and 0.022653579711914062 bwd\n",
      "going with SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3094, s=1, p=1, voo=True) with full time of 0.036762237548828125\n",
      "module layer2.0.conv2 replaced with SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3094, s=1, p=1, voo=True)\n",
      "keeping the module layer2.0.shortcut.0 dense...\n",
      "module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.016794919967651367 fwd and 0.03743624687194824 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3146, s=1, p=1, voo=False) took 0.009869575500488281 fwd and 0.03989458084106445 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3146, s=1, p=1, voo=True) took 0.012984752655029297 fwd and 0.02269434928894043 bwd\n",
      "going with SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3146, s=1, p=1, voo=True) with full time of 0.03567910194396973\n",
      "module layer2.1.conv1 replaced with SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3146, s=1, p=1, voo=True)\n",
      "module Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.017859697341918945 fwd and 0.04790067672729492 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3146, s=1, p=1, voo=False) took 0.009664773941040039 fwd and 0.04067373275756836 bwd\n",
      "module SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3146, s=1, p=1, voo=True) took 0.021489858627319336 fwd and 0.026131391525268555 bwd\n",
      "going with SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3146, s=1, p=1, voo=True) with full time of 0.04762125015258789\n",
      "module layer2.1.conv2 replaced with SparseConv2d([128, 128, 3, 3], sp=0.98, nnz=3146, s=1, p=1, voo=True)\n",
      "module Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) took 0.010891199111938477 fwd and 0.0304415225982666 bwd\n",
      "module SparseConv2d([256, 128, 3, 3], sp=0.98, nnz=4579, s=2, p=1, voo=False) took 0.006519794464111328 fwd and 0.024203062057495117 bwd\n",
      "module SparseConv2d([256, 128, 3, 3], sp=0.98, nnz=4579, s=2, p=1, voo=True) took 0.00839376449584961 fwd and 0.022691011428833008 bwd\n",
      "going with SparseConv2d([256, 128, 3, 3], sp=0.98, nnz=4579, s=2, p=1, voo=False) with full time of 0.030722856521606445\n",
      "module layer3.0.conv1 replaced with SparseConv2d([256, 128, 3, 3], sp=0.98, nnz=4579, s=2, p=1, voo=False)\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.014336109161376953 fwd and 0.03195929527282715 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6175, s=1, p=1, voo=False) took 0.007243156433105469 fwd and 0.013436555862426758 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6175, s=1, p=1, voo=True) took 0.015186071395874023 fwd and 0.02743673324584961 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6175, s=1, p=1, voo=False) with full time of 0.020679712295532227\n",
      "module layer3.0.conv2 replaced with SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6175, s=1, p=1, voo=False)\n",
      "module Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) took 0.0030775070190429688 fwd and 0.014110565185546875 bwd\n",
      "module SparseConv2d([256, 128, 1, 1], sp=0.86, nnz=4541, s=2, p=0, voo=False) took 0.008023738861083984 fwd and 0.02305316925048828 bwd\n",
      "module SparseConv2d([256, 128, 1, 1], sp=0.86, nnz=4541, s=2, p=0, voo=True) took 0.00634002685546875 fwd and 0.021112680435180664 bwd\n",
      "going with Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) with full time of 0.017188072204589844\n",
      "keeping the module layer3.0.shortcut.0 dense...\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.013739347457885742 fwd and 0.04588627815246582 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6188, s=1, p=1, voo=False) took 0.008497476577758789 fwd and 0.016492128372192383 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6188, s=1, p=1, voo=True) took 0.018187999725341797 fwd and 0.031215906143188477 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6188, s=1, p=1, voo=False) with full time of 0.024989604949951172\n",
      "module layer3.1.conv1 replaced with SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6188, s=1, p=1, voo=False)\n",
      "module Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.02216029167175293 fwd and 0.03136134147644043 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6072, s=1, p=1, voo=False) took 0.004300117492675781 fwd and 0.014942169189453125 bwd\n",
      "module SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6072, s=1, p=1, voo=True) took 0.018225669860839844 fwd and 0.024531841278076172 bwd\n",
      "going with SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6072, s=1, p=1, voo=False) with full time of 0.019242286682128906\n",
      "module layer3.1.conv2 replaced with SparseConv2d([256, 256, 3, 3], sp=0.99, nnz=6072, s=1, p=1, voo=False)\n",
      "module Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) took 0.00873875617980957 fwd and 0.03018045425415039 bwd\n",
      "module SparseConv2d([512, 256, 3, 3], sp=0.99, nnz=9240, s=2, p=1, voo=False) took 0.0036039352416992188 fwd and 0.0089263916015625 bwd\n",
      "module SparseConv2d([512, 256, 3, 3], sp=0.99, nnz=9240, s=2, p=1, voo=True) took 0.002955198287963867 fwd and 0.03491806983947754 bwd\n",
      "going with SparseConv2d([512, 256, 3, 3], sp=0.99, nnz=9240, s=2, p=1, voo=False) with full time of 0.012530326843261719\n",
      "module layer4.0.conv1 replaced with SparseConv2d([512, 256, 3, 3], sp=0.99, nnz=9240, s=2, p=1, voo=False)\n",
      "module Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.01592087745666504 fwd and 0.0504908561706543 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12048, s=1, p=1, voo=False) took 0.002291440963745117 fwd and 0.006503105163574219 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12048, s=1, p=1, voo=True) took 0.028370141983032227 fwd and 0.0502626895904541 bwd\n",
      "going with SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12048, s=1, p=1, voo=False) with full time of 0.008794546127319336\n",
      "module layer4.0.conv2 replaced with SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12048, s=1, p=1, voo=False)\n",
      "module Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) took 0.002288341522216797 fwd and 0.006678342819213867 bwd\n",
      "module SparseConv2d([512, 256, 1, 1], sp=0.93, nnz=9220, s=2, p=0, voo=False) took 0.0030753612518310547 fwd and 0.008929729461669922 bwd\n",
      "module SparseConv2d([512, 256, 1, 1], sp=0.93, nnz=9220, s=2, p=0, voo=True) took 0.0029296875 fwd and 0.038886308670043945 bwd\n",
      "going with Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) with full time of 0.008966684341430664\n",
      "keeping the module layer4.0.shortcut.0 dense...\n",
      "module Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.014787435531616211 fwd and 0.050479888916015625 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12376, s=1, p=1, voo=False) took 0.002579927444458008 fwd and 0.006142854690551758 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12376, s=1, p=1, voo=True) took 0.02935791015625 fwd and 0.048082590103149414 bwd\n",
      "going with SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12376, s=1, p=1, voo=False) with full time of 0.008722782135009766\n",
      "module layer4.1.conv1 replaced with SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12376, s=1, p=1, voo=False)\n",
      "module Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) took 0.015109777450561523 fwd and 0.04944586753845215 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12350, s=1, p=1, voo=False) took 0.0023882389068603516 fwd and 0.0073909759521484375 bwd\n",
      "module SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12350, s=1, p=1, voo=True) took 0.028226852416992188 fwd and 0.04944276809692383 bwd\n",
      "going with SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12350, s=1, p=1, voo=False) with full time of 0.009779214859008789\n",
      "module layer4.1.conv2 replaced with SparseConv2d([512, 512, 3, 3], sp=0.99, nnz=12350, s=1, p=1, voo=False)\n",
      "keeping the module linear dense...\n"
     ]
    }
   ],
   "source": [
    "from sparseprop.utils import swap_modules_with_sparse\n",
    "\n",
    "sparse_model = swap_modules_with_sparse(model.to(\"cpu\"), data.shape, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "input = torch.rand(size=(128,3,32,32))\n",
    "layer = model\n",
    "t_dense = benchmark.Timer(\n",
    "    stmt=\"layer(input)\",\n",
    "    globals={\"input\": input, \"layer\": layer},\n",
    "    num_threads=4,\n",
    "    label=\"Dense\",\n",
    ")\n",
    "\n",
    "input = torch.rand(size=(128,3,32,32))\n",
    "layer = sparse_model\n",
    "t_sparse = benchmark.Timer(\n",
    "    stmt=\"layer(input)\",\n",
    "    globals={\"input\": input, \"layer\": layer},\n",
    "    num_threads=4,\n",
    "    label=\"Sparse Linear\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f4cce370d30>\n",
      "Dense\n",
      "  508.66 ms\n",
      "  1 measurement, 100 runs , 4 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f4cce3708b0>\n",
      "Sparse Linear\n",
      "  417.84 ms\n",
      "  1 measurement, 100 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "print(t_dense.timeit(100))\n",
    "print(t_sparse.timeit(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(2, 2)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "(2, 2)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(2, 2)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "(2, 2)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "(2, 2)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "(2, 2)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "(1, 1)\n",
      "Linear(in_features=512, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "from sparseprop.modules import SparseConv2d, SparseLinear\n",
    "from sparseprop.utils import swap_module\n",
    "\n",
    "class SparseModelFactory():\n",
    "    module_mapping = {\n",
    "            torch.nn.Linear: SparseLinear,\n",
    "            torch.nn.Conv2d: SparseConv2d,\n",
    "        }\n",
    "        \n",
    "    # def __init__(self, model: torch.nn.Module):\n",
    "    #     self.module_mapping = {\n",
    "    #         torch.nn.Linear: SparseLinear,\n",
    "    #         torch.nn.Conv2d: SparseConv2d,\n",
    "    #     }\n",
    "    #     self.dense_model = model\n",
    "    \n",
    "    @classmethod\n",
    "    def get_sparse_model(cls , model, input_shape):\n",
    "        for name, mod in model.named_modules():\n",
    "            if type(mod) in cls.module_mapping.keys():\n",
    "                print(mod)\n",
    "                new_mod = cls._get_new_mod(cls, current_mod=mod, input_shape=input_shape)\n",
    "                swap_module(model, name, new_mod)\n",
    "        return model\n",
    "    \n",
    "    def _swap_module(network, module_name, new_module):\n",
    "        name_parts = module_name.split('.')\n",
    "        parent = network\n",
    "        for part in name_parts[:-1]:\n",
    "            if part.isdigit():\n",
    "                parent = parent[int(part)]\n",
    "            else:\n",
    "                parent = getattr(parent, part)\n",
    "        last_part = name_parts[-1]\n",
    "        if last_part.isdigit():\n",
    "            parent[int(last_part)] = new_module\n",
    "        else:\n",
    "            setattr(parent, last_part, new_module)\n",
    "    \n",
    "    def _get_new_mod(cls, current_mod,  input_shape, ):\n",
    "        if isinstance(current_mod, torch.nn.Linear):\n",
    "            return cls._get_new_linear_mod(current_mod, input_shape)\n",
    "        elif isinstance(current_mod, torch.nn.Conv2d):\n",
    "            return cls._get_new_conv_mod(current_mod, input_shape)\n",
    "    \n",
    "    def _get_new_linear_mod(mod, input_shape):\n",
    "        bias = None if mod.bias is None else torch.nn.Parameter(mod.bias.data)\n",
    "        return SparseLinear(dense_weight=mod.weight.data, bias=bias)\n",
    "    \n",
    "    def _get_new_conv_mod(mod, input_shape):\n",
    "        print(mod.stride)\n",
    "        bias = None if mod.bias is None else torch.nn.Parameter(mod.bias.data)\n",
    "        dense_weight = mod.weight.data\n",
    "        stride = mod.stride[0]\n",
    "        padding = mod.padding[0]\n",
    "        return SparseConv2d(\n",
    "            dense_weight = dense_weight,\n",
    "            bias=bias,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "            vectorizing_over_on=True)\n",
    "    \n",
    "\n",
    "sparse_mod = SparseModelFactory.get_sparse_model(model.to(\"cpu\"), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4162,  0.4518,  0.3597,  ..., -0.9688, -0.1319,  0.0462],\n",
       "        [ 0.3097,  0.4583,  0.2424,  ..., -1.0518, -0.1513, -0.1427],\n",
       "        [ 0.1790,  0.8623,  0.5161,  ..., -0.7629, -0.1604, -0.2863],\n",
       "        ...,\n",
       "        [ 0.3994,  0.6235,  0.5751,  ..., -1.1589, -0.2731, -0.1744],\n",
       "        [ 0.4407,  0.9827,  0.1701,  ..., -0.7215, -0.0502, -0.3095],\n",
       "        [ 0.2535,  0.3990,  0.6862,  ..., -0.7910, -0.1029, -0.0865]],\n",
       "       grad_fn=<SparseLinearFunctionBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mod(data.to(\"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): SparseConv2d()\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): SparseConv2d()\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d()\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): SparseConv2d()\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d()\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): SparseConv2d()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d()\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): SparseConv2d()\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): SparseConv2d()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d()\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): SparseConv2d()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d()\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): SparseConv2d()\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): SparseConv2d()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d()\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): SparseConv2d()\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d()\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): SparseConv2d()\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): SparseConv2d()\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SparseConv2d()\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): SparseLinear()\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4857129423304003"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.ones_like(torch.tensor([[3,3,3], [1,1,1]]))*0.1\n",
    "t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(885, device='cuda:0')\n",
      "1728\n"
     ]
    }
   ],
   "source": [
    "for m, w in list(zip(pruner.backward_masks, pruner.W)):\n",
    "    print(m.sum())\n",
    "    print(m.numel())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-31655.7344, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-54168032., device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-1.0154e+10, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-6.9829e+08, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-748835.7500, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-248644.1406, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-3.3549e+09, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-17579.5195, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-46779.0703, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-4553479.5000, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-10820.7139, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-46554.8008, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-6704635.5000, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-21896.1660, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-5470497.5000, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-20026.2676, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-1444722.2500, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-2.1796e+09, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-66365336., device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-4.4225e+08, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "tensor(-158416.2188, device='cuda:0', grad_fn=<MinBackward1>)\n"
     ]
    }
   ],
   "source": [
    "for w in pruner.W:\n",
    "    print(w.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f58689cba30> with args: () and kwargs: {'diet': [17, 16, 17, 14, 16, 33, 31, 31, 32, 30, 65, 63, 63, 65, 63, 122, 124, 124, 114, 125, 0]}\n"
     ]
    }
   ],
   "source": [
    "results = {k:[] for k in [\"rigl.dense_allocation\", \"min_sal_per_layer\", \"layer_name\"]}\n",
    "for da in [0.01]: #, 0.05, 0.1, 0.2]:\n",
    "\n",
    "    rank=0\n",
    "    checkpoint=None\n",
    "    if checkpoint is not None:\n",
    "        run_id = checkpoint.run_id\n",
    "        optimizer_state = checkpoint.optimizer\n",
    "        scheduler_state = checkpoint.scheduler\n",
    "        pruner_state = checkpoint.pruner\n",
    "        model_state = checkpoint.model\n",
    "        cfg = checkpoint.cfg\n",
    "    else:\n",
    "        run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    if \"diet\" not in cfg.rigl:\n",
    "        with omegaconf.open_dict(cfg):\n",
    "            cfg.rigl.diet = None\n",
    "    if \"keep_first_layer_dense\" not in cfg.rigl:\n",
    "        with omegaconf.open_dict(cfg):\n",
    "            cfg.rigl.keep_first_layer_dense = False\n",
    "    print(cfg.compute)\n",
    "    cfg.compute.distributed=False\n",
    "        \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    if not use_cuda:\n",
    "        raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "        logger.warning(\n",
    "            \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "            \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "        )\n",
    "\n",
    "    if cfg.compute.distributed and use_cuda:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        print(f\"loading to device rank: {rank}\")\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    if not use_cuda:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name, diet=cfg.rigl.diet\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        if cfg.rigl.dense_allocation is not None:\n",
    "            if cfg.model.name == \"skinny_resnet18\":\n",
    "                dense_allocation = (\n",
    "                    cfg.rigl.dense_allocation * cfg.model.sparsity_scale_factor\n",
    "                )\n",
    "                print(\n",
    "                    f\"Scaling {cfg.rigl.dense_allocation} by \"\n",
    "                    f\"{cfg.model.sparsity_scale_factor:.2f} for SkinnyResNet18 \"\n",
    "                    f\"New Dense Alloc == {dense_allocation:.6f}\"\n",
    "                )\n",
    "            else:\n",
    "                dense_allocation = cfg.rigl.dense_allocation\n",
    "            T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "            if cfg.rigl.const_fan_in:\n",
    "                rigl_scheduler = RigLConstFanScheduler\n",
    "            else:\n",
    "                rigl_scheduler = RigLScheduler\n",
    "            pruner = rigl_scheduler(\n",
    "                model,\n",
    "                optimizer,\n",
    "                dense_allocation=cfg.rigl.dense_allocation,\n",
    "                alpha=cfg.rigl.alpha,\n",
    "                delta=cfg.rigl.delta,\n",
    "                static_topo=cfg.rigl.static_topo,\n",
    "                T_end=T_end,\n",
    "                ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "                grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "                sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "                erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "                state_dict=pruner_state,\n",
    "                filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "                static_ablation=cfg.rigl.static_ablation,\n",
    "                dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "                min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "                use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "                init_method_str=cfg.rigl.init_method_str,\n",
    "                use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "            )\n",
    "            step=0\n",
    "            reinit_ablated_neuron_count(pruner)\n",
    "        \n",
    "    model.train()\n",
    "    for idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        logits = model(data)\n",
    "        loss = F.cross_entropy(\n",
    "            logits,\n",
    "            target,\n",
    "            label_smoothing=cfg.training.label_smoothing,\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pruner()\n",
    "        if idx > 2:\n",
    "            break\n",
    "    from rigl_torch.utils.rigl_utils import get_names_and_W\n",
    "    names, _ = get_names_and_W(model)\n",
    "    for min_sal, name in list(zip(pruner._min_sal_per_layer, names)):\n",
    "        results[\"rigl.dense_allocation\"].append(da)\n",
    "        results[\"min_sal_per_layer\"].append(min_sal)\n",
    "        results[\"layer_name\"].append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rigl.dense_allocation</th>\n",
       "      <th>min_sal_per_layer</th>\n",
       "      <th>layer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer1.0.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>layer1.0.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer1.0.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer1.0.downsample.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer1.1.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>layer1.1.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer1.1.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer1.2.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>layer1.2.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer1.2.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>layer2.0.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer2.0.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer2.0.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer2.0.downsample.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer2.1.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer2.1.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer2.1.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer2.2.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer2.2.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer2.2.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer2.3.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer2.3.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer2.3.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>layer3.0.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer3.0.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer3.0.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer3.0.downsample.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer3.1.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer3.1.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer3.1.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer3.2.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer3.2.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer3.2.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer3.3.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer3.3.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer3.3.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer3.4.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer3.4.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer3.4.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer3.5.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer3.5.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer3.5.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>layer4.0.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer4.0.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer4.0.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer4.0.downsample.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer4.1.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer4.1.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer4.1.conv3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>layer4.2.conv1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>layer4.2.conv2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>layer4.2.conv3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rigl.dense_allocation  min_sal_per_layer             layer_name\n",
       "0                    0.01                  1                  conv1\n",
       "1                    0.01                  2         layer1.0.conv1\n",
       "2                    0.01                  3         layer1.0.conv2\n",
       "3                    0.01                  1         layer1.0.conv3\n",
       "4                    0.01                  1  layer1.0.downsample.0\n",
       "5                    0.01                  7         layer1.1.conv1\n",
       "6                    0.01                  3         layer1.1.conv2\n",
       "7                    0.01                  1         layer1.1.conv3\n",
       "8                    0.01                  7         layer1.2.conv1\n",
       "9                    0.01                  3         layer1.2.conv2\n",
       "10                   0.01                  1         layer1.2.conv3\n",
       "11                   0.01                  4         layer2.0.conv1\n",
       "12                   0.01                  2         layer2.0.conv2\n",
       "13                   0.01                  1         layer2.0.conv3\n",
       "14                   0.01                  2  layer2.0.downsample.0\n",
       "15                   0.01                  7         layer2.1.conv1\n",
       "16                   0.01                  2         layer2.1.conv2\n",
       "17                   0.01                  1         layer2.1.conv3\n",
       "18                   0.01                  7         layer2.2.conv1\n",
       "19                   0.01                  2         layer2.2.conv2\n",
       "20                   0.01                  1         layer2.2.conv3\n",
       "21                   0.01                  7         layer2.3.conv1\n",
       "22                   0.01                  2         layer2.3.conv2\n",
       "23                   0.01                  1         layer2.3.conv3\n",
       "24                   0.01                  4         layer3.0.conv1\n",
       "25                   0.01                  2         layer3.0.conv2\n",
       "26                   0.01                  1         layer3.0.conv3\n",
       "27                   0.01                  2  layer3.0.downsample.0\n",
       "28                   0.01                  7         layer3.1.conv1\n",
       "29                   0.01                  2         layer3.1.conv2\n",
       "30                   0.01                  1         layer3.1.conv3\n",
       "31                   0.01                  7         layer3.2.conv1\n",
       "32                   0.01                  2         layer3.2.conv2\n",
       "33                   0.01                  1         layer3.2.conv3\n",
       "34                   0.01                  7         layer3.3.conv1\n",
       "35                   0.01                  2         layer3.3.conv2\n",
       "36                   0.01                  1         layer3.3.conv3\n",
       "37                   0.01                  7         layer3.4.conv1\n",
       "38                   0.01                  2         layer3.4.conv2\n",
       "39                   0.01                  1         layer3.4.conv3\n",
       "40                   0.01                  7         layer3.5.conv1\n",
       "41                   0.01                  2         layer3.5.conv2\n",
       "42                   0.01                  1         layer3.5.conv3\n",
       "43                   0.01                  4         layer4.0.conv1\n",
       "44                   0.01                  2         layer4.0.conv2\n",
       "45                   0.01                  1         layer4.0.conv3\n",
       "46                   0.01                  2  layer4.0.downsample.0\n",
       "47                   0.01                  7         layer4.1.conv1\n",
       "48                   0.01                  2         layer4.1.conv2\n",
       "49                   0.01                  1         layer4.1.conv3\n",
       "50                   0.01                  7         layer4.2.conv1\n",
       "51                   0.01                  2         layer4.2.conv2\n",
       "52                   0.01                  1         layer4.2.conv3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"../min-sal-per-layer.csv\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rigl.dense_allocation': {0: 0.01,\n",
       "  1: 0.01,\n",
       "  2: 0.01,\n",
       "  3: 0.01,\n",
       "  4: 0.01,\n",
       "  5: 0.01,\n",
       "  6: 0.01,\n",
       "  7: 0.01,\n",
       "  8: 0.01,\n",
       "  9: 0.01,\n",
       "  10: 0.01,\n",
       "  11: 0.01,\n",
       "  12: 0.01,\n",
       "  13: 0.01,\n",
       "  14: 0.01,\n",
       "  15: 0.01,\n",
       "  16: 0.01,\n",
       "  17: 0.01,\n",
       "  18: 0.01,\n",
       "  19: 0.01,\n",
       "  20: 0.01,\n",
       "  21: 0.01,\n",
       "  22: 0.01,\n",
       "  23: 0.01,\n",
       "  24: 0.01,\n",
       "  25: 0.01,\n",
       "  26: 0.01,\n",
       "  27: 0.01,\n",
       "  28: 0.01,\n",
       "  29: 0.01,\n",
       "  30: 0.01,\n",
       "  31: 0.01,\n",
       "  32: 0.01,\n",
       "  33: 0.01,\n",
       "  34: 0.01,\n",
       "  35: 0.01,\n",
       "  36: 0.01,\n",
       "  37: 0.01,\n",
       "  38: 0.01,\n",
       "  39: 0.01,\n",
       "  40: 0.01,\n",
       "  41: 0.01,\n",
       "  42: 0.01,\n",
       "  43: 0.01,\n",
       "  44: 0.01,\n",
       "  45: 0.01,\n",
       "  46: 0.01,\n",
       "  47: 0.01,\n",
       "  48: 0.01,\n",
       "  49: 0.01,\n",
       "  50: 0.01,\n",
       "  51: 0.01,\n",
       "  52: 0.01},\n",
       " 'min_sal_per_layer': {0: 1,\n",
       "  1: 2,\n",
       "  2: 3,\n",
       "  3: 1,\n",
       "  4: 1,\n",
       "  5: 7,\n",
       "  6: 3,\n",
       "  7: 1,\n",
       "  8: 7,\n",
       "  9: 3,\n",
       "  10: 1,\n",
       "  11: 4,\n",
       "  12: 2,\n",
       "  13: 1,\n",
       "  14: 2,\n",
       "  15: 7,\n",
       "  16: 2,\n",
       "  17: 1,\n",
       "  18: 7,\n",
       "  19: 2,\n",
       "  20: 1,\n",
       "  21: 7,\n",
       "  22: 2,\n",
       "  23: 1,\n",
       "  24: 4,\n",
       "  25: 2,\n",
       "  26: 1,\n",
       "  27: 2,\n",
       "  28: 7,\n",
       "  29: 2,\n",
       "  30: 1,\n",
       "  31: 7,\n",
       "  32: 2,\n",
       "  33: 1,\n",
       "  34: 7,\n",
       "  35: 2,\n",
       "  36: 1,\n",
       "  37: 7,\n",
       "  38: 2,\n",
       "  39: 1,\n",
       "  40: 7,\n",
       "  41: 2,\n",
       "  42: 1,\n",
       "  43: 4,\n",
       "  44: 2,\n",
       "  45: 1,\n",
       "  46: 2,\n",
       "  47: 7,\n",
       "  48: 2,\n",
       "  49: 1,\n",
       "  50: 7,\n",
       "  51: 2,\n",
       "  52: 1},\n",
       " 'layer_name': {0: 'conv1',\n",
       "  1: 'layer1.0.conv1',\n",
       "  2: 'layer1.0.conv2',\n",
       "  3: 'layer1.0.conv3',\n",
       "  4: 'layer1.0.downsample.0',\n",
       "  5: 'layer1.1.conv1',\n",
       "  6: 'layer1.1.conv2',\n",
       "  7: 'layer1.1.conv3',\n",
       "  8: 'layer1.2.conv1',\n",
       "  9: 'layer1.2.conv2',\n",
       "  10: 'layer1.2.conv3',\n",
       "  11: 'layer2.0.conv1',\n",
       "  12: 'layer2.0.conv2',\n",
       "  13: 'layer2.0.conv3',\n",
       "  14: 'layer2.0.downsample.0',\n",
       "  15: 'layer2.1.conv1',\n",
       "  16: 'layer2.1.conv2',\n",
       "  17: 'layer2.1.conv3',\n",
       "  18: 'layer2.2.conv1',\n",
       "  19: 'layer2.2.conv2',\n",
       "  20: 'layer2.2.conv3',\n",
       "  21: 'layer2.3.conv1',\n",
       "  22: 'layer2.3.conv2',\n",
       "  23: 'layer2.3.conv3',\n",
       "  24: 'layer3.0.conv1',\n",
       "  25: 'layer3.0.conv2',\n",
       "  26: 'layer3.0.conv3',\n",
       "  27: 'layer3.0.downsample.0',\n",
       "  28: 'layer3.1.conv1',\n",
       "  29: 'layer3.1.conv2',\n",
       "  30: 'layer3.1.conv3',\n",
       "  31: 'layer3.2.conv1',\n",
       "  32: 'layer3.2.conv2',\n",
       "  33: 'layer3.2.conv3',\n",
       "  34: 'layer3.3.conv1',\n",
       "  35: 'layer3.3.conv2',\n",
       "  36: 'layer3.3.conv3',\n",
       "  37: 'layer3.4.conv1',\n",
       "  38: 'layer3.4.conv2',\n",
       "  39: 'layer3.4.conv3',\n",
       "  40: 'layer3.5.conv1',\n",
       "  41: 'layer3.5.conv2',\n",
       "  42: 'layer3.5.conv3',\n",
       "  43: 'layer4.0.conv1',\n",
       "  44: 'layer4.0.conv2',\n",
       "  45: 'layer4.0.conv3',\n",
       "  46: 'layer4.0.downsample.0',\n",
       "  47: 'layer4.1.conv1',\n",
       "  48: 'layer4.1.conv2',\n",
       "  49: 'layer4.1.conv3',\n",
       "  50: 'layer4.2.conv1',\n",
       "  51: 'layer4.2.conv2',\n",
       "  52: 'layer4.2.conv3'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1, 1, 7, 3, 1, 7, 3, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1, 7, 2, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1, 7, 2, 1, 7, 2, 1, 7, 2, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1]\n",
      "[1, 2, 3, 1, 1, 7, 3, 1, 7, 3, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1, 7, 2, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1, 7, 2, 1, 7, 2, 1, 7, 2, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1]\n",
      "[1, 2, 3, 1, 1, 7, 3, 1, 7, 3, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1, 7, 2, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1, 7, 2, 1, 7, 2, 1, 7, 2, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1]\n",
      "[1, 2, 3, 1, 1, 7, 3, 1, 7, 3, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1, 7, 2, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1, 7, 2, 1, 7, 2, 1, 7, 2, 1, 4, 2, 1, 2, 7, 2, 1, 7, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in enumerate(df[\"min_sal_per_layer\"]):\n",
    "    print(row)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(3., device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(3., device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(3., device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(4.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(2.1000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(4.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(2.1000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(4.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(2.1000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(7.2000, device='cuda:0')\n",
      "tensor(2.7000, device='cuda:0')\n",
      "tensor(1.8000, device='cuda:0')\n",
      "tensor(4.2000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for layer in pruner.backward_masks:\n",
    "    for n in layer:\n",
    "        print(n.sum()*0.3)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rigl.dense_allocation': {0: 0.01, 1: 0.05, 2: 0.1, 3: 0.2},\n",
       " 'min_sal_per_layer': {0: [1,\n",
       "   2,\n",
       "   3,\n",
       "   1,\n",
       "   1,\n",
       "   7,\n",
       "   3,\n",
       "   1,\n",
       "   7,\n",
       "   3,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1],\n",
       "  1: [1,\n",
       "   2,\n",
       "   3,\n",
       "   1,\n",
       "   1,\n",
       "   7,\n",
       "   3,\n",
       "   1,\n",
       "   7,\n",
       "   3,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1],\n",
       "  2: [1,\n",
       "   2,\n",
       "   3,\n",
       "   1,\n",
       "   1,\n",
       "   7,\n",
       "   3,\n",
       "   1,\n",
       "   7,\n",
       "   3,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1],\n",
       "  3: [1,\n",
       "   2,\n",
       "   3,\n",
       "   1,\n",
       "   1,\n",
       "   7,\n",
       "   3,\n",
       "   1,\n",
       "   7,\n",
       "   3,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   4,\n",
       "   2,\n",
       "   1,\n",
       "   2,\n",
       "   7,\n",
       "   2,\n",
       "   1,\n",
       "   7,\n",
       "   2,\n",
       "   1]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner._min_sal_per_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/20230111_cjkc5i44/checkpoint.pt.tar...\n",
      "Global seed set to 2078\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x7f58689c91b0> with args: () and kwargs: {'diet': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    }
   ],
   "source": [
    "# params = {k:[] for k in [\"dense_allocation\", \"parameters\", \"dense_params\"]}\n",
    "# for da in [0.01, 0.05, 0.0625, 0.1, 0.2, 0.25, 0.3, 0.4, 0.5,]:\n",
    "\n",
    "\n",
    "results = {k:[] for k in [\"dense_allocation\", \"layer_idx\", \"layer_name\", \"width\", \"active_neurons\", \"ablated_neurons\", \"rigl.dense_allocation\", \"run_id\"]}\n",
    "\n",
    "    # checkpoint = Checkpoint.load_last_checkpoint(run_id=run_id, parent_dir = cfg.paths.checkpoints)\n",
    "runs = ['cjkc5i44']\n",
    "for run_id in runs:\n",
    "    checkpoint = Checkpoint.load_last_checkpoint(run_id=run_id, parent_dir=cfg.paths.checkpoints)\n",
    "    # checkpoint=None\n",
    "    rank=0\n",
    "\n",
    "    if checkpoint is not None:\n",
    "        run_id = checkpoint.run_id\n",
    "        optimizer_state = checkpoint.optimizer\n",
    "        scheduler_state = checkpoint.scheduler\n",
    "        pruner_state = checkpoint.pruner\n",
    "        model_state = checkpoint.model\n",
    "        cfg = checkpoint.cfg\n",
    "    else:\n",
    "        run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    if \"diet\" not in cfg.rigl:\n",
    "        with omegaconf.open_dict(cfg):\n",
    "            cfg.rigl.diet = None\n",
    "    if \"keep_first_layer_dense\" not in cfg.rigl:\n",
    "        with omegaconf.open_dict(cfg):\n",
    "            cfg.rigl.keep_first_layer_dense = False\n",
    "    print(cfg.compute)\n",
    "    cfg.compute.distributed=False\n",
    "        \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    if not use_cuda:\n",
    "        raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "        logger.warning(\n",
    "            \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "            \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "        )\n",
    "\n",
    "    if cfg.compute.distributed and use_cuda:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        print(f\"loading to device rank: {rank}\")\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    if not use_cuda:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name, diet=cfg.rigl.diet\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        if cfg.rigl.dense_allocation is not None:\n",
    "            if cfg.model.name == \"skinny_resnet18\":\n",
    "                dense_allocation = (\n",
    "                    cfg.rigl.dense_allocation * cfg.model.sparsity_scale_factor\n",
    "                )\n",
    "                print(\n",
    "                    f\"Scaling {cfg.rigl.dense_allocation} by \"\n",
    "                    f\"{cfg.model.sparsity_scale_factor:.2f} for SkinnyResNet18 \"\n",
    "                    f\"New Dense Alloc == {dense_allocation:.6f}\"\n",
    "                )\n",
    "            else:\n",
    "                dense_allocation = cfg.rigl.dense_allocation\n",
    "            T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "            if cfg.rigl.const_fan_in:\n",
    "                rigl_scheduler = RigLConstFanScheduler\n",
    "            else:\n",
    "                rigl_scheduler = RigLScheduler\n",
    "            pruner = rigl_scheduler(\n",
    "                model,\n",
    "                optimizer,\n",
    "                dense_allocation=cfg.rigl.dense_allocation,\n",
    "                alpha=cfg.rigl.alpha,\n",
    "                delta=cfg.rigl.delta,\n",
    "                static_topo=cfg.rigl.static_topo,\n",
    "                T_end=T_end,\n",
    "                ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "                grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "                sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "                erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "                state_dict=pruner_state,\n",
    "                filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "                static_ablation=cfg.rigl.static_ablation,\n",
    "                dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "                min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "                use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "                init_method_str=cfg.rigl.init_method_str,\n",
    "                use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "            )\n",
    "            step=0\n",
    "            reinit_ablated_neuron_count(pruner)\n",
    "            \n",
    "            \n",
    "\n",
    "    from rigl_torch.utils.rigl_utils import get_names_and_W\n",
    "    names, W = get_names_and_W(model)\n",
    "    for idx, (name, w) in enumerate(list(zip(names, W))):\n",
    "        results[\"rigl.dense_allocation\"].append(cfg.rigl.dense_allocation)\n",
    "        results[\"run_id\"].append(run_id)\n",
    "        results[\"dense_allocation\"].append(pruner.S[idx])\n",
    "        results[\"layer_idx\"].append(idx)\n",
    "        results[\"layer_name\"].append(name)\n",
    "        results[\"width\"].append(w.shape[0])\n",
    "        results[\"active_neurons\"].append(len(pruner.active_neurons[idx]))\n",
    "        results[\"ablated_neurons\"].append(len(pruner.dynamically_ablated_neuron_idx[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ablation_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "name": "Active Neurons",
         "type": "bar",
         "x": [
          "conv1",
          "layer1.0.conv1",
          "layer1.0.conv2",
          "layer1.0.conv3",
          "layer1.0.downsample.0",
          "layer1.1.conv1",
          "layer1.1.conv2",
          "layer1.1.conv3",
          "layer1.2.conv1",
          "layer1.2.conv2",
          "layer1.2.conv3",
          "layer2.0.conv1",
          "layer2.0.conv2",
          "layer2.0.conv3",
          "layer2.0.downsample.0",
          "layer2.1.conv1",
          "layer2.1.conv2",
          "layer2.1.conv3",
          "layer2.2.conv1",
          "layer2.2.conv2",
          "layer2.2.conv3",
          "layer2.3.conv1",
          "layer2.3.conv2",
          "layer2.3.conv3",
          "layer3.0.conv1",
          "layer3.0.conv2",
          "layer3.0.conv3",
          "layer3.0.downsample.0",
          "layer3.1.conv1",
          "layer3.1.conv2",
          "layer3.1.conv3",
          "layer3.2.conv1",
          "layer3.2.conv2",
          "layer3.2.conv3",
          "layer3.3.conv1",
          "layer3.3.conv2",
          "layer3.3.conv3",
          "layer3.4.conv1",
          "layer3.4.conv2",
          "layer3.4.conv3",
          "layer3.5.conv1",
          "layer3.5.conv2",
          "layer3.5.conv3",
          "layer4.0.conv1",
          "layer4.0.conv2",
          "layer4.0.conv3",
          "layer4.0.downsample.0",
          "layer4.1.conv1",
          "layer4.1.conv2",
          "layer4.1.conv3",
          "layer4.2.conv1",
          "layer4.2.conv2",
          "layer4.2.conv3",
          "fc"
         ],
         "y": [
          50,
          56,
          59,
          230,
          224,
          58,
          55,
          248,
          60,
          56,
          231,
          118,
          123,
          454,
          432,
          111,
          115,
          478,
          122,
          123,
          455,
          122,
          119,
          399,
          220,
          242,
          893,
          851,
          232,
          228,
          977,
          235,
          234,
          967,
          243,
          228,
          941,
          239,
          230,
          889,
          237,
          222,
          837,
          450,
          453,
          1419,
          1350,
          482,
          444,
          1295,
          495,
          441,
          1151,
          1000
         ]
        },
        {
         "name": "Dense Width",
         "type": "bar",
         "x": [
          "conv1",
          "layer1.0.conv1",
          "layer1.0.conv2",
          "layer1.0.conv3",
          "layer1.0.downsample.0",
          "layer1.1.conv1",
          "layer1.1.conv2",
          "layer1.1.conv3",
          "layer1.2.conv1",
          "layer1.2.conv2",
          "layer1.2.conv3",
          "layer2.0.conv1",
          "layer2.0.conv2",
          "layer2.0.conv3",
          "layer2.0.downsample.0",
          "layer2.1.conv1",
          "layer2.1.conv2",
          "layer2.1.conv3",
          "layer2.2.conv1",
          "layer2.2.conv2",
          "layer2.2.conv3",
          "layer2.3.conv1",
          "layer2.3.conv2",
          "layer2.3.conv3",
          "layer3.0.conv1",
          "layer3.0.conv2",
          "layer3.0.conv3",
          "layer3.0.downsample.0",
          "layer3.1.conv1",
          "layer3.1.conv2",
          "layer3.1.conv3",
          "layer3.2.conv1",
          "layer3.2.conv2",
          "layer3.2.conv3",
          "layer3.3.conv1",
          "layer3.3.conv2",
          "layer3.3.conv3",
          "layer3.4.conv1",
          "layer3.4.conv2",
          "layer3.4.conv3",
          "layer3.5.conv1",
          "layer3.5.conv2",
          "layer3.5.conv3",
          "layer4.0.conv1",
          "layer4.0.conv2",
          "layer4.0.conv3",
          "layer4.0.downsample.0",
          "layer4.1.conv1",
          "layer4.1.conv2",
          "layer4.1.conv3",
          "layer4.2.conv1",
          "layer4.2.conv2",
          "layer4.2.conv3",
          "fc"
         ],
         "y": [
          50,
          56,
          59,
          230,
          224,
          58,
          55,
          248,
          60,
          56,
          231,
          118,
          123,
          454,
          432,
          111,
          115,
          478,
          122,
          123,
          455,
          122,
          119,
          399,
          220,
          242,
          893,
          851,
          232,
          228,
          977,
          235,
          234,
          967,
          243,
          228,
          941,
          239,
          230,
          889,
          237,
          222,
          837,
          450,
          453,
          1419,
          1350,
          482,
          444,
          1295,
          495,
          441,
          1151,
          1000
         ]
        }
       ],
       "layout": {
        "barmode": "stack",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"95babafa-e7d2-4c9d-a4e3-9b05d2bcf314\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"95babafa-e7d2-4c9d-a4e3-9b05d2bcf314\")) {                    Plotly.newPlot(                        \"95babafa-e7d2-4c9d-a4e3-9b05d2bcf314\",                        [{\"name\":\"Active Neurons\",\"x\":[\"conv1\",\"layer1.0.conv1\",\"layer1.0.conv2\",\"layer1.0.conv3\",\"layer1.0.downsample.0\",\"layer1.1.conv1\",\"layer1.1.conv2\",\"layer1.1.conv3\",\"layer1.2.conv1\",\"layer1.2.conv2\",\"layer1.2.conv3\",\"layer2.0.conv1\",\"layer2.0.conv2\",\"layer2.0.conv3\",\"layer2.0.downsample.0\",\"layer2.1.conv1\",\"layer2.1.conv2\",\"layer2.1.conv3\",\"layer2.2.conv1\",\"layer2.2.conv2\",\"layer2.2.conv3\",\"layer2.3.conv1\",\"layer2.3.conv2\",\"layer2.3.conv3\",\"layer3.0.conv1\",\"layer3.0.conv2\",\"layer3.0.conv3\",\"layer3.0.downsample.0\",\"layer3.1.conv1\",\"layer3.1.conv2\",\"layer3.1.conv3\",\"layer3.2.conv1\",\"layer3.2.conv2\",\"layer3.2.conv3\",\"layer3.3.conv1\",\"layer3.3.conv2\",\"layer3.3.conv3\",\"layer3.4.conv1\",\"layer3.4.conv2\",\"layer3.4.conv3\",\"layer3.5.conv1\",\"layer3.5.conv2\",\"layer3.5.conv3\",\"layer4.0.conv1\",\"layer4.0.conv2\",\"layer4.0.conv3\",\"layer4.0.downsample.0\",\"layer4.1.conv1\",\"layer4.1.conv2\",\"layer4.1.conv3\",\"layer4.2.conv1\",\"layer4.2.conv2\",\"layer4.2.conv3\",\"fc\"],\"y\":[50,56,59,230,224,58,55,248,60,56,231,118,123,454,432,111,115,478,122,123,455,122,119,399,220,242,893,851,232,228,977,235,234,967,243,228,941,239,230,889,237,222,837,450,453,1419,1350,482,444,1295,495,441,1151,1000],\"type\":\"bar\"},{\"name\":\"Dense Width\",\"x\":[\"conv1\",\"layer1.0.conv1\",\"layer1.0.conv2\",\"layer1.0.conv3\",\"layer1.0.downsample.0\",\"layer1.1.conv1\",\"layer1.1.conv2\",\"layer1.1.conv3\",\"layer1.2.conv1\",\"layer1.2.conv2\",\"layer1.2.conv3\",\"layer2.0.conv1\",\"layer2.0.conv2\",\"layer2.0.conv3\",\"layer2.0.downsample.0\",\"layer2.1.conv1\",\"layer2.1.conv2\",\"layer2.1.conv3\",\"layer2.2.conv1\",\"layer2.2.conv2\",\"layer2.2.conv3\",\"layer2.3.conv1\",\"layer2.3.conv2\",\"layer2.3.conv3\",\"layer3.0.conv1\",\"layer3.0.conv2\",\"layer3.0.conv3\",\"layer3.0.downsample.0\",\"layer3.1.conv1\",\"layer3.1.conv2\",\"layer3.1.conv3\",\"layer3.2.conv1\",\"layer3.2.conv2\",\"layer3.2.conv3\",\"layer3.3.conv1\",\"layer3.3.conv2\",\"layer3.3.conv3\",\"layer3.4.conv1\",\"layer3.4.conv2\",\"layer3.4.conv3\",\"layer3.5.conv1\",\"layer3.5.conv2\",\"layer3.5.conv3\",\"layer4.0.conv1\",\"layer4.0.conv2\",\"layer4.0.conv3\",\"layer4.0.downsample.0\",\"layer4.1.conv1\",\"layer4.1.conv2\",\"layer4.1.conv3\",\"layer4.2.conv1\",\"layer4.2.conv2\",\"layer4.2.conv3\",\"fc\"],\"y\":[50,56,59,230,224,58,55,248,60,56,231,118,123,454,432,111,115,478,122,123,455,122,119,399,220,242,893,851,232,228,977,235,234,967,243,228,941,239,230,889,237,222,837,450,453,1419,1350,482,444,1295,495,441,1151,1000],\"type\":\"bar\"}],                        {\"barmode\":\"stack\",\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('95babafa-e7d2-4c9d-a4e3-9b05d2bcf314');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "df_slice = ablation_df.loc[ablation_df[\"rigl.dense_allocation\"]==0.01]\n",
    "df_slice\n",
    "\n",
    "data = [\n",
    "    go.Bar(\n",
    "        y=df_slice[\"active_neurons\"], x=df_slice[\"layer_name\"], name=\"Active Neurons\"\n",
    "    ),\n",
    "    go.Bar(\n",
    "        y=df_slice[\"active_neurons\"], x=df_slice[\"layer_name\"], name=\"Dense Width\"\n",
    "    ),\n",
    "    \n",
    "]\n",
    "layout = go.Layout(barmode=\"stack\")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense_allocation': {0: 0.01,\n",
       "  1: 0.05,\n",
       "  2: 0.0625,\n",
       "  3: 0.1,\n",
       "  4: 0.2,\n",
       "  5: 0.25,\n",
       "  6: 0.3,\n",
       "  7: 0.4,\n",
       "  8: 0.5},\n",
       " 'parameters': {0: 274072,\n",
       "  1: 1289784,\n",
       "  2: 1611784,\n",
       "  3: 2571656,\n",
       "  4: 5113920,\n",
       "  5: 6391944,\n",
       "  6: 7663032,\n",
       "  7: 10222975,\n",
       "  8: 12774296},\n",
       " 'dense_params': {0: 25557032,\n",
       "  1: 25557032,\n",
       "  2: 25557032,\n",
       "  3: 25557032,\n",
       "  4: 25557032,\n",
       "  5: 25557032,\n",
       "  6: 25557032,\n",
       "  7: 25557032,\n",
       "  8: 25557032}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(params).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Results for 0.95 sparsity...\n",
    "total el: 25557032\n",
    "non zero el: 1289784\n",
    "non zero weights only: 1262224\n",
    "0.05046689302576293\n",
    "\n",
    "Results for 0.9375 sparsity...\n",
    "total el: 25557032\n",
    "non zero el: 1611784\n",
    "non zero weights only: 1584224\n",
    "0.06306616511651275\n",
    "\n",
    "Results for 0.19999999999999996 sparsity...\n",
    "total el: 25557032\n",
    "non zero el: 20427879\n",
    "non zero weights only: 20400319\n",
    "0.7993056079438332\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RES50 - 93.75%\n",
    "els = []\n",
    "non_zero=[]\n",
    "for p in model.parameters():\n",
    "    els.append(p.numel())\n",
    "    non_zero.append(torch.count_nonzero(p))\n",
    "s=torch.tensor(non_zero).sum().item()\n",
    "n=torch.tensor(els).sum().item()\n",
    "w_total = torch.tensor([torch.count_nonzero(w) for w in pruner.W]).sum()\n",
    "print(f\"total el: {n}\")\n",
    "print(f\"non zero el: {s}\")\n",
    "print(f\"non zero weights only: {w_total}\")\n",
    "print(s/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total el: 25557032\n",
      "non zero el: 25530471\n",
      "0.9989607165652099\n"
     ]
    }
   ],
   "source": [
    "# RES50 - 100%\n",
    "els = []\n",
    "non_zero=[]\n",
    "for p in model.parameters():\n",
    "    els.append(p.numel())\n",
    "    non_zero.append(torch.count_nonzero(p))\n",
    "s=torch.tensor(non_zero).sum().item()\n",
    "n=torch.tensor(els).sum().item()\n",
    "print(f\"total el: {n}\")\n",
    "print(f\"non zero el: {s}\")\n",
    "print(s/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total el: 25557032\n",
      "non zero el: 6391944\n",
      "0.25010509827588745\n"
     ]
    }
   ],
   "source": [
    "# RES50 - 75%\n",
    "els = []\n",
    "non_zero=[]\n",
    "for p in model.parameters():\n",
    "    els.append(p.numel())\n",
    "    non_zero.append(torch.count_nonzero(p))\n",
    "s=torch.tensor(non_zero).sum().item()\n",
    "n=torch.tensor(els).sum().item()\n",
    "print(f\"total el: {n}\")\n",
    "print(f\"non zero el: {s}\")\n",
    "print(s/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total el: 25557032\n",
      "non zero el: 1289784\n",
      "non zero weights only: 1262224\n",
      "0.05046689302576293\n"
     ]
    }
   ],
   "source": [
    "# RES50 - 93.75%\n",
    "els = []\n",
    "non_zero=[]\n",
    "for p in model.parameters():\n",
    "    els.append(p.numel())\n",
    "    non_zero.append(torch.count_nonzero(p))\n",
    "s=torch.tensor(non_zero).sum().item()\n",
    "n=torch.tensor(els).sum().item()\n",
    "w_total = torch.tensor([torch.count_nonzero(w) for w in pruner.W]).sum()\n",
    "print(f\"total el: {n}\")\n",
    "print(f\"non zero el: {s}\")\n",
    "print(f\"non zero weights only: {w_total}\")\n",
    "print(s/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1584224)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([torch.count_nonzero(w) for w in pruner.W]).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "19152999\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total el: 6628793\n",
      "non zero el: 560246\n",
      "0.08451704556168822\n"
     ]
    }
   ],
   "source": [
    "# ADJUSTED SPARSITY SKINNY RESNET18\n",
    "els = []\n",
    "non_zero=[]\n",
    "for p in model.parameters():\n",
    "    els.append(p.numel())\n",
    "    non_zero.append(torch.count_nonzero(p))\n",
    "s=torch.tensor(non_zero).sum().item()\n",
    "n=torch.tensor(els).sum().item()\n",
    "print(f\"total el: {n}\")\n",
    "print(f\"non zero el: {s}\")\n",
    "print(s/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total el: 11173962\n",
      "non zero el: 560522\n",
      "0.05016322768951604\n"
     ]
    }
   ],
   "source": [
    "# RESNET18\n",
    "els = []\n",
    "non_zero=[]\n",
    "for p in model.parameters():\n",
    "    els.append(p.numel())\n",
    "    non_zero.append(torch.count_nonzero(p))\n",
    "s=torch.tensor(non_zero).sum().item()\n",
    "n=torch.tensor(els).sum().item()\n",
    "print(f\"total el: {n}\")\n",
    "print(f\"non zero el: {s}\")\n",
    "print(s/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6856706794132807"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11173962/6628793 = 1.6856706794132807\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total el: 6628793\n",
      "non zero el: 68494\n",
      "0.01033280116003019\n"
     ]
    }
   ],
   "source": [
    "# skinny\n",
    "els = []\n",
    "non_zero=[]\n",
    "for p in model.parameters():\n",
    "    els.append(p.numel())\n",
    "    non_zero.append(torch.count_nonzero(p))\n",
    "s=torch.tensor(non_zero).sum().item()\n",
    "n=torch.tensor(els).sum().item()\n",
    "print(f\"total el: {n}\")\n",
    "print(f\"non zero el: {s}\")\n",
    "print(s/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total el: 6628793\n",
      "non zero el: 114115\n",
      "0.017215049557287428\n"
     ]
    }
   ],
   "source": [
    "# skinny adjusted\n",
    "els = []\n",
    "non_zero=[]\n",
    "for p in model.parameters():\n",
    "    els.append(p.numel())\n",
    "    non_zero.append(torch.count_nonzero(p))\n",
    "s=torch.tensor(non_zero).sum().item()\n",
    "n=torch.tensor(els).sum().item()\n",
    "print(f\"total el: {n}\")\n",
    "print(f\"non zero el: {s}\")\n",
    "print(s/n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/for_anna_2/resnet18-99-50/20230112_f75f6a5m/checkpoint.pt.tar...\n",
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x7fb59595d090> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/for_anna_2/resnet18-99-50/20230112_2jjmdzam/checkpoint.pt.tar...\n",
      "Global seed set to 2078\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x7fb59595d090> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/for_anna_2/resnet18-99-50/20230112_tkcz3emd/checkpoint.pt.tar...\n",
      "Global seed set to 7303\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x7fb59595d090> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/for_anna_2/resnet18-99-50/20230112_37my33se/checkpoint.pt.tar...\n",
      "Global seed set to 6037\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x7fb59595d090> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': False, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    }
   ],
   "source": [
    "run_id = \"us1p7psr\" \n",
    "rank=0\n",
    "#  resnet18 0.01 0.5\n",
    "# runs = ['26t97fyn', 'f75f6a5m', '2jjmdzam', 'tkcz3emd','37my33se']\n",
    "# runs = ['f75f6a5m', '2jjmdzam', 'tkcz3emd','37my33se']\n",
    "runs = ['26ypkzes', 'uydgvx31', '2umeh1wv', '23bqr8zs']\n",
    "diets = []\n",
    "for run_id in runs:\n",
    "    dir = \"/home/user/condensed-sparsity/artifacts/checkpoints/for_anna_2/resnet18-99-50/\"\n",
    "    checkpoint = Checkpoint.load_last_checkpoint(run_id=run_id, parent_dir=dir)\n",
    "    # checkpoint = Checkpoint.load_last_checkpoint(run_id=run_id, parent_dir = cfg.paths.checkpoints)\n",
    "    # print(checkpoint)\n",
    "    # checkpoint=None\n",
    "    if checkpoint is not None:\n",
    "        run_id = checkpoint.run_id\n",
    "        optimizer_state = checkpoint.optimizer\n",
    "        scheduler_state = checkpoint.scheduler\n",
    "        pruner_state = checkpoint.pruner\n",
    "        model_state = checkpoint.model\n",
    "        cfg = checkpoint.cfg\n",
    "    else:\n",
    "        run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    print(cfg.compute)\n",
    "    cfg.compute.distributed=False\n",
    "        \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    if not use_cuda:\n",
    "        raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "        logger.warning(\n",
    "            \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "            \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "        )\n",
    "\n",
    "    if cfg.compute.distributed and use_cuda:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        print(f\"loading to device rank: {rank}\")\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    if not use_cuda:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "        if cfg.rigl.const_fan_in:\n",
    "            rigl_scheduler = RigLConstFanScheduler\n",
    "        else:\n",
    "            rigl_scheduler = RigLScheduler\n",
    "        pruner = rigl_scheduler(\n",
    "            model,\n",
    "            optimizer,\n",
    "            dense_allocation=cfg.rigl.dense_allocation,\n",
    "            alpha=cfg.rigl.alpha,\n",
    "            delta=cfg.rigl.delta,\n",
    "            static_topo=cfg.rigl.static_topo,\n",
    "            T_end=T_end,\n",
    "            ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "            grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "            sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "            erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "            state_dict=pruner_state,\n",
    "            filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "            static_ablation=cfg.rigl.static_ablation,\n",
    "            dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "            min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "            use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "            init_method_str=cfg.rigl.init_method_str,\n",
    "            use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "        )\n",
    "        \n",
    "        step=0\n",
    "\n",
    "    pruner = reinit_ablated_neuron_count(pruner)\n",
    "    diet = [len(d) for d in pruner.dynamically_ablated_neuron_idx]\n",
    "    diets.append(diet)\n",
    "\n",
    "    \n",
    "    # checkpoint = Checkpoint(\n",
    "    #             run_id=run_id,\n",
    "    #             cfg=cfg,\n",
    "    #             model=model,\n",
    "    #             optimizer=optimizer,\n",
    "    #             scheduler=scheduler,\n",
    "    #             pruner=pruner,\n",
    "    #             epoch=0,\n",
    "    #             step=step,\n",
    "    #             parent_dir=cfg.paths.checkpoints,\n",
    "    #         )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11164352)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(pruner.N).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor()and\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16, 19, 18, 16])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(diets)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 15,\n",
       " 17,\n",
       " 13,\n",
       " 17,\n",
       " 31,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 27,\n",
       " 59,\n",
       " 56,\n",
       " 58,\n",
       " 63,\n",
       " 58,\n",
       " 119,\n",
       " 121,\n",
       " 120,\n",
       " 115,\n",
       " 125,\n",
       " 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17,\n",
       " 16,\n",
       " 17,\n",
       " 14,\n",
       " 16,\n",
       " 33,\n",
       " 31,\n",
       " 31,\n",
       " 32,\n",
       " 30,\n",
       " 65,\n",
       " 63,\n",
       " 63,\n",
       " 65,\n",
       " 63,\n",
       " 122,\n",
       " 124,\n",
       " 124,\n",
       " 114,\n",
       " 125,\n",
       " 0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(diets, dtype=torch.float).mean(dim=0).type(dtype=torch.int).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1.9]], dtype=torch.float).type(dtype=torch.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.399999618530273,\n",
       " 16.399999618530273,\n",
       " 17.200000762939453,\n",
       " 14.600000381469727,\n",
       " 16.200000762939453,\n",
       " 33.400001525878906,\n",
       " 31.200000762939453,\n",
       " 31.200000762939453,\n",
       " 32.400001525878906,\n",
       " 30.399999618530273,\n",
       " 65.19999694824219,\n",
       " 63.0,\n",
       " 63.20000076293945,\n",
       " 65.0,\n",
       " 63.0,\n",
       " 122.19999694824219,\n",
       " 124.4000015258789,\n",
       " 124.4000015258789,\n",
       " 114.0,\n",
       " 125.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(diets, dtype=torch.float).mean(dim=0).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigLScheduler(\n",
      "layers=21,\n",
      "nonzero_params=[864/1728, 1624/36864, 1628/36864, 1617/36864, 1610/36864, 2400/73728, 3116/147456, 2325/8192, 3136/147456, 3124/147456, 4704/294912, 6256/589824, 4655/32768, 6272/589824, 6300/589824, 9292/1179648, 12420/2359296, 9360/131072, 12506/2359296, 12444/2359296, 5120/5120],\n",
      "nonzero_percentages=[50.00%, 4.41%, 4.42%, 4.39%, 4.37%, 3.26%, 2.11%, 28.38%, 2.13%, 2.12%, 1.60%, 1.06%, 14.21%, 1.06%, 1.07%, 0.79%, 0.53%, 7.14%, 0.53%, 0.53%, 100.00%],\n",
      "total_nonzero_params=110773/11164352 (0.99%),\n",
      "total_CONV_nonzero_params=105653/11159232 (0.95%),\n",
      "step=97500,\n",
      "num_rigl_steps=731,\n",
      "ignoring_linear_layers=False,\n",
      "sparsity_distribution=erk,\n",
      "ITOP rate=0.2386,\n",
      "Active Neuron Count=[(32, 64), (29, 64), (37, 64), (33, 64), (35, 64), (60, 128), (76, 128), (75, 128), (64, 128), (71, 128), (112, 256), (136, 256), (133, 256), (112, 256), (105, 256), (202, 512), (207, 512), (208, 512), (169, 512), (204, 512), (10, 10)],\n",
      "constant fan ins=[27, 56, 44, 49, 46, 40, 41, 31, 49, 44, 42, 46, 35, 56, 60, 46, 60, 45, 74, 61, 512]\n",
      "Neurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Neurons Dynamically Ablated per layer = [18, 16, 18, 12, 17, 34, 30, 29, 30, 30, 64, 65, 64, 66, 63, 127, 120, 118, 107, 117, 0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pruner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rigl_torch.utils.rigl_utils import get_names_and_W\n",
    "names, W = get_names_and_W(model)\n",
    "ablated = [0, 22, 20, 26, 18, 51, 34, 0, 56, 38, 114, 102, 64, 114, 121, 248, 223, 218, 286, 221, 0]\n",
    "len(W) == len(ablated) == len(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 128,\n",
       " 256,\n",
       " 256,\n",
       " 256,\n",
       " 256,\n",
       " 256,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 512,\n",
       " 10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1',\n",
       " 'layer1.0.conv1',\n",
       " 'layer1.0.conv2',\n",
       " 'layer1.1.conv1',\n",
       " 'layer1.1.conv2',\n",
       " 'layer2.0.conv1',\n",
       " 'layer2.0.conv2',\n",
       " 'layer2.0.shortcut.0',\n",
       " 'layer2.1.conv1',\n",
       " 'layer2.1.conv2',\n",
       " 'layer3.0.conv1',\n",
       " 'layer3.0.conv2',\n",
       " 'layer3.0.shortcut.0',\n",
       " 'layer3.1.conv1',\n",
       " 'layer3.1.conv2',\n",
       " 'layer4.0.conv1',\n",
       " 'layer4.0.conv2',\n",
       " 'layer4.0.shortcut.0',\n",
       " 'layer4.1.conv1',\n",
       " 'layer4.1.conv2',\n",
       " 'linear']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x7f07ecf001f0> with args: () and kwargs: {}\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from typing import Optional\n",
    "\n",
    "class SkinnyBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels , stride, skip_conn_input_channels: Optional[int]=None ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels=out_channels[0],\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels[0])\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels[0], out_channels[1], kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels[1])\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if skip_conn_input_channels is not None:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    out_channels[1],\n",
    "                    skip_conn_input_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(skip_conn_input_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SkinnyResNet18(nn.Module):\n",
    "    def __init__(self, full_width_network: nn.Module, diet: List[int], num_blocks: List[int], num_classes=10):\n",
    "        super().__init__()\n",
    "        self.num_blocks=num_blocks\n",
    "        self.names, full_w = get_names_and_W(full_width_network)\n",
    "        self.diet = diet\n",
    "        self.full_width = [len(w) for w in full_w]\n",
    "        self.width = [fw-d for fw,d in list(zip(self.full_width, self.diet))]\n",
    "        self._in_channel_idx=0\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, self.width[0], kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.width[0])\n",
    "        self.layer1 = self._make_layer(\n",
    "                num_blocks=self.num_blocks[0],\n",
    "                stride=1,\n",
    "            )\n",
    "        self.layer2 = self._make_layer(\n",
    "            num_blocks=self.num_blocks[0],\n",
    "                stride=2,\n",
    "            )\n",
    "        self.layer3 = self._make_layer(\n",
    "            num_blocks=self.num_blocks[0],\n",
    "                stride=2,\n",
    "            )\n",
    "        self.layer4 = self._make_layer(\n",
    "            num_blocks=self.num_blocks[0],\n",
    "\n",
    "                stride=2\n",
    "            )\n",
    "        self.linear = nn.Linear(self.width[-1] * SkinnyBlock.expansion, num_classes)\n",
    "        _, skinny_w = get_names_and_W(self)\n",
    "        assert [len(w) for w in skinny_w] == self.width\n",
    "        \n",
    "    @property\n",
    "    def _block_start_idx(self):\n",
    "        return self._in_channel_idx+1\n",
    "    \n",
    "    def _make_layer(self, num_blocks, stride):\n",
    "        strides: List[int] = [stride] + [1] * (num_blocks - 1)\n",
    "        layers=[]\n",
    "        in_channels = self.width[self._in_channel_idx]\n",
    "        \n",
    "        for stride in strides:\n",
    "            skip_conn_input_channels=None\n",
    "            if stride != 1:\n",
    "                skip_conn_input_channels=self.width[self._block_start_idx+num_blocks]\n",
    "            layers.append(\n",
    "                SkinnyBlock(\n",
    "                    self.width[self._in_channel_idx],\n",
    "                    self.width[self._block_start_idx:self._block_start_idx+num_blocks],\n",
    "                    stride=stride, \n",
    "                    skip_conn_input_channels=skip_conn_input_channels,\n",
    "                )\n",
    "            )\n",
    "            if skip_conn_input_channels is None:\n",
    "                # We only need to move index num blocks away\n",
    "                self._in_channel_idx+=num_blocks \n",
    "            else:\n",
    "                # Else we need to move past this layers skip conn too\n",
    "                self._in_channel_idx+=num_blocks+1\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "model = ModelFactory.load_model(\n",
    "    model=cfg.model.name, dataset=cfg.dataset.name\n",
    ")\n",
    "                          \n",
    "from rigl_torch.utils.rigl_utils import get_names_and_W\n",
    "names, W = get_names_and_W(model)\n",
    "ablated = [0, 22, 20, 26, 18, 51, 34, 0, 56, 38, 114, 102, 64, 114, 121, 248, 223, 218, 286, 221, 0]\n",
    "len(W) == len(ablated) == len(names)\n",
    "[len(w) for w in W]\n",
    "\n",
    "net = SkinnyResNet18(\n",
    "    full_width_network=model,\n",
    "    diet=ablated,\n",
    "    num_blocks=[2,2,2,2]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train()\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discon = pruner.backward_masks[1][17]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 3, 3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[2].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:0')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[2][:,17].any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruner.W[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 17\n",
      "disconnected at (2, 17)? True\n",
      "1 19\n",
      "disconnected at (2, 19)? True\n",
      "1 25\n",
      "disconnected at (2, 25)? True\n",
      "1 32\n",
      "disconnected at (2, 32)? True\n",
      "1 36\n",
      "disconnected at (2, 36)? True\n",
      "1 40\n",
      "disconnected at (2, 40)? True\n",
      "1 49\n",
      "disconnected at (2, 49)? True\n",
      "1 55\n",
      "disconnected at (2, 55)? True\n",
      "1 60\n",
      "disconnected at (2, 60)? True\n",
      "2 8\n",
      "disconnected at (3, 8)? True\n",
      "2 25\n",
      "disconnected at (3, 25)? True\n",
      "2 40\n",
      "disconnected at (3, 40)? True\n",
      "2 61\n",
      "disconnected at (3, 61)? True\n",
      "3 3\n",
      "disconnected at (4, 3)? True\n",
      "3 5\n",
      "disconnected at (4, 5)? True\n",
      "3 16\n",
      "disconnected at (4, 16)? True\n",
      "3 25\n",
      "disconnected at (4, 25)? True\n",
      "3 38\n",
      "disconnected at (4, 38)? True\n",
      "3 42\n",
      "disconnected at (4, 42)? True\n",
      "3 45\n",
      "disconnected at (4, 45)? True\n",
      "3 49\n",
      "disconnected at (4, 49)? True\n",
      "3 52\n",
      "disconnected at (4, 52)? True\n",
      "4 32\n",
      "disconnected at (5, 32)? True\n",
      "4 40\n",
      "disconnected at (5, 40)? True\n",
      "4 59\n",
      "disconnected at (5, 59)? True\n",
      "5 6\n",
      "disconnected at (6, 6)? True\n",
      "5 10\n",
      "disconnected at (6, 10)? True\n",
      "5 17\n",
      "disconnected at (6, 17)? True\n",
      "5 28\n",
      "disconnected at (6, 28)? True\n",
      "5 31\n",
      "disconnected at (6, 31)? True\n",
      "5 33\n",
      "disconnected at (6, 33)? True\n",
      "5 41\n",
      "disconnected at (6, 41)? True\n",
      "5 46\n",
      "disconnected at (6, 46)? True\n",
      "5 53\n",
      "disconnected at (6, 53)? True\n",
      "5 56\n",
      "disconnected at (6, 56)? True\n",
      "5 59\n",
      "disconnected at (6, 59)? True\n",
      "5 66\n",
      "disconnected at (6, 66)? True\n",
      "5 72\n",
      "disconnected at (6, 72)? True\n",
      "5 75\n",
      "disconnected at (6, 75)? True\n",
      "5 77\n",
      "disconnected at (6, 77)? True\n",
      "5 85\n",
      "disconnected at (6, 85)? True\n",
      "5 101\n",
      "disconnected at (6, 101)? True\n",
      "5 107\n",
      "disconnected at (6, 107)? True\n",
      "5 111\n",
      "disconnected at (6, 111)? True\n",
      "5 113\n",
      "disconnected at (6, 113)? True\n",
      "5 122\n",
      "disconnected at (6, 122)? True\n",
      "5 125\n",
      "disconnected at (6, 125)? True\n",
      "5 127\n",
      "disconnected at (6, 127)? True\n",
      "inc short\n",
      "6 1\n",
      "disconnected at (7, 1)? False\n",
      "6 17\n",
      "disconnected at (7, 17)? True\n",
      "6 18\n",
      "disconnected at (7, 18)? True\n",
      "6 41\n",
      "disconnected at (7, 41)? True\n",
      "6 67\n",
      "disconnected at (7, 67)? True\n",
      "6 68\n",
      "disconnected at (7, 68)? True\n",
      "6 75\n",
      "disconnected at (7, 75)? False\n",
      "6 81\n",
      "disconnected at (7, 81)? True\n",
      "6 121\n",
      "disconnected at (7, 121)? True\n",
      "8 5\n",
      "disconnected at (9, 5)? False\n",
      "8 16\n",
      "disconnected at (9, 16)? False\n",
      "8 24\n",
      "disconnected at (9, 24)? False\n",
      "8 27\n",
      "disconnected at (9, 27)? False\n",
      "8 34\n",
      "disconnected at (9, 34)? False\n",
      "8 36\n",
      "disconnected at (9, 36)? False\n",
      "8 45\n",
      "disconnected at (9, 45)? False\n",
      "8 47\n",
      "disconnected at (9, 47)? False\n",
      "8 48\n",
      "disconnected at (9, 48)? False\n",
      "8 50\n",
      "disconnected at (9, 50)? False\n",
      "8 52\n",
      "disconnected at (9, 52)? False\n",
      "8 60\n",
      "disconnected at (9, 60)? False\n",
      "8 62\n",
      "disconnected at (9, 62)? False\n",
      "8 69\n",
      "disconnected at (9, 69)? False\n",
      "8 71\n",
      "disconnected at (9, 71)? False\n",
      "8 72\n",
      "disconnected at (9, 72)? False\n",
      "8 76\n",
      "disconnected at (9, 76)? False\n",
      "8 90\n",
      "disconnected at (9, 90)? False\n",
      "8 93\n",
      "disconnected at (9, 93)? False\n",
      "8 99\n",
      "disconnected at (9, 99)? False\n",
      "8 104\n",
      "disconnected at (9, 104)? False\n",
      "8 120\n",
      "disconnected at (9, 120)? False\n",
      "8 126\n",
      "disconnected at (9, 126)? True\n",
      "9 1\n",
      "disconnected at (10, 1)? False\n",
      "9 18\n",
      "disconnected at (10, 18)? False\n",
      "9 28\n",
      "disconnected at (10, 28)? False\n",
      "9 41\n",
      "disconnected at (10, 41)? False\n",
      "9 50\n",
      "disconnected at (10, 50)? False\n",
      "9 67\n",
      "disconnected at (10, 67)? False\n",
      "9 68\n",
      "disconnected at (10, 68)? False\n",
      "9 75\n",
      "disconnected at (10, 75)? False\n",
      "9 81\n",
      "disconnected at (10, 81)? False\n",
      "9 121\n",
      "disconnected at (10, 121)? False\n",
      "9 124\n",
      "disconnected at (10, 124)? True\n",
      "10 12\n",
      "disconnected at (11, 12)? False\n",
      "10 13\n",
      "disconnected at (11, 13)? False\n",
      "10 16\n",
      "disconnected at (11, 16)? False\n",
      "10 17\n",
      "disconnected at (11, 17)? False\n",
      "10 19\n",
      "disconnected at (11, 19)? False\n",
      "10 27\n",
      "disconnected at (11, 27)? False\n",
      "10 31\n",
      "disconnected at (11, 31)? False\n",
      "10 32\n",
      "disconnected at (11, 32)? False\n",
      "10 40\n",
      "disconnected at (11, 40)? False\n",
      "10 49\n",
      "disconnected at (11, 49)? False\n",
      "10 51\n",
      "disconnected at (11, 51)? False\n",
      "10 55\n",
      "disconnected at (11, 55)? False\n",
      "10 56\n",
      "disconnected at (11, 56)? False\n",
      "10 60\n",
      "disconnected at (11, 60)? False\n",
      "10 61\n",
      "disconnected at (11, 61)? False\n",
      "10 70\n",
      "disconnected at (11, 70)? False\n",
      "10 88\n",
      "disconnected at (11, 88)? False\n",
      "10 89\n",
      "disconnected at (11, 89)? False\n",
      "10 91\n",
      "disconnected at (11, 91)? False\n",
      "10 93\n",
      "disconnected at (11, 93)? False\n",
      "10 99\n",
      "disconnected at (11, 99)? False\n",
      "10 101\n",
      "disconnected at (11, 101)? False\n",
      "10 102\n",
      "disconnected at (11, 102)? False\n",
      "10 105\n",
      "disconnected at (11, 105)? False\n",
      "10 109\n",
      "disconnected at (11, 109)? False\n",
      "10 113\n",
      "disconnected at (11, 113)? False\n",
      "10 116\n",
      "disconnected at (11, 116)? False\n",
      "10 124\n",
      "disconnected at (11, 124)? True\n",
      "10 134\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 134 is out of bounds for dimension 1 with size 128",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [119], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n\u001b[39m.\u001b[39many():\n\u001b[1;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(layer_idx, n_idx)\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdisconnected at \u001b[39m\u001b[39m{\u001b[39;00mlayer_idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m ,n_idx\u001b[39m}\u001b[39;00m\u001b[39m? \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mnot\u001b[39;00m pruner\u001b[39m.\u001b[39mbackward_masks[layer_idx\u001b[39m+\u001b[39mshortcut_increment][:,n_idx]\u001b[39m.\u001b[39many()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 134 is out of bounds for dimension 1 with size 128"
     ]
    }
   ],
   "source": [
    "shortcut_increment = 1 \n",
    "for layer_idx, w in enumerate(pruner.W):\n",
    "    if pruner.backward_masks[layer_idx+1].shape[1] != w.shape[0]:\n",
    "        print(\"inc short\")\n",
    "        shortcut_increment+=1\n",
    "    for n_idx, n in enumerate(w):\n",
    "        if not n.any():\n",
    "            print(layer_idx, n_idx)\n",
    "            print(f\"disconnected at {layer_idx+1 ,n_idx}? {not pruner.backward_masks[layer_idx+shortcut_increment][:,n_idx].any()}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t._parameters[\"weight\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[6].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 1, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[7].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13, device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(pruner.W[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13, device='cuda:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[0][0].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in pruner.W[0]:\n",
    "    if torch.count_nonzero(n) == 0:\n",
    "        print(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 4, 9, 3, 23, 9, 0, 23, 11, 53, 19, 12, 51, 24, 108, 69, 53, 92, 53, 0]\n"
     ]
    }
   ],
   "source": [
    "ablated = []\n",
    "for layer_idx, layer in enumerate(pruner.W):\n",
    "    layer_ablated = []\n",
    "    for n_idx, n in enumerate(layer):\n",
    "        if torch.count_nonzero(pruner.W[layer_idx][n_idx]) == 0:\n",
    "            layer_ablated.append(n_idx)\n",
    "    ablated.append(layer_ablated)\n",
    "print([len(a) for a in ablated])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([not n.any() for n in pruner.W[0]]).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(736, device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pruner.W[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor(13, device='cuda:0'),\n",
       "  tensor(6, device='cuda:0'),\n",
       "  tensor(11, device='cuda:0'),\n",
       "  tensor(12, device='cuda:0'),\n",
       "  tensor(6, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(9, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(7, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(8, device='cuda:0'),\n",
       "  tensor(12, device='cuda:0'),\n",
       "  tensor(12, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(12, device='cuda:0'),\n",
       "  tensor(8, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(7, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(12, device='cuda:0'),\n",
       "  tensor(6, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(10, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(9, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(5, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(12, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(10, device='cuda:0'),\n",
       "  tensor(5, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(10, device='cuda:0'),\n",
       "  tensor(11, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0')],\n",
       " [tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(10, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0')],\n",
       " [tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(23, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0')],\n",
       " [tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0')],\n",
       " [tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0'),\n",
       "  tensor(25, device='cuda:0')],\n",
       " [tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(10, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(7, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(23, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0')],\n",
       " [tensor(18, device='cuda:0'),\n",
       "  tensor(6, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(15, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(8, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(17, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(23, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0')],\n",
       " [tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(21, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(22, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(23, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [tensor(17, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(15, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(5, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(17, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(5, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(9, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(8, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(8, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(15, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(15, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(13, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(22, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(23, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(22, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0')],\n",
       " [tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(17, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(17, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0'),\n",
       "  tensor(18, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(23, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(5, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(6, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(23, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(14, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(4, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(7, device='cuda:0'),\n",
       "  tensor(3, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0')],\n",
       " [tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(1, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(2, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(0, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0'),\n",
       "  tensor(24, device='cuda:0')],\n",
       " [tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0'),\n",
       "  tensor(512, device='cuda:0')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ [torch.count_nonzero(n) for n in layer] for layer in pruner.W ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pruner.W:\n",
    "    total = []\n",
    "    for n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(832, device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.backward_masks[0].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(736, device='cuda:0')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(pruner.W[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(13, device='cuda:0')\n",
      "1\n",
      "tensor(6, device='cuda:0')\n",
      "2\n",
      "tensor(11, device='cuda:0')\n",
      "3\n",
      "tensor(12, device='cuda:0')\n",
      "4\n",
      "tensor(6, device='cuda:0')\n",
      "5\n",
      "tensor(13, device='cuda:0')\n",
      "6\n",
      "tensor(9, device='cuda:0')\n",
      "7\n",
      "tensor(13, device='cuda:0')\n",
      "8\n",
      "tensor(13, device='cuda:0')\n",
      "9\n",
      "tensor(13, device='cuda:0')\n",
      "10\n",
      "tensor(7, device='cuda:0')\n",
      "11\n",
      "tensor(13, device='cuda:0')\n",
      "12\n",
      "tensor(13, device='cuda:0')\n",
      "13\n",
      "tensor(8, device='cuda:0')\n",
      "14\n",
      "tensor(12, device='cuda:0')\n",
      "15\n",
      "tensor(12, device='cuda:0')\n",
      "16\n",
      "tensor(13, device='cuda:0')\n",
      "17\n",
      "tensor(12, device='cuda:0')\n",
      "18\n",
      "tensor(8, device='cuda:0')\n",
      "19\n",
      "tensor(13, device='cuda:0')\n",
      "20\n",
      "tensor(7, device='cuda:0')\n",
      "21\n",
      "tensor(13, device='cuda:0')\n",
      "22\n",
      "tensor(13, device='cuda:0')\n",
      "23\n",
      "tensor(13, device='cuda:0')\n",
      "24\n",
      "tensor(13, device='cuda:0')\n",
      "25\n",
      "tensor(13, device='cuda:0')\n",
      "26\n",
      "tensor(13, device='cuda:0')\n",
      "27\n",
      "tensor(13, device='cuda:0')\n",
      "28\n",
      "tensor(13, device='cuda:0')\n",
      "29\n",
      "tensor(13, device='cuda:0')\n",
      "30\n",
      "tensor(3, device='cuda:0')\n",
      "31\n",
      "tensor(13, device='cuda:0')\n",
      "32\n",
      "tensor(12, device='cuda:0')\n",
      "33\n",
      "tensor(6, device='cuda:0')\n",
      "34\n",
      "tensor(13, device='cuda:0')\n",
      "35\n",
      "tensor(13, device='cuda:0')\n",
      "36\n",
      "tensor(10, device='cuda:0')\n",
      "37\n",
      "tensor(13, device='cuda:0')\n",
      "38\n",
      "tensor(13, device='cuda:0')\n",
      "39\n",
      "tensor(13, device='cuda:0')\n",
      "40\n",
      "tensor(13, device='cuda:0')\n",
      "41\n",
      "tensor(13, device='cuda:0')\n",
      "42\n",
      "tensor(13, device='cuda:0')\n",
      "43\n",
      "tensor(13, device='cuda:0')\n",
      "44\n",
      "tensor(9, device='cuda:0')\n",
      "45\n",
      "tensor(13, device='cuda:0')\n",
      "46\n",
      "tensor(5, device='cuda:0')\n",
      "47\n",
      "tensor(13, device='cuda:0')\n",
      "48\n",
      "tensor(13, device='cuda:0')\n",
      "49\n",
      "tensor(12, device='cuda:0')\n",
      "50\n",
      "tensor(13, device='cuda:0')\n",
      "51\n",
      "tensor(13, device='cuda:0')\n",
      "52\n",
      "tensor(13, device='cuda:0')\n",
      "53\n",
      "tensor(13, device='cuda:0')\n",
      "54\n",
      "tensor(10, device='cuda:0')\n",
      "55\n",
      "tensor(5, device='cuda:0')\n",
      "56\n",
      "tensor(13, device='cuda:0')\n",
      "57\n",
      "tensor(13, device='cuda:0')\n",
      "58\n",
      "tensor(10, device='cuda:0')\n",
      "59\n",
      "tensor(11, device='cuda:0')\n",
      "60\n",
      "tensor(13, device='cuda:0')\n",
      "61\n",
      "tensor(13, device='cuda:0')\n",
      "62\n",
      "tensor(13, device='cuda:0')\n",
      "63\n",
      "tensor(13, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for idx, neuron in enumerate(pruner.W[0]):\n",
    "    print(idx)\n",
    "    print(torch.count_nonzero(neuron))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for mask in pruner.backward_masks:\n",
    "    for neuron in \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = reinit_ablated_neuron_count(pruner)\n",
    "# pruner.dynamically_ablated_neuron_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinit_ablated_neuron_count(pruner: RigLConstFanScheduler) -> RigLConstFanScheduler:\n",
    "    pruner.dynamically_ablated_neuron_idx=dynamically_ablated_neurons = [ [x for x in list(range(len(layer))) if x not in layer] for layer in pruner.active_neurons]\n",
    "    for layer_idx, layer in enumerate(pruner.dynamically_ablated_neuron_idx):\n",
    "        for neuron_idx in layer:\n",
    "            assert not pruner.backward_masks[layer_idx][neuron_idx].any()\n",
    "            assert (pruner.W[layer_idx][neuron_idx]==0).all()\n",
    "    return pruner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dynamically_ablated_neurons[0]:\n",
    "    if x in pruner.active_neurons[0]:\n",
    "        print(\"uhoh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 39,\n",
       " 41,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 61]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.active_neurons[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 18, 19, 20, 22, 23, 25, 30],\n",
       " [0, 1, 3, 5, 6, 7, 8, 10, 15, 19, 21, 22, 23, 24, 25, 26],\n",
       " [0, 2, 3, 4, 6, 8, 12, 14, 17, 18, 20, 21, 22, 23, 25, 28, 30, 34],\n",
       " [0, 1, 3, 5, 9, 11, 14, 15, 18, 19, 23, 32],\n",
       " [0, 2, 4, 6, 8, 9, 10, 12, 14, 15, 18, 21, 23, 27, 28, 29, 30],\n",
       " [0,\n",
       "  2,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  15,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  51,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58],\n",
       " [1,\n",
       "  3,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  16,\n",
       "  17,\n",
       "  22,\n",
       "  24,\n",
       "  28,\n",
       "  31,\n",
       "  34,\n",
       "  36,\n",
       "  39,\n",
       "  41,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  62,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  73],\n",
       " [1,\n",
       "  3,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  16,\n",
       "  17,\n",
       "  22,\n",
       "  24,\n",
       "  28,\n",
       "  31,\n",
       "  34,\n",
       "  36,\n",
       "  38,\n",
       "  39,\n",
       "  41,\n",
       "  42,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  67,\n",
       "  68],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  10,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  22,\n",
       "  24,\n",
       "  25,\n",
       "  28,\n",
       "  31,\n",
       "  32,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  41,\n",
       "  47,\n",
       "  50,\n",
       "  51,\n",
       "  53,\n",
       "  55,\n",
       "  57,\n",
       "  60],\n",
       " [1,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  14,\n",
       "  16,\n",
       "  17,\n",
       "  22,\n",
       "  28,\n",
       "  36,\n",
       "  39,\n",
       "  41,\n",
       "  45,\n",
       "  47,\n",
       "  48,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  61,\n",
       "  64,\n",
       "  67,\n",
       "  68],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  13,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  43,\n",
       "  45,\n",
       "  46,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  52,\n",
       "  55,\n",
       "  56,\n",
       "  59,\n",
       "  60,\n",
       "  62,\n",
       "  63,\n",
       "  66,\n",
       "  67,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  79,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  101,\n",
       "  102,\n",
       "  107,\n",
       "  109,\n",
       "  110,\n",
       "  111],\n",
       " [1,\n",
       "  4,\n",
       "  7,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  23,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  48,\n",
       "  50,\n",
       "  53,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  111,\n",
       "  112,\n",
       "  115,\n",
       "  117,\n",
       "  119,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  131,\n",
       "  133,\n",
       "  135],\n",
       " [1,\n",
       "  4,\n",
       "  7,\n",
       "  9,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  23,\n",
       "  27,\n",
       "  29,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  48,\n",
       "  50,\n",
       "  53,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  111,\n",
       "  112,\n",
       "  115,\n",
       "  117,\n",
       "  119,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  131,\n",
       "  132],\n",
       " [0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  20,\n",
       "  22,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  35,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  53,\n",
       "  55,\n",
       "  57,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  70,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  76,\n",
       "  78,\n",
       "  79,\n",
       "  83,\n",
       "  85,\n",
       "  91,\n",
       "  94,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  111],\n",
       " [1,\n",
       "  4,\n",
       "  7,\n",
       "  11,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  26,\n",
       "  27,\n",
       "  29,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  52,\n",
       "  53,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  80,\n",
       "  81,\n",
       "  86,\n",
       "  88,\n",
       "  90,\n",
       "  92,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  103,\n",
       "  104],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  9,\n",
       "  12,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  28,\n",
       "  30,\n",
       "  31,\n",
       "  34,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  41,\n",
       "  42,\n",
       "  45,\n",
       "  46,\n",
       "  48,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  55,\n",
       "  58,\n",
       "  59,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  69,\n",
       "  70,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  77,\n",
       "  79,\n",
       "  81,\n",
       "  82,\n",
       "  85,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  97,\n",
       "  98,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  110,\n",
       "  111,\n",
       "  114,\n",
       "  115,\n",
       "  119,\n",
       "  121,\n",
       "  125,\n",
       "  130,\n",
       "  131,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  140,\n",
       "  141,\n",
       "  143,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  152,\n",
       "  154,\n",
       "  156,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  163,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  174,\n",
       "  175,\n",
       "  176,\n",
       "  178,\n",
       "  179,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  188,\n",
       "  189,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  195,\n",
       "  196,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201],\n",
       " [0,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  23,\n",
       "  25,\n",
       "  27,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  40,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  84,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  95,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  109,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  115,\n",
       "  116,\n",
       "  118,\n",
       "  120,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  147,\n",
       "  148,\n",
       "  154,\n",
       "  156,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  165,\n",
       "  166,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  182,\n",
       "  183,\n",
       "  186,\n",
       "  187,\n",
       "  193,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  203,\n",
       "  205],\n",
       " [0,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  23,\n",
       "  25,\n",
       "  27,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  84,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  95,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  109,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  115,\n",
       "  116,\n",
       "  118,\n",
       "  120,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  154,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  165,\n",
       "  166,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  182,\n",
       "  183,\n",
       "  186,\n",
       "  187,\n",
       "  193,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  203,\n",
       "  205],\n",
       " [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  49,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  62,\n",
       "  63,\n",
       "  65,\n",
       "  67,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  78,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  95,\n",
       "  97,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  111,\n",
       "  112,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  133,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  145,\n",
       "  146,\n",
       "  149,\n",
       "  151,\n",
       "  153,\n",
       "  154,\n",
       "  157,\n",
       "  164,\n",
       "  166,\n",
       "  167],\n",
       " [0,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  25,\n",
       "  27,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  62,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  84,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  91,\n",
       "  92,\n",
       "  94,\n",
       "  95,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  109,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  115,\n",
       "  116,\n",
       "  118,\n",
       "  120,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  147,\n",
       "  148,\n",
       "  150,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  165,\n",
       "  166,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  182,\n",
       "  183,\n",
       "  186,\n",
       "  187,\n",
       "  193,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  200,\n",
       "  201,\n",
       "  203],\n",
       " []]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ [x for x in list(range(len(layer))) if x not in layer] for layer in pruner.active_neurons]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigLScheduler(\n",
      "layers=21,\n",
      "nonzero_params=[864/1728, 1624/36864, 1628/36864, 1617/36864, 1610/36864, 2400/73728, 3116/147456, 2325/8192, 3136/147456, 3124/147456, 4704/294912, 6256/589824, 4655/32768, 6272/589824, 6300/589824, 9292/1179648, 12420/2359296, 9360/131072, 12506/2359296, 12444/2359296, 5120/5120],\n",
      "nonzero_percentages=[50.00%, 4.41%, 4.42%, 4.39%, 4.37%, 3.26%, 2.11%, 28.38%, 2.13%, 2.12%, 1.60%, 1.06%, 14.21%, 1.06%, 1.07%, 0.79%, 0.53%, 7.14%, 0.53%, 0.53%, 100.00%],\n",
      "total_nonzero_params=110773/11164352 (0.99%),\n",
      "total_CONV_nonzero_params=105653/11159232 (0.95%),\n",
      "step=97500,\n",
      "num_rigl_steps=731,\n",
      "ignoring_linear_layers=False,\n",
      "sparsity_distribution=erk,\n",
      "ITOP rate=0.2386,\n",
      "Active Neuron Count=[(32, 64), (29, 64), (37, 64), (33, 64), (35, 64), (60, 128), (76, 128), (75, 128), (64, 128), (71, 128), (112, 256), (136, 256), (133, 256), (112, 256), (105, 256), (202, 512), (207, 512), (208, 512), (169, 512), (204, 512), (10, 10)],\n",
      "constant fan ins=[27, 56, 44, 49, 46, 40, 41, 31, 49, 44, 42, 46, 35, 56, 60, 46, 60, 45, 74, 61, 512]\n",
      "Neurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Neurons Dynamically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pruner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_dynamic_ablated_neuron_idx = \n",
    "\n",
    "\n",
    "# pruner.dynamically_ablated_neuron_idx  = [[list(range(x)) for x in] for layer_idx, layer in enumerate(pruner.active_neurons)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9408"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[0].numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(384, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(pruner.W[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580298609954484"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9408"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.N[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9592, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- pruner.backward_masks[0].sum() / pruner.W[0].numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-384/9408\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/build/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:124: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a155be850>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lrs=[]\n",
    "for _ in list(range(1,149)):\n",
    "    scheduler.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "\n",
    "plt.plot(lrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:New best checkpoint accuracy (0.000000 > -inf)!\n"
     ]
    }
   ],
   "source": [
    "scheduler_state_dict, optimizer_state_dict = checkpoint.get_state()[\"scheduler\"], checkpoint.get_state()[\"optimizer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading optimizer from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "new_optim = get_optimizer(cfg, model, optimizer_state_dict)\n",
    "ckp_scheduler= get_lr_scheduler(cfg, new_optim, state_dict=scheduler_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': [150, 350, 450],\n",
       " 'warm_up_steps': 25,\n",
       " 'gamma': 0.1,\n",
       " 'lr': 0.4,\n",
       " '_linear_warmup_lrs': array([1.00000000e-06, 1.66676250e-02, 3.33342500e-02, 5.00008750e-02,\n",
       "        6.66675000e-02, 8.33341250e-02, 1.00000750e-01, 1.16667375e-01,\n",
       "        1.33334000e-01, 1.50000625e-01, 1.66667250e-01, 1.83333875e-01,\n",
       "        2.00000500e-01, 2.16667125e-01, 2.33333750e-01, 2.50000375e-01,\n",
       "        2.66667000e-01, 2.83333625e-01, 3.00000250e-01, 3.16666875e-01,\n",
       "        3.33333500e-01, 3.50000125e-01, 3.66666750e-01, 3.83333375e-01,\n",
       "        4.00000000e-01]),\n",
       " '_logger': <Logger /home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py (INFO)>,\n",
       " 'base_lrs': [0.4],\n",
       " 'last_epoch': 148,\n",
       " '_step_count': 149,\n",
       " 'verbose': False,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [0.4]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckp_scheduler.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.04000000000000001 @ epoch 150\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.004000000000000001 @ epoch 350\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.00040000000000000013 @ epoch 450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a12ab2f10>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lrs=[]\n",
    "for _ in list(range(149,501)):\n",
    "    ckp_scheduler.step()\n",
    "    lrs.append(ckp_scheduler.get_last_lr())\n",
    "\n",
    "plt.plot(lrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': [150, 350, 450],\n",
       " 'warm_up_steps': 25,\n",
       " 'gamma': 0.1,\n",
       " 'lr': 0.4,\n",
       " '_linear_warmup_lrs': array([1.00000000e-06, 1.66676250e-02, 3.33342500e-02, 5.00008750e-02,\n",
       "        6.66675000e-02, 8.33341250e-02, 1.00000750e-01, 1.16667375e-01,\n",
       "        1.33334000e-01, 1.50000625e-01, 1.66667250e-01, 1.83333875e-01,\n",
       "        2.00000500e-01, 2.16667125e-01, 2.33333750e-01, 2.50000375e-01,\n",
       "        2.66667000e-01, 2.83333625e-01, 3.00000250e-01, 3.16666875e-01,\n",
       "        3.33333500e-01, 3.50000125e-01, 3.66666750e-01, 3.83333375e-01,\n",
       "        4.00000000e-01]),\n",
       " '_logger': <Logger /home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py (INFO)>,\n",
       " 'optimizer': SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     foreach: None\n",
       "     initial_lr: 0.4\n",
       "     lr: 1e-06\n",
       "     maximize: False\n",
       "     momentum: 0.9\n",
       "     nesterov: True\n",
       "     weight_decay: 0.0001\n",
       " ),\n",
       " 'base_lrs': [0.4],\n",
       " 'last_epoch': 148,\n",
       " '_step_count': 149,\n",
       " 'verbose': False,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [0.4]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckp_scheduler.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/build/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:124: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.04000000000000001 @ epoch 150\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.004000000000000001 @ epoch 350\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.00040000000000000013 @ epoch 450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.016667625000000002], [0.03333425], [0.050000875], [0.0666675], [0.08333412500000001], [0.10000075], [0.116667375], [0.133334], [0.150000625], [0.16666725000000002], [0.183333875], [0.2000005], [0.21666712500000002], [0.23333375], [0.250000375], [0.266667], [0.283333625], [0.30000024999999997], [0.316666875], [0.3333335], [0.350000125], [0.36666675], [0.383333375], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a4fce6550>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lrs = []\n",
    "for epoch in list(range(1,150)):\n",
    "    scheduler.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "print(lrs)\n",
    "plt.plot(lrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RigLScheduler(\\nlayers=54,\\nnonzero_params=[384/9408, 576/4096, 640/36864, 1536/16384, 1536/16384, 1536/16384, 640/36864, 1536/16384, 1536/16384, 640/36864, 1536/16384, 1792/32768, 1152/147456, 3072/65536, 3584/131072, 3072/65536, 1152/147456, 3072/65536, 3072/65536, 1152/147456, 3072/65536, 3072/65536, 1152/147456, 3072/65536, 3584/131072, 2304/589824, 6144/262144, 7168/524288, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 7168/524288, 4608/2359296, 12288/1048576, 14336/2097152, 12288/1048576, 4608/2359296, 12288/1048576, 12288/1048576, 4608/2359296, 12288/1048576, 14000/2048000],\\nnonzero_percentages=[4.08%, 14.06%, 1.74%, 9.38%, 9.38%, 9.38%, 1.74%, 9.38%, 9.38%, 1.74%, 9.38%, 5.47%, 0.78%, 4.69%, 2.73%, 4.69%, 0.78%, 4.69%, 4.69%, 0.78%, 4.69%, 4.69%, 0.78%, 4.69%, 2.73%, 0.39%, 2.34%, 1.37%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 1.37%, 0.20%, 1.17%, 0.68%, 1.17%, 0.20%, 1.17%, 1.17%, 0.20%, 1.17%, 0.68%],\\ntotal_nonzero_params=246512/25502912 (0.97%),\\ntotal_CONV_nonzero_params=232512/23454912 (0.99%),\\nstep=0,\\nnum_rigl_steps=0,\\nignoring_linear_layers=False,\\nsparsity_distribution=erk,\\nITOP rate=0.0097,\\nActive Neuron Count=[(64, 64), (64, 64), (64, 64), (256, 256), (256, 256), (64, 64), (64, 64), (256, 256), (64, 64), (64, 64), (256, 256), (128, 128), (128, 128), (512, 512), (512, 512), (128, 128), (128, 128), (512, 512), (128, 128), (128, 128), (512, 512), (128, 128), (128, 128), (512, 512), (256, 256), (256, 256), (1024, 1024), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (512, 512), (512, 512), (2048, 2048), (2048, 2048), (512, 512), (512, 512), (2048, 2048), (512, 512), (512, 512), (2048, 2048), (1000, 1000)],\\nconstant fan ins=[6, 9, 10, 6, 6, 24, 10, 6, 24, 10, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 24, 9, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 24, 9, 6, 24, 9, 6, 24, 9, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 14]\\nNeurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nNeurons Dynamically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\n)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.__str__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/project/6066928/mklasby/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f808c85ac10> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")\n",
    "model = ModelFactory.load_model(\"resnet50\", \"imagenet\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "# model = ModelFactory.load_model(\n",
    "#         model=cfg.model.name, dataset=cfg.dataset.name\n",
    "#     )\n",
    "model.to(device)\n",
    "optimizer = get_optimizer(cfg, model, state_dict=None)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=None)\n",
    "T_end = get_T_end(cfg, train_loader)\n",
    "if cfg.rigl.const_fan_in:\n",
    "    rigl_scheduler = RigLConstFanScheduler\n",
    "else:\n",
    "    rigl_scheduler = RigLScheduler\n",
    "# pruner = rigl_scheduler(\n",
    "#     model,\n",
    "#     optimizer,\n",
    "#     dense_allocation=cfg.rigl.dense_allocation,\n",
    "#     alpha=cfg.rigl.alpha,\n",
    "#     delta=cfg.rigl.delta,\n",
    "#     static_topo=cfg.rigl.static_topo,\n",
    "#     T_end=T_end,\n",
    "#     ignore_linear_layers=False,\n",
    "#     grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "#     sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "#     erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "#     state_dict=None,\n",
    "#     filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "#     static_ablation=cfg.rigl.static_ablation,\n",
    "#     dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "#     min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner(\n",
    "    \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "816b48dc46e0e4033a4b7ddacb526e2f216437e7413cf9fdf092ed7be3b64e38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50\n"
     ]
    }
   ],
   "source": [
    "with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "    cfg = compose(\n",
    "        \"config.yaml\",\n",
    "        overrides=[\n",
    "            \"dataset=imagenet\",\n",
    "            \"compute.distributed=False\",\n",
    "            \"model=resnet50\"\n",
    "            ])\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "os.environ[\"IMAGE_NET_PATH\"]\n",
    "print(cfg.model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /home/user/condensed-sparsity/artifacts/checkpoints/20230116_stmf1orh/checkpoint.pt.tar...\n",
      "Global seed set to 42\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7fe174742a70> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_cuda': False, 'cuda_kwargs': {'num_workers': '${ oc.decode:${oc.env:NUM_WORKERS} }', 'pin_memory': True}, 'distributed': True, 'world_size': 4, 'dist_backend': 'nccl'}\n",
      "loading to device rank: 0\n"
     ]
    }
   ],
   "source": [
    "run_id = \"stmf1orh\" \n",
    "rank=0\n",
    "checkpoint = Checkpoint.load_last_checkpoint(run_id=run_id, parent_dir = cfg.paths.checkpoints)\n",
    "# print(checkpoint)\n",
    "if checkpoint is not None:\n",
    "    run_id = checkpoint.run_id\n",
    "    optimizer_state = checkpoint.optimizer\n",
    "    scheduler_state = checkpoint.scheduler\n",
    "    pruner_state = checkpoint.pruner\n",
    "    model_state = checkpoint.model\n",
    "    cfg = checkpoint.cfg\n",
    "else:\n",
    "    run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "        None,\n",
    "    )\n",
    "\n",
    "print(cfg.compute)\n",
    "cfg.compute.distributed=False\n",
    "    \n",
    "pl.seed_everything(cfg.training.seed)\n",
    "use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "    raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "    logger.warning(\n",
    "        \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "        \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "    )\n",
    "\n",
    "if cfg.compute.distributed and use_cuda:\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "else:\n",
    "    print(f\"loading to device rank: {rank}\")\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "if not use_cuda:\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "# train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "model = ModelFactory.load_model(\n",
    "    model=cfg.model.name, dataset=cfg.dataset.name\n",
    ")\n",
    "model.to(device)\n",
    "if cfg.compute.distributed:\n",
    "    model = DistributedDataParallel(model, device_ids=[rank])\n",
    "if model_state is not None:\n",
    "    try:\n",
    "        model.load_state_dict(model_state)\n",
    "    except RuntimeError:\n",
    "        model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "        model.load_state_dict(model_state)\n",
    "        \n",
    "optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "pruner = None\n",
    "if cfg.rigl.dense_allocation is not None:\n",
    "    T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "    if cfg.rigl.const_fan_in:\n",
    "        rigl_scheduler = RigLConstFanScheduler\n",
    "    else:\n",
    "        rigl_scheduler = RigLScheduler\n",
    "    pruner = rigl_scheduler(\n",
    "        model,\n",
    "        optimizer,\n",
    "        dense_allocation=cfg.rigl.dense_allocation,\n",
    "        alpha=cfg.rigl.alpha,\n",
    "        delta=cfg.rigl.delta,\n",
    "        static_topo=cfg.rigl.static_topo,\n",
    "        T_end=T_end,\n",
    "        ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "        grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "        sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "        erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "        state_dict=pruner_state,\n",
    "        filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "        static_ablation=cfg.rigl.static_ablation,\n",
    "        dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "        min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "        use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "        init_method_str=cfg.rigl.init_method_str,\n",
    "        use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "    )\n",
    "    \n",
    "    step=0\n",
    "    \n",
    "def reinit_ablated_neuron_count(pruner: RigLConstFanScheduler) -> RigLConstFanScheduler:\n",
    "    pruner.dynamically_ablated_neuron_idx = [\n",
    "            [x for x in list(range(len(layer))) if x not in layer]\n",
    "            for layer in pruner.active_neurons\n",
    "        ]\n",
    "    return pruner\n",
    "\n",
    "    \n",
    "    # checkpoint = Checkpoint(\n",
    "    #             run_id=run_id,\n",
    "    #             cfg=cfg,\n",
    "    #             model=model,\n",
    "    #             optimizer=optimizer,\n",
    "    #             scheduler=scheduler,\n",
    "    #             pruner=pruner,\n",
    "    #             epoch=0,\n",
    "    #             step=step,\n",
    "    #             parent_dir=cfg.paths.checkpoints,\n",
    "    #         )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_state_dict_keys =['dense_allocation', 'S', 'N', 'delta_T', 'alpha', 'T_end', 'ignore_linear_layers', 'static_topo', 'sparsity_distribution', 'grad_accumulation_n', 'erk_power_scale', 'static_ablation', 'dynamic_ablation', 'min_salient_weights_per_neuron', 'step', 'rigl_steps', 'backward_masks', '_linear_layers_mask', 'itop_rs', 'explored_params', 'active_neurons', 'static_ablated_filters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dense_allocation', 'S', 'N', 'delta_T', 'alpha', 'T_end', 'ignore_linear_layers', 'static_topo', 'sparsity_distribution', 'grad_accumulation_n', 'erk_power_scale', 'static_ablation', 'dynamic_ablation', 'min_salient_weights_per_neuron', 'step', 'rigl_steps', 'backward_masks', '_linear_layers_mask', 'itop_rs', 'explored_params', 'active_neurons', 'static_ablated_filters'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self = pruner\n",
    "obj = {\n",
    "    \"dense_allocation\": self.dense_allocation,\n",
    "    \"S\": self.S,\n",
    "    \"N\": self.N,\n",
    "    \"delta_T\": self.delta_T,\n",
    "    \"alpha\": self.alpha,\n",
    "    \"T_end\": self.T_end,\n",
    "    \"ignore_linear_layers\": self.ignore_linear_layers,\n",
    "    \"static_topo\": self.static_topo,\n",
    "    \"sparsity_distribution\": self.sparsity_distribution,\n",
    "    \"grad_accumulation_n\": self.grad_accumulation_n,\n",
    "    \"erk_power_scale\": self.erk_power_scale,\n",
    "    \"static_ablation\": self.static_ablation,\n",
    "    \"dynamic_ablation\": self.dynamic_ablation,\n",
    "    \"min_salient_weights_per_neuron\": self.min_salient_weights_per_neuron,  # noqa\n",
    "    \"step\": self.step,\n",
    "    \"rigl_steps\": self.rigl_steps,\n",
    "    \"backward_masks\": self.backward_masks,\n",
    "    \"_linear_layers_mask\": self._linear_layers_mask,\n",
    "    \"itop_rs\": self.itop_rs,\n",
    "    \"explored_params\": self.explored_params,\n",
    "    \"active_neurons\": self.active_neurons,\n",
    "    \"static_ablated_filters\": self.static_ablated_filters,\n",
    "}\n",
    "obj.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dense_allocation', 'S', 'N', 'delta_T', 'alpha', 'T_end', 'ignore_linear_layers', 'static_topo', 'sparsity_distribution', 'grad_accumulation_n', 'erk_power_scale', 'static_ablation', 'dynamic_ablation', 'min_salient_weights_per_neuron', 'step', 'rigl_steps', 'backward_masks', '_linear_layers_mask', 'itop_rs', 'explored_params', 'active_neurons', 'static_ablated_filters'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.pruner.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.dynamically_ablated_neuron_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = reinit_ablated_neuron_count(pruner)\n",
    "# pruner.dynamically_ablated_neuron_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinit_ablated_neuron_count(pruner: RigLConstFanScheduler) -> RigLConstFanScheduler:\n",
    "    pruner.dynamically_ablated_neuron_idx=dynamically_ablated_neurons = [ [x for x in list(range(len(layer))) if x not in layer] for layer in pruner.active_neurons]\n",
    "    for layer_idx, layer in enumerate(pruner.dynamically_ablated_neuron_idx):\n",
    "        for neuron_idx in layer:\n",
    "            assert not pruner.backward_masks[layer_idx][neuron_idx].any()\n",
    "            assert (pruner.W[layer_idx][neuron_idx]==0).all()\n",
    "    return pruner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dynamically_ablated_neurons[0]:\n",
    "    if x in pruner.active_neurons[0]:\n",
    "        print(\"uhoh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 16,\n",
       " 17,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 39,\n",
       " 41,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 61]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.active_neurons[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 8, 9, 12, 13, 18, 19, 20, 22, 23, 25, 30],\n",
       " [0, 1, 3, 5, 6, 7, 8, 10, 15, 19, 21, 22, 23, 24, 25, 26],\n",
       " [0, 2, 3, 4, 6, 8, 12, 14, 17, 18, 20, 21, 22, 23, 25, 28, 30, 34],\n",
       " [0, 1, 3, 5, 9, 11, 14, 15, 18, 19, 23, 32],\n",
       " [0, 2, 4, 6, 8, 9, 10, 12, 14, 15, 18, 21, 23, 27, 28, 29, 30],\n",
       " [0,\n",
       "  2,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  15,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  42,\n",
       "  43,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  51,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58],\n",
       " [1,\n",
       "  3,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  16,\n",
       "  17,\n",
       "  22,\n",
       "  24,\n",
       "  28,\n",
       "  31,\n",
       "  34,\n",
       "  36,\n",
       "  39,\n",
       "  41,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  62,\n",
       "  67,\n",
       "  68,\n",
       "  69,\n",
       "  73],\n",
       " [1,\n",
       "  3,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  16,\n",
       "  17,\n",
       "  22,\n",
       "  24,\n",
       "  28,\n",
       "  31,\n",
       "  34,\n",
       "  36,\n",
       "  38,\n",
       "  39,\n",
       "  41,\n",
       "  42,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  67,\n",
       "  68],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  10,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  22,\n",
       "  24,\n",
       "  25,\n",
       "  28,\n",
       "  31,\n",
       "  32,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  41,\n",
       "  47,\n",
       "  50,\n",
       "  51,\n",
       "  53,\n",
       "  55,\n",
       "  57,\n",
       "  60],\n",
       " [1,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  14,\n",
       "  16,\n",
       "  17,\n",
       "  22,\n",
       "  28,\n",
       "  36,\n",
       "  39,\n",
       "  41,\n",
       "  45,\n",
       "  47,\n",
       "  48,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  61,\n",
       "  64,\n",
       "  67,\n",
       "  68],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  11,\n",
       "  13,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  43,\n",
       "  45,\n",
       "  46,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  52,\n",
       "  55,\n",
       "  56,\n",
       "  59,\n",
       "  60,\n",
       "  62,\n",
       "  63,\n",
       "  66,\n",
       "  67,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  79,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  89,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  101,\n",
       "  102,\n",
       "  107,\n",
       "  109,\n",
       "  110,\n",
       "  111],\n",
       " [1,\n",
       "  4,\n",
       "  7,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  23,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  48,\n",
       "  50,\n",
       "  53,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  111,\n",
       "  112,\n",
       "  115,\n",
       "  117,\n",
       "  119,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  131,\n",
       "  133,\n",
       "  135],\n",
       " [1,\n",
       "  4,\n",
       "  7,\n",
       "  9,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  23,\n",
       "  27,\n",
       "  29,\n",
       "  31,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  48,\n",
       "  50,\n",
       "  53,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  87,\n",
       "  88,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  103,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  111,\n",
       "  112,\n",
       "  115,\n",
       "  117,\n",
       "  119,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  131,\n",
       "  132],\n",
       " [0,\n",
       "  1,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  20,\n",
       "  22,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  35,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  53,\n",
       "  55,\n",
       "  57,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  68,\n",
       "  70,\n",
       "  72,\n",
       "  73,\n",
       "  74,\n",
       "  76,\n",
       "  78,\n",
       "  79,\n",
       "  83,\n",
       "  85,\n",
       "  91,\n",
       "  94,\n",
       "  100,\n",
       "  101,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  108,\n",
       "  109,\n",
       "  111],\n",
       " [1,\n",
       "  4,\n",
       "  7,\n",
       "  11,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  26,\n",
       "  27,\n",
       "  29,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  52,\n",
       "  53,\n",
       "  55,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  59,\n",
       "  61,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  71,\n",
       "  72,\n",
       "  73,\n",
       "  75,\n",
       "  76,\n",
       "  77,\n",
       "  80,\n",
       "  81,\n",
       "  86,\n",
       "  88,\n",
       "  90,\n",
       "  92,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  103,\n",
       "  104],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  9,\n",
       "  12,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  28,\n",
       "  30,\n",
       "  31,\n",
       "  34,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  41,\n",
       "  42,\n",
       "  45,\n",
       "  46,\n",
       "  48,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  55,\n",
       "  58,\n",
       "  59,\n",
       "  62,\n",
       "  63,\n",
       "  64,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  69,\n",
       "  70,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  77,\n",
       "  79,\n",
       "  81,\n",
       "  82,\n",
       "  85,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  93,\n",
       "  94,\n",
       "  95,\n",
       "  97,\n",
       "  98,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  110,\n",
       "  111,\n",
       "  114,\n",
       "  115,\n",
       "  119,\n",
       "  121,\n",
       "  125,\n",
       "  130,\n",
       "  131,\n",
       "  134,\n",
       "  135,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  140,\n",
       "  141,\n",
       "  143,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  149,\n",
       "  150,\n",
       "  152,\n",
       "  154,\n",
       "  156,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  163,\n",
       "  164,\n",
       "  165,\n",
       "  166,\n",
       "  167,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  171,\n",
       "  174,\n",
       "  175,\n",
       "  176,\n",
       "  178,\n",
       "  179,\n",
       "  181,\n",
       "  182,\n",
       "  183,\n",
       "  184,\n",
       "  185,\n",
       "  186,\n",
       "  188,\n",
       "  189,\n",
       "  191,\n",
       "  192,\n",
       "  193,\n",
       "  195,\n",
       "  196,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201],\n",
       " [0,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  23,\n",
       "  25,\n",
       "  27,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  40,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  84,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  95,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  109,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  115,\n",
       "  116,\n",
       "  118,\n",
       "  120,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  147,\n",
       "  148,\n",
       "  154,\n",
       "  156,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  165,\n",
       "  166,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  182,\n",
       "  183,\n",
       "  186,\n",
       "  187,\n",
       "  193,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  203,\n",
       "  205],\n",
       " [0,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  23,\n",
       "  25,\n",
       "  27,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  84,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  95,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  109,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  115,\n",
       "  116,\n",
       "  118,\n",
       "  120,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  146,\n",
       "  147,\n",
       "  148,\n",
       "  154,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  165,\n",
       "  166,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  182,\n",
       "  183,\n",
       "  186,\n",
       "  187,\n",
       "  193,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  199,\n",
       "  200,\n",
       "  201,\n",
       "  203,\n",
       "  205],\n",
       " [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  14,\n",
       "  15,\n",
       "  17,\n",
       "  18,\n",
       "  20,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  49,\n",
       "  51,\n",
       "  52,\n",
       "  53,\n",
       "  56,\n",
       "  57,\n",
       "  58,\n",
       "  60,\n",
       "  62,\n",
       "  63,\n",
       "  65,\n",
       "  67,\n",
       "  69,\n",
       "  70,\n",
       "  71,\n",
       "  73,\n",
       "  74,\n",
       "  75,\n",
       "  76,\n",
       "  78,\n",
       "  80,\n",
       "  81,\n",
       "  82,\n",
       "  83,\n",
       "  84,\n",
       "  85,\n",
       "  86,\n",
       "  89,\n",
       "  90,\n",
       "  91,\n",
       "  92,\n",
       "  93,\n",
       "  95,\n",
       "  97,\n",
       "  99,\n",
       "  100,\n",
       "  101,\n",
       "  104,\n",
       "  105,\n",
       "  106,\n",
       "  107,\n",
       "  111,\n",
       "  112,\n",
       "  115,\n",
       "  116,\n",
       "  117,\n",
       "  121,\n",
       "  122,\n",
       "  123,\n",
       "  126,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  133,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  140,\n",
       "  141,\n",
       "  142,\n",
       "  143,\n",
       "  145,\n",
       "  146,\n",
       "  149,\n",
       "  151,\n",
       "  153,\n",
       "  154,\n",
       "  157,\n",
       "  164,\n",
       "  166,\n",
       "  167],\n",
       " [0,\n",
       "  3,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  19,\n",
       "  25,\n",
       "  27,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  38,\n",
       "  40,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50,\n",
       "  51,\n",
       "  52,\n",
       "  54,\n",
       "  55,\n",
       "  56,\n",
       "  58,\n",
       "  59,\n",
       "  60,\n",
       "  62,\n",
       "  65,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  71,\n",
       "  72,\n",
       "  74,\n",
       "  76,\n",
       "  77,\n",
       "  78,\n",
       "  79,\n",
       "  80,\n",
       "  84,\n",
       "  86,\n",
       "  88,\n",
       "  89,\n",
       "  91,\n",
       "  92,\n",
       "  94,\n",
       "  95,\n",
       "  97,\n",
       "  99,\n",
       "  102,\n",
       "  104,\n",
       "  105,\n",
       "  107,\n",
       "  109,\n",
       "  111,\n",
       "  112,\n",
       "  113,\n",
       "  115,\n",
       "  116,\n",
       "  118,\n",
       "  120,\n",
       "  121,\n",
       "  124,\n",
       "  125,\n",
       "  127,\n",
       "  128,\n",
       "  129,\n",
       "  130,\n",
       "  131,\n",
       "  132,\n",
       "  133,\n",
       "  134,\n",
       "  137,\n",
       "  138,\n",
       "  139,\n",
       "  142,\n",
       "  143,\n",
       "  144,\n",
       "  145,\n",
       "  147,\n",
       "  148,\n",
       "  150,\n",
       "  157,\n",
       "  158,\n",
       "  159,\n",
       "  160,\n",
       "  161,\n",
       "  165,\n",
       "  166,\n",
       "  168,\n",
       "  169,\n",
       "  170,\n",
       "  176,\n",
       "  177,\n",
       "  178,\n",
       "  179,\n",
       "  182,\n",
       "  183,\n",
       "  186,\n",
       "  187,\n",
       "  193,\n",
       "  196,\n",
       "  197,\n",
       "  198,\n",
       "  200,\n",
       "  201,\n",
       "  203],\n",
       " []]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ [x for x in list(range(len(layer))) if x not in layer] for layer in pruner.active_neurons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RigLScheduler(\n",
      "layers=21,\n",
      "nonzero_params=[864/1728, 1624/36864, 1628/36864, 1617/36864, 1610/36864, 2400/73728, 3116/147456, 2325/8192, 3136/147456, 3124/147456, 4704/294912, 6256/589824, 4655/32768, 6272/589824, 6300/589824, 9292/1179648, 12420/2359296, 9360/131072, 12506/2359296, 12444/2359296, 5120/5120],\n",
      "nonzero_percentages=[50.00%, 4.41%, 4.42%, 4.39%, 4.37%, 3.26%, 2.11%, 28.38%, 2.13%, 2.12%, 1.60%, 1.06%, 14.21%, 1.06%, 1.07%, 0.79%, 0.53%, 7.14%, 0.53%, 0.53%, 100.00%],\n",
      "total_nonzero_params=110773/11164352 (0.99%),\n",
      "total_CONV_nonzero_params=105653/11159232 (0.95%),\n",
      "step=97500,\n",
      "num_rigl_steps=731,\n",
      "ignoring_linear_layers=False,\n",
      "sparsity_distribution=erk,\n",
      "ITOP rate=0.2386,\n",
      "Active Neuron Count=[(32, 64), (29, 64), (37, 64), (33, 64), (35, 64), (60, 128), (76, 128), (75, 128), (64, 128), (71, 128), (112, 256), (136, 256), (133, 256), (112, 256), (105, 256), (202, 512), (207, 512), (208, 512), (169, 512), (204, 512), (10, 10)],\n",
      "constant fan ins=[27, 56, 44, 49, 46, 40, 41, 31, 49, 44, 42, 46, 35, 56, 60, 46, 60, 45, 74, 61, 512]\n",
      "Neurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Neurons Dynamically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_dynamic_ablated_neuron_idx = \n",
    "\n",
    "\n",
    "# pruner.dynamically_ablated_neuron_idx  = [[list(range(x)) for x in] for layer_idx, layer in enumerate(pruner.active_neurons)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9408"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(384, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(pruner.W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580298609954484"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.S[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9408"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9592, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- pruner.backward_masks[0].sum() / pruner.W[0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-384/9408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/build/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:124: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a155be850>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lrs=[]\n",
    "for _ in list(range(1,149)):\n",
    "    scheduler.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:New best checkpoint accuracy (0.000000 > -inf)!\n"
     ]
    }
   ],
   "source": [
    "scheduler_state_dict, optimizer_state_dict = checkpoint.get_state()[\"scheduler\"], checkpoint.get_state()[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading optimizer from checkpoint...\n"
     ]
    }
   ],
   "source": [
    "new_optim = get_optimizer(cfg, model, optimizer_state_dict)\n",
    "ckp_scheduler= get_lr_scheduler(cfg, new_optim, state_dict=scheduler_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': [150, 350, 450],\n",
       " 'warm_up_steps': 25,\n",
       " 'gamma': 0.1,\n",
       " 'lr': 0.4,\n",
       " '_linear_warmup_lrs': array([1.00000000e-06, 1.66676250e-02, 3.33342500e-02, 5.00008750e-02,\n",
       "        6.66675000e-02, 8.33341250e-02, 1.00000750e-01, 1.16667375e-01,\n",
       "        1.33334000e-01, 1.50000625e-01, 1.66667250e-01, 1.83333875e-01,\n",
       "        2.00000500e-01, 2.16667125e-01, 2.33333750e-01, 2.50000375e-01,\n",
       "        2.66667000e-01, 2.83333625e-01, 3.00000250e-01, 3.16666875e-01,\n",
       "        3.33333500e-01, 3.50000125e-01, 3.66666750e-01, 3.83333375e-01,\n",
       "        4.00000000e-01]),\n",
       " '_logger': <Logger /home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py (INFO)>,\n",
       " 'base_lrs': [0.4],\n",
       " 'last_epoch': 148,\n",
       " '_step_count': 149,\n",
       " 'verbose': False,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [0.4]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckp_scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.04000000000000001 @ epoch 150\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.004000000000000001 @ epoch 350\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.00040000000000000013 @ epoch 450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a12ab2f10>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lrs=[]\n",
    "for _ in list(range(149,501)):\n",
    "    ckp_scheduler.step()\n",
    "    lrs.append(ckp_scheduler.get_last_lr())\n",
    "\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': [150, 350, 450],\n",
       " 'warm_up_steps': 25,\n",
       " 'gamma': 0.1,\n",
       " 'lr': 0.4,\n",
       " '_linear_warmup_lrs': array([1.00000000e-06, 1.66676250e-02, 3.33342500e-02, 5.00008750e-02,\n",
       "        6.66675000e-02, 8.33341250e-02, 1.00000750e-01, 1.16667375e-01,\n",
       "        1.33334000e-01, 1.50000625e-01, 1.66667250e-01, 1.83333875e-01,\n",
       "        2.00000500e-01, 2.16667125e-01, 2.33333750e-01, 2.50000375e-01,\n",
       "        2.66667000e-01, 2.83333625e-01, 3.00000250e-01, 3.16666875e-01,\n",
       "        3.33333500e-01, 3.50000125e-01, 3.66666750e-01, 3.83333375e-01,\n",
       "        4.00000000e-01]),\n",
       " '_logger': <Logger /home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py (INFO)>,\n",
       " 'optimizer': SGD (\n",
       " Parameter Group 0\n",
       "     dampening: 0\n",
       "     foreach: None\n",
       "     initial_lr: 0.4\n",
       "     lr: 1e-06\n",
       "     maximize: False\n",
       "     momentum: 0.9\n",
       "     nesterov: True\n",
       "     weight_decay: 0.0001\n",
       " ),\n",
       " 'base_lrs': [0.4],\n",
       " 'last_epoch': 148,\n",
       " '_step_count': 149,\n",
       " 'verbose': False,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [0.4]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckp_scheduler.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/build/.venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:124: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Seems like `optimizer.step()` has been overridden after learning rate scheduler \"\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.04000000000000001 @ epoch 150\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.004000000000000001 @ epoch 350\n",
      "INFO:/home/user/condensed-sparsity/src/rigl_torch/optim/step_lr_with_linear_warm_up.py:Reducing LR to 0.00040000000000000013 @ epoch 450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.016667625000000002], [0.03333425], [0.050000875], [0.0666675], [0.08333412500000001], [0.10000075], [0.116667375], [0.133334], [0.150000625], [0.16666725000000002], [0.183333875], [0.2000005], [0.21666712500000002], [0.23333375], [0.250000375], [0.266667], [0.283333625], [0.30000024999999997], [0.316666875], [0.3333335], [0.350000125], [0.36666675], [0.383333375], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.4], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.04000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.004000000000000001], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013], [0.00040000000000000013]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a4fce6550>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lrs = []\n",
    "for epoch in list(range(1,150)):\n",
    "    scheduler.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "print(lrs)\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RigLScheduler(\\nlayers=54,\\nnonzero_params=[384/9408, 576/4096, 640/36864, 1536/16384, 1536/16384, 1536/16384, 640/36864, 1536/16384, 1536/16384, 640/36864, 1536/16384, 1792/32768, 1152/147456, 3072/65536, 3584/131072, 3072/65536, 1152/147456, 3072/65536, 3072/65536, 1152/147456, 3072/65536, 3072/65536, 1152/147456, 3072/65536, 3584/131072, 2304/589824, 6144/262144, 7168/524288, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 6144/262144, 2304/589824, 6144/262144, 7168/524288, 4608/2359296, 12288/1048576, 14336/2097152, 12288/1048576, 4608/2359296, 12288/1048576, 12288/1048576, 4608/2359296, 12288/1048576, 14000/2048000],\\nnonzero_percentages=[4.08%, 14.06%, 1.74%, 9.38%, 9.38%, 9.38%, 1.74%, 9.38%, 9.38%, 1.74%, 9.38%, 5.47%, 0.78%, 4.69%, 2.73%, 4.69%, 0.78%, 4.69%, 4.69%, 0.78%, 4.69%, 4.69%, 0.78%, 4.69%, 2.73%, 0.39%, 2.34%, 1.37%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 2.34%, 0.39%, 2.34%, 1.37%, 0.20%, 1.17%, 0.68%, 1.17%, 0.20%, 1.17%, 1.17%, 0.20%, 1.17%, 0.68%],\\ntotal_nonzero_params=246512/25502912 (0.97%),\\ntotal_CONV_nonzero_params=232512/23454912 (0.99%),\\nstep=0,\\nnum_rigl_steps=0,\\nignoring_linear_layers=False,\\nsparsity_distribution=erk,\\nITOP rate=0.0097,\\nActive Neuron Count=[(64, 64), (64, 64), (64, 64), (256, 256), (256, 256), (64, 64), (64, 64), (256, 256), (64, 64), (64, 64), (256, 256), (128, 128), (128, 128), (512, 512), (512, 512), (128, 128), (128, 128), (512, 512), (128, 128), (128, 128), (512, 512), (128, 128), (128, 128), (512, 512), (256, 256), (256, 256), (1024, 1024), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (256, 256), (256, 256), (1024, 1024), (512, 512), (512, 512), (2048, 2048), (2048, 2048), (512, 512), (512, 512), (2048, 2048), (512, 512), (512, 512), (2048, 2048), (1000, 1000)],\\nconstant fan ins=[6, 9, 10, 6, 6, 24, 10, 6, 24, 10, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 24, 9, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 24, 9, 6, 24, 9, 6, 24, 9, 6, 14, 9, 6, 7, 24, 9, 6, 24, 9, 6, 14]\\nNeurons Statically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\nNeurons Dynamically Ablated per layer = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\\n)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:/project/6066928/mklasby/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet50/imagenet using <function get_imagenet_resnet50 at 0x7f808c85ac10> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")\n",
    "model = ModelFactory.load_model(\"resnet50\", \"imagenet\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "# model = ModelFactory.load_model(\n",
    "#         model=cfg.model.name, dataset=cfg.dataset.name\n",
    "#     )\n",
    "model.to(device)\n",
    "optimizer = get_optimizer(cfg, model, state_dict=None)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=None)\n",
    "T_end = get_T_end(cfg, train_loader)\n",
    "if cfg.rigl.const_fan_in:\n",
    "    rigl_scheduler = RigLConstFanScheduler\n",
    "else:\n",
    "    rigl_scheduler = RigLScheduler\n",
    "# pruner = rigl_scheduler(\n",
    "#     model,\n",
    "#     optimizer,\n",
    "#     dense_allocation=cfg.rigl.dense_allocation,\n",
    "#     alpha=cfg.rigl.alpha,\n",
    "#     delta=cfg.rigl.delta,\n",
    "#     static_topo=cfg.rigl.static_topo,\n",
    "#     T_end=T_end,\n",
    "#     ignore_linear_layers=False,\n",
    "#     grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "#     sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "#     erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "#     state_dict=None,\n",
    "#     filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "#     static_ablation=cfg.rigl.static_ablation,\n",
    "#     dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "#     min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "816b48dc46e0e4033a4b7ddacb526e2f216437e7413cf9fdf092ed7be3b64e38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

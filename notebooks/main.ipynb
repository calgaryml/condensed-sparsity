{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "import dotenv\n",
    "import omegaconf\n",
    "import hydra\n",
    "import logging\n",
    "import wandb\n",
    "from datetime import date\n",
    "import dotenv\n",
    "import os\n",
    "import pathlib\n",
    "from typing import Dict, Any\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils_eval import get_num_allzero_filters, get_num_allzero_fanout, get_num_allzero_kernels, get_num_kernels\n",
    "\n",
    "from rigl_torch.models import ModelFactory\n",
    "from rigl_torch.rigl_scheduler import RigLScheduler\n",
    "from rigl_torch.rigl_constant_fan import RigLConstFanScheduler\n",
    "from rigl_torch.datasets import get_dataloaders\n",
    "from rigl_torch.optim import (\n",
    "    get_optimizer,\n",
    "    get_lr_scheduler,\n",
    ")\n",
    "from rigl_torch.utils.checkpoint import Checkpoint\n",
    "from rigl_torch.utils.rigl_utils import get_T_end, get_fan_in_after_ablation, get_conv_idx_from_flat_idx\n",
    "from hydra import initialize, compose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18\n"
     ]
    }
   ],
   "source": [
    "with initialize(\"../configs\", version_base=\"1.2.0\"):\n",
    "    cfg = compose(\n",
    "        \"config.yaml\",\n",
    "        overrides=[\n",
    "            \"dataset=cifar10\",\n",
    "            \"compute.distributed=False\",\n",
    "            \"model=resnet18\"\n",
    "            ])\n",
    "dotenv.load_dotenv(\"../.env\")\n",
    "os.environ[\"IMAGE_NET_PATH\"]\n",
    "print(cfg.model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /Users/annago/Desktop/current_projects/work_w_UCalgary/checkpointsA/20221208_us1p7psr/checkpoint.pt.tar...\n",
      "Global seed set to 42\n",
      "INFO:/Users/annago/Desktop/current_projects/work_w_UCalgary/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x14619cd30> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /Users/annago/Desktop/current_projects/work_w_UCalgary/checkpointsA/20230111_8m2ytv3b/checkpoint.pt.tar...\n",
      "Global seed set to 42\n",
      "INFO:/Users/annago/Desktop/current_projects/work_w_UCalgary/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x14619cd30> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /Users/annago/Desktop/current_projects/work_w_UCalgary/checkpointsA/20230111_ek5wjcyn/checkpoint.pt.tar...\n",
      "Global seed set to 42\n",
      "INFO:/Users/annago/Desktop/current_projects/work_w_UCalgary/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x14619cd30> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading to device rank: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rigl_torch.utils.checkpoint:Loading checkpoint from /Users/annago/Desktop/current_projects/work_w_UCalgary/checkpointsA/20230112_f75f6a5m/checkpoint.pt.tar...\n",
      "Global seed set to 42\n",
      "INFO:/Users/annago/Desktop/current_projects/work_w_UCalgary/condensed-sparsity/src/rigl_torch/models/model_factory.py:Loading model resnet18/cifar10 using <function ResNet18 at 0x14619cd30> with args: () and kwargs: {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading to device rank: 0\n"
     ]
    }
   ],
   "source": [
    "run_ids= [\"us1p7psr\", \"8m2ytv3b\", \"ek5wjcyn\", \"f75f6a5m\"]\n",
    "# ['20230112_8yltfx1b', '20230112_d17iii70']\n",
    "# [\"20230112_2jjmdzam\", \"20230112_37my33se\", \"20230112_4d3flaxi\", \"20230112_f75f6a5m\", \"20230112_tkcz3emd\"]\n",
    "#run_id = \"us1p7psr\" # us1p7psr (no dyn ablation), 8m2ytv3b (0.01), ek5wjcyn (0.1), f75f6a5m (0.5)\n",
    "\n",
    "rank=0\n",
    "ckpt_path=\"/Users/annago/Desktop/current_projects/work_w_UCalgary/checkpointsA\"\n",
    "NumZeroFilters={}\n",
    "NumZeroFanOut={}\n",
    "zkn={}\n",
    "zkf={}\n",
    "sparsity={}\n",
    "\n",
    "for run_id in run_ids:\n",
    "    checkpoint = Checkpoint.load_last_checkpoint(run_id=run_id, parent_dir = ckpt_path)\n",
    "    #checkpoint=None\n",
    "    if checkpoint is not None:\n",
    "        run_id = checkpoint.run_id\n",
    "        optimizer_state = checkpoint.optimizer\n",
    "        scheduler_state = checkpoint.scheduler\n",
    "        pruner_state = checkpoint.pruner\n",
    "        model_state = checkpoint.model\n",
    "        cfg = checkpoint.cfg\n",
    "    else:\n",
    "        run_id, optimizer_state, scheduler_state, pruner_state, model_state = (\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        )\n",
    "\n",
    "\n",
    "        # cfg.compute.distributed=False\n",
    "        \n",
    "    pl.seed_everything(cfg.training.seed)\n",
    "    use_cuda = not cfg.compute.no_cuda and torch.cuda.is_available()\n",
    "    # if not use_cuda:\n",
    "    #     raise SystemError(\"GPU has stopped responding...waiting to die!\")\n",
    "    #     logger.warning(\n",
    "    #         \"Using CPU! Verify cfg.compute.no_cuda and \"\n",
    "    #         \"torch.cuda.is_available() are properly set if this is unexpected\"\n",
    "    #     )\n",
    "\n",
    "\n",
    "    if cfg.compute.distributed and use_cuda:\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    else:\n",
    "        print(f\"loading to device rank: {rank}\")\n",
    "        device = torch.device(f\"cuda:{rank}\")\n",
    "    if not use_cuda:\n",
    "        device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # train_loader, test_loader = get_dataloaders(cfg)\n",
    "\n",
    "    model = ModelFactory.load_model(\n",
    "        model=cfg.model.name, dataset=cfg.dataset.name\n",
    "    )\n",
    "    model.to(device)\n",
    "    if cfg.compute.distributed:\n",
    "        model = DistributedDataParallel(model, device_ids=[rank])\n",
    "    if model_state is not None:\n",
    "        try:\n",
    "            model.load_state_dict(model_state)\n",
    "        except RuntimeError:\n",
    "            model_state = checkpoint.get_single_process_model_state_from_distributed_state()\n",
    "            model.load_state_dict(model_state)\n",
    "            \n",
    "    optimizer = get_optimizer(cfg, model, state_dict=optimizer_state)\n",
    "    scheduler = get_lr_scheduler(cfg, optimizer, state_dict=scheduler_state)\n",
    "    pruner = None\n",
    "    if cfg.rigl.dense_allocation is not None:\n",
    "        T_end = get_T_end(cfg, [0 for _ in range(0,1251)])\n",
    "        if cfg.rigl.const_fan_in:\n",
    "            rigl_scheduler = RigLConstFanScheduler\n",
    "        else:\n",
    "            rigl_scheduler = RigLScheduler\n",
    "        pruner = rigl_scheduler(\n",
    "            model,\n",
    "            optimizer,\n",
    "            dense_allocation=cfg.rigl.dense_allocation,\n",
    "            alpha=cfg.rigl.alpha,\n",
    "            delta=cfg.rigl.delta,\n",
    "            static_topo=cfg.rigl.static_topo,\n",
    "            T_end=T_end,\n",
    "            ignore_linear_layers=cfg.rigl.ignore_linear_layers,\n",
    "            grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "            sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "            erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "            state_dict=pruner_state,\n",
    "            filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "            static_ablation=cfg.rigl.static_ablation,\n",
    "            dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "            min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,  # noqa\n",
    "            use_sparse_init=cfg.rigl.use_sparse_initialization,\n",
    "            init_method_str=cfg.rigl.init_method_str,\n",
    "            use_sparse_const_fan_in_for_ablation=cfg.rigl.use_sparse_const_fan_in_for_ablation,  # noqa\n",
    "        )\n",
    "        \n",
    "        step=0\n",
    "        \n",
    "        checkpoint = Checkpoint(\n",
    "                    run_id=run_id,\n",
    "                    cfg=cfg,\n",
    "                    model=model,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    pruner=pruner,\n",
    "                    epoch=0,\n",
    "                    step=step,\n",
    "                    parent_dir=ckpt_path,\n",
    "                )\n",
    "\n",
    "    NumZeroFilters[run_id]= []\n",
    "    NumZeroFanOut[run_id]= []\n",
    "\n",
    "    for i, w in enumerate(pruner.W):\n",
    "        if pruner.S[i]>0:\n",
    "            num_zero_filters= get_num_allzero_filters(w)\n",
    "            num_zero_fanout = get_num_allzero_fanout(w)\n",
    "        else:\n",
    "            num_zero_filters=0\n",
    "            num_zero_fanout=0\n",
    "        NumZeroFilters[run_id].append(num_zero_filters)\n",
    "        NumZeroFanOut[run_id].append(num_zero_fanout)\n",
    "\n",
    "    sparsity[run_id]=pruner.S\n",
    "\n",
    "\n",
    "\n",
    "    zkf[run_id]= []\n",
    "    zkn[run_id]= []\n",
    "\n",
    "    for i, w in enumerate(pruner.W):\n",
    "        if pruner.S[i]>0:\n",
    "            zero_kernel_fract= get_num_allzero_kernels(w)/get_num_kernels(w)\n",
    "            num_allzero_kernels= get_num_allzero_kernels(w)\n",
    "        else:\n",
    "            zero_kernel_fract=0\n",
    "            num_allzero_kernels=0\n",
    "        zkf[run_id].append(zero_kernel_fract)\n",
    "        zkn[run_id].append(num_allzero_kernels)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers= len(pruner.W)\n",
    "layer_inds=[]\n",
    "\n",
    "for layer_idx in range(num_layers):\n",
    "    if pruner.W[layer_idx].shape[-1]==3:\n",
    "        layer_inds.append(layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for zero fan-in and fan-out\n",
    "\n",
    "num_layers= len(pruner.W)\n",
    "num_disconnected_neurons={}\n",
    "\n",
    "for l in range(len(layer_inds)-1):\n",
    "    \n",
    "    w1= pruner.W[layer_inds[l]]\n",
    "    w2= pruner.W[layer_inds[l+1]]\n",
    "\n",
    "    num_neurons= w1.shape[0]\n",
    "    count=0\n",
    "    for neuron_idx in range(num_neurons):\n",
    "        if w2[:,neuron_idx,:,:].any()==False and w1[neuron_idx,:,:,:].any()==False:\n",
    "            count+=1\n",
    "    \n",
    "    num_disconnected_neurons[layer_inds[l]]=count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 32,\n",
       " 1: 35,\n",
       " 2: 19,\n",
       " 3: 27,\n",
       " 4: 11,\n",
       " 5: 64,\n",
       " 6: 48,\n",
       " 8: 65,\n",
       " 9: 46,\n",
       " 10: 137,\n",
       " 11: 112,\n",
       " 13: 140,\n",
       " 14: 111,\n",
       " 15: 319,\n",
       " 16: 294,\n",
       " 18: 335}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_disconnected_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f75f6a5m'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.W[8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks= checkpoint.pruner.backward_masks\n",
    "num_layers= len(masks)\n",
    "for layer_ind in range(num_layers):\n",
    "    if masks[layer_ind] is not None:\n",
    "        s= masks[layer_ind].shape\n",
    "    else:\n",
    "        s='None'\n",
    "    print(layer_ind, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children(model: torch.nn.Module):\n",
    "    # get children form model!\n",
    "    children = list(model.children())\n",
    "    flatt_children = []\n",
    "    if children == []:\n",
    "        # if model has no children; model is last child! :O\n",
    "        return model\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for child in children:\n",
    "            try:\n",
    "                flatt_children.extend(get_children(child))\n",
    "            except TypeError:\n",
    "                flatt_children.append(get_children(child))\n",
    "    return flatt_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatM= get_children(M)\n",
    "\n",
    "j=0\n",
    "for i, layer in enumerate(flatM):\n",
    "    if isinstance(layer, (torch.nn.Conv2d,torch.nn.AvgPool2d)):\n",
    "        print(j, layer, \"   \", masks[j].shape)\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "plot_savedir = '/Users/annago/Desktop/'\n",
    "cmap = matplotlib.cm.get_cmap('gnuplot2') # rainbow\n",
    "\n",
    "x=3.5\n",
    "title_font_size=6*x\n",
    "label_font_size=5.5*x\n",
    "tick_font_size=5*x\n",
    "legend_font_size=22*x/6\n",
    "legend_title_font_size=22*x/6\n",
    "\n",
    "# ==== plot styling\n",
    "plotparams = {'savefig.dpi': 300,\n",
    "              'text.usetex': True,\n",
    "              'font.family': 'serif',\n",
    "              'legend.fontsize': legend_font_size,\n",
    "              'legend.title_fontsize': legend_title_font_size,\n",
    "              'axes.labelsize': label_font_size,\n",
    "              'axes.titlesize': title_font_size,\n",
    "              'xtick.labelsize': tick_font_size,\n",
    "              'ytick.labelsize': tick_font_size,\n",
    "              'axes.grid': True,\n",
    "              'axes.grid.axis': 'both',\n",
    "              'axes.grid.which': 'both',\n",
    "              'grid.alpha': 0.5,\n",
    "              'grid.color': '#b0b0b0',\n",
    "              'grid.linestyle': '-',\n",
    "              'grid.linewidth': 0.8}\n",
    "plt.style.use(plotparams)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "\n",
    "def label_bars(ax, bars, text_format, **kwargs):\n",
    "    \"\"\"\n",
    "    Attaches a label on every bar of a regular or horizontal bar chart\n",
    "    \"\"\"\n",
    "    ys = [bar.get_y() for bar in bars]\n",
    "    y_is_constant = all(y == ys[0] for y in ys)  # -> regular bar chart, since all bars start on the same y level (0)\n",
    "\n",
    "    if y_is_constant:\n",
    "        _label_bar(ax, bars, text_format, **kwargs)\n",
    "    else:\n",
    "        _label_barh(ax, bars, text_format, **kwargs)\n",
    "\n",
    "\n",
    "def _label_bar(ax, bars, text_format, **kwargs):\n",
    "    \"\"\"\n",
    "    Attach a text label to each bar displaying its y value\n",
    "    \"\"\"\n",
    "    max_y_value = ax.get_ylim()[1]\n",
    "    inside_distance = max_y_value * 0.05\n",
    "    outside_distance = max_y_value * 0.01\n",
    "\n",
    "    for bar in bars:\n",
    "        text = text_format.format(bar.get_height())\n",
    "        text_x = bar.get_x() + bar.get_width() / 2\n",
    "\n",
    "        is_inside = bar.get_height() >= max_y_value * 0.15\n",
    "        if is_inside:\n",
    "            color = \"white\"\n",
    "            text_y = bar.get_height() - inside_distance\n",
    "        else:\n",
    "            color = \"black\"\n",
    "            text_y = bar.get_height() + outside_distance\n",
    "\n",
    "        ax.text(text_x, text_y, text, ha='center', va='bottom', color=color, **kwargs)\n",
    "\n",
    "\n",
    "def _label_barh(ax, bars, text_format, **kwargs):\n",
    "    \"\"\"\n",
    "    Attach a text label to each bar displaying its y value\n",
    "    Note: hacky ad-hoc solution to adjust text position inside/outside the bars.\n",
    "    \"\"\"\n",
    "    max_x_value = ax.get_xlim()[1]\n",
    "    distance = max_x_value * 0.15\n",
    "\n",
    "    for bar in bars:\n",
    "        text = text_format.format(bar.get_width())\n",
    "        \n",
    "        bwidth = bar.get_width()\n",
    "        if bwidth<distance: \n",
    "            text_x= bwidth + distance/4\n",
    "        else: \n",
    "            text_x= bwidth + distance/4\n",
    "            \n",
    "        text_y= bar.get_y() + bar.get_height() / 2\n",
    "\n",
    "        if bwidth>0: # do not print zero values\n",
    "            ax.text(text_x, text_y, text, va='center', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import MutableMapping\n",
    "def flatten(d, parent_key='', sep='_'):\n",
    "\titems = []\n",
    "\tfor k, v in d.items():\n",
    "\t\tnew_key = parent_key + sep + k if parent_key else k\n",
    "\t\tif isinstance(v, MutableMapping):\n",
    "\t\t\titems.extend(flatten(v, new_key, sep=sep).items())\n",
    "\t\telse:\n",
    "\t\t\titems.append((new_key, v))\n",
    "\treturn dict(items)\n",
    "\t\n",
    "def get_tensor_dims(model, ltypes):\n",
    "\t\"\"\" Makes dict tensor_dims containing the dimensions of each layer tensor. \"\"\"\n",
    "\ttensor_dims= {}\n",
    "\tfill_tensor_dims(model, ltypes, tensor_dims)\n",
    "\ttensor_dims= flatten(tensor_dims)\n",
    "\treturn tensor_dims\n",
    "\n",
    "\n",
    "def fill_tensor_dims(model, ltypes, tensor_dims):\n",
    "\t\"\"\" Fills the dict tensor_dims with the dims of each layer of type specified in ltypes \n",
    "\tin the given model. \"\"\"   \n",
    "\tfor lname, child in model.named_children():\n",
    "\t\tltype = child._get_name()\n",
    "\n",
    "\t\tif ltype in ltypes:\n",
    "\t\t\ttensor_dims[lname] = list(child.weight.shape)\n",
    "\t\telse:\n",
    "\t\t\ttensor_dims[lname] = {}\n",
    "\t\t\tfill_tensor_dims(child, ltypes, tensor_dims[lname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltypes=['Linear', 'Conv2d']\n",
    "tdims= get_tensor_dims(model, ltypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"orig.width - abl.neurons = remaining width\")\n",
    "for i in range(len(NumZeroFilters[run_id])-1):\n",
    "    num_out_dense= pruner.W[i].shape[0]\n",
    "    num_out_gone= NumZeroFilters[run_id][i]\n",
    "    num_out_left= pruner.W[i].shape[0]-NumZeroFilters[run_id][i]\n",
    "    print(f\"{num_out_dense} - {num_out_gone} = {num_out_left} ({100*num_out_left/num_out_dense:.1f} %)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids=['us1p7psr', 'f75f6a5m']\n",
    "la= {'us1p7psr': 'no abl.', '8m2ytv3b': 'abl.t=0.01', 'ek5wjcyn': 'abl.t=0.1', 'f75f6a5m': 'abl.t=0.5'}\n",
    "ma= {'us1p7psr': 'x', \n",
    "'8m2ytv3b': 'o', \n",
    "'ek5wjcyn': 'o', \n",
    "'f75f6a5m': 'o'}\n",
    "ma_size=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig= True\n",
    "fig_savename= 'combined'\n",
    "\n",
    "fig, axs = plt.subplots(1,4, figsize=(12,2.5))\n",
    "\n",
    "\n",
    "ax=axs[0]\n",
    "for run_id in run_ids:\n",
    "    v= sparsity[run_id]\n",
    "    ax.plot(v[:-1], label=la[run_id], linestyle='', marker=ma[run_id], markersize=ma_size, markerfacecolor='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('layer index')\n",
    "ax.set_ylabel('sparsity')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "ax=axs[1]\n",
    "for run_id in run_ids:\n",
    "    v= zkf[run_id]\n",
    "    ax.plot(v[:-1], label=la[run_id], linestyle='', marker=ma[run_id], markersize=ma_size, markerfacecolor='none')\n",
    "\n",
    "ax.set_xlabel('layer index')\n",
    "ax.set_ylabel('fraction all-zero kernels')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "\n",
    "ax=axs[2]\n",
    "for run_id in run_ids:\n",
    "    v= NumZeroFilters[run_id]\n",
    "    p= [v[i]/pruner.W[i].shape[0] for i in range(len(v))]\n",
    "    ax.plot(p[:-1], label=la[run_id], linestyle='', marker=ma[run_id], markersize=ma_size, markerfacecolor='none')\n",
    "\n",
    "ax.set_xlabel('layer index')\n",
    "ax.set_ylabel('fraction all-zero neurons')\n",
    "\n",
    "\n",
    "ax=axs[3]\n",
    "for run_id in run_ids:\n",
    "    v= NumZeroFanOut[run_id]\n",
    "    p= [v[i]/pruner.W[i].shape[1] for i in range(len(v))]\n",
    "    ax.plot(p[:-1], label=la[run_id], linestyle='', marker=ma[run_id], markersize=ma_size, markerfacecolor='none')\n",
    "\n",
    "ax.set_xlabel('layer index')\n",
    "ax.set_ylabel('fraction all-zero fan-out')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fig.savefig(plot_savedir+fig_savename+'.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig= True\n",
    "fig_savename= 'zero_kernel_fract'\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,4))\n",
    "\n",
    "for run_id in run_ids:\n",
    "    v= zkf[run_id]\n",
    "    ax.plot(v, label=la[run_id], linestyle='', marker=ma[run_id], markersize=ma_size, markerfacecolor='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('layer index')\n",
    "ax.set_ylabel('fraction all-zero kernels')\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fig.savefig(plot_savedir+fig_savename+'.png', format='png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig= True\n",
    "fig_savename= 'zero_neurons_fract'\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,4))\n",
    "\n",
    "for run_id in run_ids:\n",
    "    v= NumZeroFilters[run_id]\n",
    "    p= [v[i]/pruner.W[i].shape[0] for i in range(len(v))]\n",
    "    ax.plot(p, label=la[run_id], linestyle='', marker=ma[run_id], markersize=ma_size, markerfacecolor='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('layer index')\n",
    "ax.set_ylabel('fraction all-zero neurons')\n",
    "\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fig.savefig(plot_savedir+fig_savename+'.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig= True\n",
    "fig_savename= 'sparsity'\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,4))\n",
    "\n",
    "for run_id in run_ids:\n",
    "    v= sparsity[run_id]\n",
    "    ax.plot(v, label=la[run_id], linestyle='', marker=ma[run_id], markersize=ma_size, markerfacecolor='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('layer index')\n",
    "ax.set_ylabel('sparsity')\n",
    "\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fig.savefig(plot_savedir+fig_savename+'.png', format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig= True\n",
    "fig_savename= \"sparsity\" # \"width\"\n",
    "n= 1\n",
    "fig, ax = plt.subplots(1,n,figsize=(3.5*n,7))\n",
    "#plt.suptitle(f'Per-layer sparsity distribution in {args.resnet_type} with base width {args.noc1_base}', fontsize=title_font_size)\n",
    "\n",
    "\n",
    "lnames= list(tdims.keys())\n",
    "y_pos = np.arange(len(lnames))\n",
    "\n",
    "#x_val = [pruner.W[i].shape[0] for i in range(len(pruner.W))]\n",
    "x_val = np.zeros(len(pruner.S))\n",
    "error = None\n",
    "\n",
    "bars= ax.barh(y_pos, x_val, xerr=error, align='center', alpha=1, label='orig.width')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels([l.replace(\"_\",\".\") for l in lnames])\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Sparsity') #Width\n",
    "ax.set_xlim([0,100]) # 512\n",
    "value_format= \"{:.1f}\"\n",
    "label_bars(ax, bars, value_format)\n",
    "\n",
    "\n",
    "for run_id in run_ids:\n",
    "\n",
    "    #x_val = [pruner.W[i].shape[0]-NumZeroFilters[run_id][i] for i in range(len(pruner.W))]\n",
    "    x_val = 100*np.array(sparsity[run_id])\n",
    "    bars= ax.barh(y_pos, x_val, xerr=error, align='center', alpha=1, label=la[run_id])\n",
    "    \n",
    "    #label_bars(ax, bars, value_format)\n",
    "\n",
    "plt.legend()\n",
    "#plt.tight_layout()\n",
    "#fig.subplots_adjust(wspace=0.25)\n",
    "plt.show()\n",
    "if save_fig:\n",
    "    fig.savefig(plot_savedir+fig_savename+'.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    w= pruner.W[i]\n",
    "    #r= 1-torch.count_nonzero(w)/w.numel()\n",
    "    r= 1-torch.count_nonzero(masks[i])/w.numel()\n",
    "    s= pruner.S[i]\n",
    "    print(f\"{r.item():.4}, {s:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NumZeroFilters={}\n",
    "NumZeroFilters[run_id]= []\n",
    "\n",
    "for i, w in enumerate(pruner.W):\n",
    "    if pruner.S[i]>0:\n",
    "        num_zero_filters= get_num_allzero_filters(w)\n",
    "    else:\n",
    "        num_zero_filters=0\n",
    "    NumZeroFilters[run_id].append(num_zero_filters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in zkf.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "cmap = mpl.cm.get_cmap('plasma') # rainbow\n",
    "\n",
    "x=2.6\n",
    "title_font_size=5.5*x\n",
    "label_font_size=5.5*x\n",
    "tick_font_size=5*x\n",
    "legend_font_size=23*x/6\n",
    "legend_title_font_size=22*x/6\n",
    "\n",
    "#==== plot styling\n",
    "plotparams = {\n",
    "              'legend.fontsize': legend_font_size,\n",
    "              'legend.title_fontsize': legend_title_font_size,\n",
    "              'axes.labelsize': label_font_size,\n",
    "              'axes.titlesize': title_font_size,\n",
    "              'xtick.labelsize': tick_font_size,\n",
    "              'ytick.labelsize': tick_font_size\n",
    "}\n",
    "plt.style.use(plotparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lrs=[]\n",
    "for _ in list(range(1,149)):\n",
    "    scheduler.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_state_dict, optimizer_state_dict = checkpoint.get_state()[\"scheduler\"], checkpoint.get_state()[\"optimizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_optim = get_optimizer(cfg, model, optimizer_state_dict)\n",
    "ckp_scheduler= get_lr_scheduler(cfg, new_optim, state_dict=scheduler_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_scheduler.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "lrs=[]\n",
    "for _ in list(range(149,501)):\n",
    "    ckp_scheduler.step()\n",
    "    lrs.append(ckp_scheduler.get_last_lr())\n",
    "\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_scheduler.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lrs = []\n",
    "for epoch in list(range(1,150)):\n",
    "    scheduler.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "print(lrs)\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = ModelFactory.load_model(\"wide_resnet22\", \"cifar10\")\n",
    "model = ModelFactory.load_model(\"resnet50\", \"imagenet\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "train_loader, test_loader = get_dataloaders(cfg)\n",
    "# model = ModelFactory.load_model(\n",
    "#         model=cfg.model.name, dataset=cfg.dataset.name\n",
    "#     )\n",
    "model.to(device)\n",
    "optimizer = get_optimizer(cfg, model, state_dict=None)\n",
    "scheduler = get_lr_scheduler(cfg, optimizer, state_dict=None)\n",
    "T_end = get_T_end(cfg, train_loader)\n",
    "if cfg.rigl.const_fan_in:\n",
    "    rigl_scheduler = RigLConstFanScheduler\n",
    "else:\n",
    "    rigl_scheduler = RigLScheduler\n",
    "# pruner = rigl_scheduler(\n",
    "#     model,\n",
    "#     optimizer,\n",
    "#     dense_allocation=cfg.rigl.dense_allocation,\n",
    "#     alpha=cfg.rigl.alpha,\n",
    "#     delta=cfg.rigl.delta,\n",
    "#     static_topo=cfg.rigl.static_topo,\n",
    "#     T_end=T_end,\n",
    "#     ignore_linear_layers=False,\n",
    "#     grad_accumulation_n=cfg.rigl.grad_accumulation_n,\n",
    "#     sparsity_distribution=cfg.rigl.sparsity_distribution,\n",
    "#     erk_power_scale=cfg.rigl.erk_power_scale,\n",
    "#     state_dict=None,\n",
    "#     filter_ablation_threshold=cfg.rigl.filter_ablation_threshold,\n",
    "#     static_ablation=cfg.rigl.static_ablation,\n",
    "#     dynamic_ablation=cfg.rigl.dynamic_ablation,\n",
    "#     min_salient_weights_per_neuron=cfg.rigl.min_salient_weights_per_neuron,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner(\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00f07e3d2e37fed0934a5fcb5990cf0253b1979f588b0b82b40c3b7117a4b479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
